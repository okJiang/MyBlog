{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"themes/butterfly/source/css/index.styl","path":"css/index.styl","modified":0,"renderable":1},{"_id":"themes/butterfly/source/css/var.styl","path":"css/var.styl","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/404.jpg","path":"img/404.jpg","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/favicon.png","path":"img/favicon.png","modified":0,"renderable":1},{"_id":"themes/butterfly/source/img/friend_404.gif","path":"img/friend_404.gif","modified":0,"renderable":1},{"_id":"themes/butterfly/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/butterfly/source/js/tw_cn.js","path":"js/tw_cn.js","modified":0,"renderable":1},{"_id":"themes/butterfly/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/butterfly/source/js/search/algolia.js","path":"js/search/algolia.js","modified":0,"renderable":1},{"_id":"themes/butterfly/source/js/search/local-search.js","path":"js/search/local-search.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/404.md","hash":"3bf1c1cecaf07cceea193fc8f00cb394145e9cc2","modified":1718462174094},{"_id":"source/_posts/2022年终总结.md","hash":"d487cdf0517746cbcf5d573e23568390753b53b0","modified":1718462174094},{"_id":"source/categories/index.md","hash":"12aa89fc2f5e0d39a459ade9efea837cde29e2bb","modified":1718462174094},{"_id":"source/tags/index.md","hash":"148a16399bdc84abbfdf5dfca0fb1446c5269ca2","modified":1718462174094},{"_id":"themes/butterfly/LICENSE","hash":"1128f8f91104ba9ef98d37eea6523a888dcfa5de","modified":1718463162815},{"_id":"themes/butterfly/README.md","hash":"4e01b47448d9f3a02afc04eef644e2321253f6f4","modified":1718463162815},{"_id":"themes/butterfly/README_CN.md","hash":"148da187d16033624ceccce8b8561835296f5a5a","modified":1718463162815},{"_id":"themes/butterfly/package.json","hash":"314b0271ba3f668d0d6081b499b2d24e90dab25e","modified":1718463162819},{"_id":"themes/butterfly/.github/FUNDING.yml","hash":"da5e77f5e0cdb7e11b36546fb6796d10e3dfbe5d","modified":1718463162811},{"_id":"themes/butterfly/plugins.yml","hash":"d807fbb62163bb6fc5a83a24ebd69ac14cf45f67","modified":1718463162819},{"_id":"themes/butterfly/_config.yml","hash":"10e02050b5eeaf5d869cf4df4d3188c9cc4acebb","modified":1718521092168},{"_id":"themes/butterfly/languages/default.yml","hash":"90a6dc361de67532437d819a55ec64945ca5404b","modified":1718463162815},{"_id":"themes/butterfly/languages/en.yml","hash":"af5603b1a888f167dc80be6d53a19437b5cf6bef","modified":1718463162815},{"_id":"themes/butterfly/layout/archive.pug","hash":"bb32c9c476372de747dfa563b83f77d7a917a77d","modified":1718463162815},{"_id":"themes/butterfly/layout/category.pug","hash":"710708cfdb436bc875602abf096c919ccdf544db","modified":1718463162815},{"_id":"themes/butterfly/languages/zh-CN.yml","hash":"5004faee365139521f161babd66649a8107e4008","modified":1718463162815},{"_id":"themes/butterfly/languages/zh-TW.yml","hash":"03629d1d13a7be09d4933aa5dc0dcbe45e79140c","modified":1718463162815},{"_id":"themes/butterfly/layout/index.pug","hash":"e1c3146834c16e6077406180858add0a8183875a","modified":1718463162819},{"_id":"themes/butterfly/layout/page.pug","hash":"baf469784aef227e4cc840550888554588e87a13","modified":1718463162819},{"_id":"themes/butterfly/layout/post.pug","hash":"fc9f45252d78fcd15e4a82bfd144401cba5b169a","modified":1718463162819},{"_id":"themes/butterfly/layout/tag.pug","hash":"0440f42569df2676273c026a92384fa7729bc4e9","modified":1718463162819},{"_id":"themes/butterfly/.github/ISSUE_TEMPLATE/bug_report.yml","hash":"6e34b565ea013812d5e363b6de5fa1f9078d4e12","modified":1718463162811},{"_id":"themes/butterfly/.github/ISSUE_TEMPLATE/config.yml","hash":"7b4831ae8f8f8c55dd1b856781210c517c63e6dd","modified":1718463162811},{"_id":"themes/butterfly/.github/ISSUE_TEMPLATE/feature_request.yml","hash":"996640605ed1e8e35182f0fd9a60a88783b24b03","modified":1718463162811},{"_id":"themes/butterfly/.github/workflows/publish.yml","hash":"05857c2f265246d8de00e31037f2720709540c09","modified":1718463162815},{"_id":"themes/butterfly/.github/workflows/stale.yml","hash":"ac62b989b5550c756e1986fcc68f243170705383","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/404.pug","hash":"cb49f737aca272ccfeb62880bd651eccee72a129","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/additional-js.pug","hash":"aca0ec7ef69b21d1f242c62fed389468a0f0e1a2","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/footer.pug","hash":"02390a5b6ae1f57497b22ba2e6be9f13cfb7acac","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/pagination.pug","hash":"4c85de4dea4dca4e5088097a79bd6d7009cbf8ef","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/head.pug","hash":"ecec62305aaa596bb1dfbb46c13d06fb5a9628cf","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/sidebar.pug","hash":"9f0e9e039f304439007460fa0a7c8ac18e0ffd37","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/layout.pug","hash":"7fa9ae4b70b87fc97e992dde5944681f92b59bea","modified":1718463162815},{"_id":"themes/butterfly/scripts/events/404.js","hash":"83cd7f73225ccad123afbd526ce1834eb1eb6a6d","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/rightside.pug","hash":"db275f7fbe4438b54cd813b695f4834e10aa234f","modified":1718463162815},{"_id":"themes/butterfly/scripts/events/comment.js","hash":"5351e0bc09e6b5b3f6d30f333a2520626a28ca3a","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_archives.pug","hash":"86897010fe71503e239887fd8f6a4f5851737be9","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_bottom_self.pug","hash":"13dc8ce922e2e2332fe6ad5856ebb5dbf9ea4444","modified":1718463162819},{"_id":"themes/butterfly/scripts/events/cdn.js","hash":"21fb5aabe043486d095c4c8cce361ed85ba88a26","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_announcement.pug","hash":"ae392459ad401a083ca51ee0b27526b3c1e1faed","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_categories.pug","hash":"d1a416d0a8a7916d0b1a41d73adc66f8c811e493","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_newest_comment.pug","hash":"7834bf7c711e739fd33cfcd0b53d151013b3d449","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_post_toc.pug","hash":"a658a274c5f7896ee5122725bee45548693bdd66","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_recent_post.pug","hash":"e5aac7b28ed4123d75797263c64e74ac547945bc","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_ad.pug","hash":"60dc48a7b5d89c2a49123c3fc5893ab9c57dd225","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_tags.pug","hash":"eceb4420a64c720f0d2741e89d6229bbb3d87353","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_webinfo.pug","hash":"35ce167c5a275211bfc1fa3d49adfde5b404d98f","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_author.pug","hash":"03c6afabbf1ac729c7fb21c7ec06da0190b0fdc7","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_top_self.pug","hash":"ae67c6d4130a6c075058a9c1faea1648bcc6f83e","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/index.pug","hash":"66f7a8b0cebc05c575ec3cb70b08d6854029d87a","modified":1718463162819},{"_id":"themes/butterfly/source/css/_global/function.styl","hash":"f19694a42dbe28eda4b39a1696e8fbcd277bc76c","modified":1718463162819},{"_id":"themes/butterfly/source/css/_highlight/highlight.styl","hash":"4dcd468e4d11a0ac75406162678feffcd89fee00","modified":1718463162819},{"_id":"themes/butterfly/source/css/_global/index.styl","hash":"c8ff6ddd5bfe1190b7b8056b68ce41114fd79dcb","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/widget/card_post_series.pug","hash":"bd5ad01277f8c6ddf8a3a29af1518e5fe6eed23f","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/comments.styl","hash":"134811b2d696f9ed2c0cd578f3886f1c60770c0a","modified":1718463162819},{"_id":"themes/butterfly/source/css/_highlight/theme.styl","hash":"bcd384c8b2aa0390c9eb69ac1abbfd1240ce1da4","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/chat.styl","hash":"f9a5d3f1fc5ed0ed2ee4c1eaa58ed650d11ddebd","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/footer.styl","hash":"83a7a70eb0532ea9c4267939fe484af915fca01e","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/aside.styl","hash":"fad650f88778b33a6358e38cf50dfafc0974d28f","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/pagination.styl","hash":"fb9f78bfbb79579f1d752cb73fb6d25c8418e0fd","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/loading.styl","hash":"ac2aeee9926f75b2a0098efe1c114126987430f2","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/relatedposts.styl","hash":"d53de408cb27a2e704aba7f7402b7caebe0410d8","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/post.styl","hash":"a2eb44fa5eaea1325319a2064439cf36d0f35a2f","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/head.styl","hash":"18d08be0cd9b1f8c049d4b922e80f8163a55c947","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/reward.styl","hash":"d6cf26ffb8a0343eda1cde65b6b73b0ddbe8fcfc","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/rightside.styl","hash":"f845b9b4efdee750f70c023aab27432611f83059","modified":1718463162819},{"_id":"themes/butterfly/source/css/_layout/sidebar.styl","hash":"b7a6a585dbc38d177c9aba75df3a467415d0488a","modified":1718463162819},{"_id":"themes/butterfly/source/css/_page/categories.styl","hash":"f01ee74948cedb44e53cd3bb1ef36b7d2778ede7","modified":1718463162823},{"_id":"themes/butterfly/source/css/_layout/third-party.styl","hash":"5556c9bf4f53a90cb9b4945cd76a8849bd67f3f3","modified":1718463162819},{"_id":"themes/butterfly/source/css/_mode/readmode.styl","hash":"e549d24ad81a7d93326a509ff8dcfcc58c80729e","modified":1718463162819},{"_id":"themes/butterfly/source/css/_mode/darkmode.styl","hash":"0db591a1f4ed5adcb8668a549bbee5c9d62682cf","modified":1718463162819},{"_id":"themes/butterfly/source/css/_page/404.styl","hash":"50dbb9e6d98c71ffe16741b8c1b0c1b9771efd2b","modified":1718463162823},{"_id":"themes/butterfly/source/css/_page/common.styl","hash":"4e320e16d49bc18085045937681f7331a1e243ca","modified":1718463162823},{"_id":"themes/butterfly/source/css/_page/archives.styl","hash":"c9e98027f2dd730ce389c2047f62ebb748955fcf","modified":1718463162823},{"_id":"themes/butterfly/scripts/events/stylus.js","hash":"e196a99733d7f90899bceed5d12488e8234817d5","modified":1718463162819},{"_id":"themes/butterfly/scripts/events/merge_config.js","hash":"2ac43fd4103ba3c6897da7c13015cb05f39fd695","modified":1718463162819},{"_id":"themes/butterfly/scripts/events/init.js","hash":"428b94c7b9e83f7ea36227dee66bfe3c23aee4a8","modified":1718463162819},{"_id":"themes/butterfly/scripts/events/welcome.js","hash":"8ad9911b755cba13dde2cc055c3f857a6b0dd20e","modified":1718463162819},{"_id":"themes/butterfly/scripts/filters/post_lazyload.js","hash":"860f967ecf3c6a6ea785b560a7aae4d0757cd18a","modified":1718463162819},{"_id":"themes/butterfly/scripts/filters/random_cover.js","hash":"a8eef3f37428436554f58a2b6bac7c255fbdf38d","modified":1718463162819},{"_id":"themes/butterfly/scripts/helpers/aside_archives.js","hash":"2ec66513d5322f185d2071acc052978ba9415a8e","modified":1718463162819},{"_id":"themes/butterfly/scripts/helpers/aside_categories.js","hash":"96f861151e3b889ef0ffe78821d489ad2625ee43","modified":1718463162819},{"_id":"themes/butterfly/scripts/helpers/findArchiveLength.js","hash":"7caf549810f971c34196fb9deac2d992545bdff9","modified":1718463162819},{"_id":"themes/butterfly/scripts/helpers/page.js","hash":"e2a8a09bfe47da26eab242a36f516e6c452c799a","modified":1718463162819},{"_id":"themes/butterfly/scripts/helpers/inject_head_js.js","hash":"d5c7e61257b08a9648404f6f48ce4d471cd5fa55","modified":1718463162819},{"_id":"themes/butterfly/scripts/helpers/related_post.js","hash":"4677be4175da6800c0b3b8c1614e593f73df8831","modified":1718463162819},{"_id":"themes/butterfly/scripts/helpers/series.js","hash":"821e973d41f7b3b64cde91e0e836ea49c43e3c06","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/button.js","hash":"93229d44b35b9da92e647b89d6d3087085974a29","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/flink.js","hash":"ab62919fa567b95fbe14889517abda649991b1ee","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/gallery.js","hash":"418684993a3a3a2ac534257a2d9ecbcead6808c1","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/hide.js","hash":"365db87ddfc582bf8c15cb440c48bed95106e4b1","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/inlineImg.js","hash":"512c68a22ae4a58d6a6b24b368a0c00c2ccb4fcb","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/label.js","hash":"19773218877281ccffed921431e87148413a7c20","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/mermaid.js","hash":"5c2a07df5874b5377540884e4da14dd21489378f","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/note.js","hash":"1acefc59ead75ebd8cafee36efc7da4fa426d088","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/score.js","hash":"5cb273e95846874e3a58074074c501df23c5e912","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/series.js","hash":"830b1d592278b9f676df0cf9a91b1eeda2456aec","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/tabs.js","hash":"ffc62222f8d7b4d44c1c0726c8a08824a2201039","modified":1718463162819},{"_id":"themes/butterfly/scripts/tag/timeline.js","hash":"4526c75e5bf84609d67e92b6af3524bcb278e852","modified":1718463162819},{"_id":"themes/butterfly/source/css/index.styl","hash":"755490867fd8afe47d5cce24faea2ca172b0c4dd","modified":1718463162823},{"_id":"themes/butterfly/source/css/var.styl","hash":"152b6bd4b6285165541a71f5a1c913f8ee6a602b","modified":1718463162823},{"_id":"themes/butterfly/source/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1718463162823},{"_id":"themes/butterfly/source/img/favicon.png","hash":"3cf89864b4f6c9b532522a4d260a2e887971c92d","modified":1718463162823},{"_id":"themes/butterfly/source/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1718463162823},{"_id":"themes/butterfly/source/js/main.js","hash":"0dac585446445e0c419b86eec5580bc9b0657dc6","modified":1718463162823},{"_id":"themes/butterfly/source/js/tw_cn.js","hash":"f8d2e3f31468991a7f5171cbfdb157dfb86d3372","modified":1718463162823},{"_id":"themes/butterfly/source/js/utils.js","hash":"8e6b48d294e7aeaba8ff6348c43b2271cf865547","modified":1718463162823},{"_id":"themes/butterfly/source/css/_search/algolia.styl","hash":"649a054e73278b6724bd4dd9b94724791ec5c928","modified":1718463162823},{"_id":"themes/butterfly/source/css/_page/homepage.styl","hash":"d4ebc41b5c855dd75f47de7345d62f85ce7cf073","modified":1718463162823},{"_id":"themes/butterfly/source/css/_search/index.styl","hash":"20a3134e1302b62bfc881f4ec43f398267111f22","modified":1718463162823},{"_id":"themes/butterfly/source/css/_page/tags.styl","hash":"580feb7e8b0822a1be48ac380f8c5c53b1523321","modified":1718463162823},{"_id":"themes/butterfly/source/css/_search/local-search.styl","hash":"961589da3c0a532c4709a4a4ea96bd579257f766","modified":1718463162823},{"_id":"themes/butterfly/source/css/_tags/button.styl","hash":"45f0c32bdea117540f6b14ebac6450d7142bd710","modified":1718463162823},{"_id":"themes/butterfly/source/css/_tags/hexo.styl","hash":"d76c38adf1d9c1279ef4241835667789f5b736e0","modified":1718463162823},{"_id":"themes/butterfly/source/css/_tags/gallery.styl","hash":"5cddbb5f4eae695a26685e415d821b523e0f17bf","modified":1718463162823},{"_id":"themes/butterfly/source/css/_tags/hide.styl","hash":"ce489ca2e249e2a3cf71584e20d84bdb022e3475","modified":1718463162823},{"_id":"themes/butterfly/source/css/_tags/inlineImg.styl","hash":"df9d405c33a9a68946b530410f64096bcb72560c","modified":1718463162823},{"_id":"themes/butterfly/source/css/_tags/label.styl","hash":"66c59e193d794cdb02cca7bd1dc4aea5a19d7e84","modified":1718463162823},{"_id":"themes/butterfly/source/css/_page/flink.styl","hash":"98d755b686ee833e9da10afaa40c4ec2bd66c19a","modified":1718463162823},{"_id":"themes/butterfly/source/css/_tags/note.styl","hash":"909bb5079b26b6ee68177919f522566503654058","modified":1718463162823},{"_id":"themes/butterfly/source/css/_tags/tabs.styl","hash":"2d02e52b360f6e6cae47c293ae57ed78e2554663","modified":1718463162823},{"_id":"themes/butterfly/source/css/_tags/timeline.styl","hash":"f071156d439556e7463ed4bc61ceee87170d5d08","modified":1718463162823},{"_id":"themes/butterfly/source/js/search/algolia.js","hash":"108988d046da9a4716148df43b3975217c8ceaae","modified":1718463162823},{"_id":"themes/butterfly/source/js/search/local-search.js","hash":"e1f60ebac53a3f596fd0a4769b4f9275c48c6542","modified":1718463162823},{"_id":"themes/butterfly/layout/includes/third-party/abcjs/abcjs.pug","hash":"f7299f9fef5bf94bb58c8cd3be8ee660ad2f9cd4","modified":1718463162815},{"_id":"themes/butterfly/source/css/_third-party/normalize.min.css","hash":"2c18a1c9604af475b4749def8f1959df88d8b276","modified":1718463162823},{"_id":"themes/butterfly/layout/includes/third-party/abcjs/index.pug","hash":"f58f1648d2d71311bafca4833f20b605bb5f18c8","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/index.pug","hash":"b2d274db84ef22fbd6d5ea8f4404821898934209","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/disqus.pug","hash":"c5f7081ca29db8cc80f808dfc29e36d5fa22fd7e","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/artalk.pug","hash":"71af0b679e00290b0854384368b3c7e9b3e5f26a","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/fb.pug","hash":"0344477a2cf38698318ead2681c63ac12f01586e","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/remark42.pug","hash":"001e8be47854b891efe04013c240c38fed4185eb","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/twikoo.pug","hash":"56c028ba0ea8fac19f0125114d765dfc56ce2b48","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/waline.pug","hash":"3a5ccfc69bd8ccb4b8f3ce3502023f7914f2a022","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/card-post-count/valine.pug","hash":"39427e107230a10790972349c9dd4c4f31d55eb7","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/chat/index.pug","hash":"618e1b7f9204049b07beb9e1363c844a78a9ace3","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/chat/crisp.pug","hash":"2fb098a7aa45010a8cd212dc0bd5308c6e7c63e3","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/chat/daovoice.pug","hash":"9b57a8e13de8fc51a5f550854e47164fd8ac1be8","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/chat/chatra.pug","hash":"ddce8352b371a1fb426bdb6c33f587eb37a69647","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/chat/messenger.pug","hash":"e39a9c37adf4cb15a2ba3b2cc65542ffea88650d","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/chat/tidio.pug","hash":"dd61eca6e9a45f63e09bdefba89fe285a81ba096","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/artalk.pug","hash":"f77f0fdeac2bc8a72f71a58f9b75aa39f0a108c8","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/disqus.pug","hash":"62f16a602e57e5f7f7c5249dd37b42d436dc032a","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/gitalk.pug","hash":"0d378ee8a671982a46213a4bfb223b4f3409aea9","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/disqusjs.pug","hash":"3bc4c1b91568561f0491bdac65b75aa0bfd01f27","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/giscus.pug","hash":"2d7b0b09678adba09481e3152e0b32962677f650","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/facebook_comments.pug","hash":"46aec6466959baec1c3d71a5dbc510fbeb00c91d","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/index.pug","hash":"a9709905593d960954e2dd572f09f48a6c2b1ef7","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/js.pug","hash":"00ed91c52939b9675b316137f854d13684c895a6","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/livere.pug","hash":"63cea2b5c8f7b59f5919379d61a2bb2ce8ed7623","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/remark42.pug","hash":"f15699abb8c7a255aabad0222ae53eee387c66a3","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/twikoo.pug","hash":"5c29b5887e2e6cd81e1f13b32da53d9c139b788b","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/valine.pug","hash":"46865e3f52096acb07d0212174b4e8751b123aea","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/utterances.pug","hash":"1995a654ba7ad62775a0a6e2922209cd1a85f2e3","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/comments/waline.pug","hash":"7aa443b4881448979b810864e206e58c9ed787e3","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/math/katex.pug","hash":"dfcbd9881be569ea420eff1a6b00e4f4dbe2138e","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/math/mermaid.pug","hash":"6b67982bb7a3713b5bffd6a23ba2810425c504d0","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/math/mathjax.pug","hash":"fc072ac839401174b5d3cf9acd3b694246c23a55","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/math/index.pug","hash":"b8ae5fd7d74e1edcef21f5004fc96147e064d219","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/artalk.pug","hash":"17080aba1754478197ab089f7948ed900f116d2b","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/disqus-comment.pug","hash":"2609bc2656aaaa9b59e8d575e711776512a62192","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/github-issues.pug","hash":"0f0b46d637a9a1b6ae35148923abecc80b866276","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/index.pug","hash":"4ec0642f2d5444acfab570a6f8c7868e7ff43fde","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/valine.pug","hash":"1f9f51023e9e33081c2add2ca73643c0edc5e9d5","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/twikoo-comment.pug","hash":"4104f96faa6040f111ebfb9a90eeb470857c3b86","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/remark42.pug","hash":"de2c4d02b520dd49a0a59fc0f33295e5bbb2c624","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/newest-comments/waline.pug","hash":"24804ab6da9727ed793655c1262fa3f1a9746f70","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/search/algolia.pug","hash":"9c3c109a12d2b6916e8b4965cca12f521510ead9","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/search/index.pug","hash":"a99a41334387ee9a46c6f8e8212331a29a10d159","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/search/local-search.pug","hash":"3335024ba91f55ccf3858571b7898f46881c455c","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/search/docsearch.pug","hash":"b928be14d1b47a9fadb1bcc5f5072a7328752d4b","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/share/addtoany.pug","hash":"85c92f8a7e44d7cd1c86f089a05be438535e5362","modified":1718463162819},{"_id":"themes/butterfly/source/css/_highlight/highlight/diff.styl","hash":"cf1fae641c927621a4df1be5ca4a853b9b526e23","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/share/index.pug","hash":"3ba49cfe186e9ca05faf9f0d0113611ec47e9b38","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/share/share-js.pug","hash":"c7dd2b2ae9b23aa0a60fffd7df9e9f76ef52033e","modified":1718463162819},{"_id":"themes/butterfly/source/css/_highlight/highlight/index.styl","hash":"18804c58239d95798fa86d0597f32d7f7dd30051","modified":1718463162819},{"_id":"themes/butterfly/source/css/_highlight/prismjs/diff.styl","hash":"5972c61f5125068cbe0af279a0c93a54847fdc3b","modified":1718463162819},{"_id":"themes/butterfly/source/css/_highlight/prismjs/line-number.styl","hash":"25914321762e30aacc610bc4dfb9de3e1cb556a3","modified":1718463162819},{"_id":"themes/butterfly/source/css/_highlight/prismjs/index.styl","hash":"5dc2e0bcae9a54bfb9bdcc82d02ae5a3cf1ca97d","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/head/Open_Graph.pug","hash":"8aa8d799aedbfd811195b84a451bc4b6e2647c12","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/head/analytics.pug","hash":"67e1c3b48e4ca7ee0b2c76d3ca7476b9883cf105","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/head/config.pug","hash":"63fed4548367a3663cdbaffa1df48167b0a2397b","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/head/config_site.pug","hash":"7df90c8e432e33716517ab918b0a125bc284041b","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/head/preconnect.pug","hash":"5208fe1e75d97a05fd9bdd6cc53c59d8b741b94b","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/head/pwa.pug","hash":"3d492cfe645d37c94d30512e0b230b0a09913148","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/head/google_adsense.pug","hash":"95a37e92b39c44bcbea4be7e29ddb3921c5b8220","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/head/site_verification.pug","hash":"e2e8d681f183f00ce5ee239c42d2e36b3744daad","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/header/index.pug","hash":"944d6e9dd50df3395f3a2c7ad9db667d50dea4ed","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/header/menu_item.pug","hash":"31346a210f4f9912c5b29f51d8f659913492f388","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/header/nav.pug","hash":"f61659aa457d1a2d1baa3a13157996cfac4d6609","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/header/social.pug","hash":"5de9a82032cdad1db3b868b797460921cd775fc2","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/header/post-info.pug","hash":"f50e6a17073677933c5bc78481bf587a4a9e6da0","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/loading/fullpage-loading.pug","hash":"9e8c5788602b29a527ef35fe8a20076a5fa969bd","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/loading/index.pug","hash":"131f344d68b4c241d6e03849b243ee792fcd3cea","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/loading/pace.pug","hash":"6ab4e301c92586505d6cddce1b3ad23b7c79010d","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/mixins/article-sort.pug","hash":"90554c2ca5ba946f4c02e1bc5fe2859cef1b1594","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/mixins/post-ui.pug","hash":"6f310ca7b392021632b987557607d5b6d18052bb","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/post/post-copyright.pug","hash":"5574804fdea5edf7fd52aad2caf030614d5e7f2f","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/post/reward.pug","hash":"a096ff8eb6b2a22395be881f827ff2a686ba5596","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/aplayer.pug","hash":"c7cfade2b160380432c47eef4cd62273b6508c58","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/effect.pug","hash":"1d39670ee6225f85f5c53bf5c84f3fd6e19290e8","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/third-party/pangu.pug","hash":"0f024e36b8116118233e10118714bde304e01e12","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/pjax.pug","hash":"12e57491e94fa00d953bbda9db0b6d6169e2358c","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/prismjs.pug","hash":"ffb9ea15a2b54423cd4cd441e2d061b8233e9b58","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/third-party/subtitle.pug","hash":"8044b9c18b34b019ffe26b7383e7e80356b5e4b5","modified":1718463162819},{"_id":"themes/butterfly/layout/includes/page/categories.pug","hash":"5276a8d2835e05bd535fedc9f593a0ce8c3e8437","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/page/default-page.pug","hash":"12c65c174d26a41821df9bad26cdf1087ec5b0ca","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/page/flink.pug","hash":"f9ce83978b217a71a2eb8761dc14b09866faa3f4","modified":1718463162815},{"_id":"themes/butterfly/layout/includes/page/tags.pug","hash":"9621991359e22b14049346f1cf87bdedc94edf5a","modified":1718463162815},{"_id":"public/atom.xml","hash":"0ed9df1c414babf36db89a13f5b9948d8473ab25","modified":1718522348024},{"_id":"public/search.xml","hash":"11d6f35e8e522227c1e63e7fb403abef08c4b504","modified":1718510864801},{"_id":"public/404.html","hash":"63af05ea75fb14957e19a5ca077a3243122315bb","modified":1718522348024},{"_id":"public/categories/index.html","hash":"c0bb9bc4e5bb52373a34c2fb715216f16cc0bc24","modified":1718522348024},{"_id":"public/tags/index.html","hash":"d7a908396c69b281ff1d8f29daabee5da9df3240","modified":1718522348024},{"_id":"public/2023/01/01/2022年终总结/index.html","hash":"9c73fe85099ba5e6fcf055af84298418f68a4360","modified":1718522348024},{"_id":"public/archives/index.html","hash":"e2169a3e51a425d3048bc2498c3cff649e1c2eb7","modified":1718522348024},{"_id":"public/archives/2023/index.html","hash":"965e014600930343a381c16eda7f2c091cde960e","modified":1718522348024},{"_id":"public/archives/2023/01/index.html","hash":"11a7563e2b7248af2893d154f804f1bb27faa20f","modified":1718522348024},{"_id":"public/categories/年终总结/index.html","hash":"b494d1f944440117961fd28333c5c9f99ac2225c","modified":1718522348024},{"_id":"public/tags/生活/index.html","hash":"94b395ef1690bc44fac31be4352b84640d1012e5","modified":1718522348024},{"_id":"public/index.html","hash":"7d3d30b184ce08e139b42b440c36ce9883ed6948","modified":1718522348024},{"_id":"public/tags/工作/index.html","hash":"98dda19babfea26e7934d3706e40b4370656aea5","modified":1718522348024},{"_id":"public/img/404.jpg","hash":"fb4489bc1d30c93d28f7332158c1c6c1416148de","modified":1718471115997},{"_id":"public/img/favicon.png","hash":"3cf89864b4f6c9b532522a4d260a2e887971c92d","modified":1718471115997},{"_id":"public/img/friend_404.gif","hash":"8d2d0ebef70a8eb07329f57e645889b0e420fa48","modified":1718471115997},{"_id":"public/css/index.css","hash":"af3f925766b9d943cfa511e4f59f84846459cf7e","modified":1718471115997},{"_id":"public/css/var.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1718471115997},{"_id":"public/js/utils.js","hash":"8e6b48d294e7aeaba8ff6348c43b2271cf865547","modified":1718471115997},{"_id":"public/js/tw_cn.js","hash":"f8d2e3f31468991a7f5171cbfdb157dfb86d3372","modified":1718471115997},{"_id":"public/js/main.js","hash":"0dac585446445e0c419b86eec5580bc9b0657dc6","modified":1718471115997},{"_id":"public/js/search/algolia.js","hash":"108988d046da9a4716148df43b3975217c8ceaae","modified":1718471115997},{"_id":"public/js/search/local-search.js","hash":"e1f60ebac53a3f596fd0a4769b4f9275c48c6542","modified":1718471115997},{"_id":"source/_posts/DM-数据旅程-00：序言.md","hash":"0b1c9abd77647339f68eeda308089a61338c3a46","modified":1718521427893},{"_id":"public/2023/01/03/DM-数据旅程-00：序言/index.html","hash":"107b9bed8cebac51de50c9c6ce08e6c1f35c82cc","modified":1718522348024},{"_id":"public/tags/DM-源码阅读/index.html","hash":"553a6c5e7c63b8a432087c8f21a18ef273e45571","modified":1718474483817},{"_id":"source/_posts/DM-数据旅程-01：第一次-start-task.md","hash":"83903e92d9a0364c886238a07fd2b11980288c11","modified":1718521949395},{"_id":"public/2023/01/03/DM-数据旅程-01：第一次-start-task/index.html","hash":"02a50eb8b50fcfa0561c8aa969ed73f278ae74ae","modified":1718522348024},{"_id":"public/categories/DM-数据旅程/index.html","hash":"f8b46791aea99158308ae32279b27a49328195bb","modified":1718522348024},{"_id":"public/tags/DM/index.html","hash":"ff2c70179c35e4364505dc5d0895fd2b71fa061e","modified":1718522348024},{"_id":"public/tags/源码阅读/index.html","hash":"146a3c8b546f6d1b3e0b7e6e72f65c079abb3152","modified":1718522348024},{"_id":"source/_posts/DM-数据旅程-01：第一次-start-taskasdfsd.md","hash":"aecd4adf32c0a4fad664d60b8637678467b98b01","modified":1718509233930},{"_id":"public/2023/01/03/DM-数据旅程-01：第一次-start-taskasdfsd/index.html","hash":"9e5114cb90147de9c36188695cddc5279c820fe1","modified":1718510068282},{"_id":"source/_posts/DM-数据旅程-02：分库分表悲观协调——02Lock-Resolve-Lock.md","hash":"6efe70ae74a10ac816c54df06f631f2aa7115687","modified":1718521164542},{"_id":"public/2023/01/03/DM-数据旅程-02：分库分表悲观协调——02Lock-Resolve-Lock/index.html","hash":"70b7dc374d5d9e8f9bbbcef43a10ec1ec4e27098","modified":1718522348024},{"_id":"source/_posts/DM-数据旅程-02：分库分表悲观协调——03reSync.md","hash":"fe8c2d96dffe9f5eeb09668a3e8124f7d3ef8af2","modified":1718521214111},{"_id":"public/2024/06/16/DM-数据旅程-02：分库分表悲观协调——03reSync/index.html","hash":"ddb3f8fd0fb8d82ad11c408794b4262f91e086fb","modified":1718510326277},{"_id":"public/archives/2024/index.html","hash":"ade5c83226994bf5a426c62fe910cd1ade8b4aa6","modified":1718510326277},{"_id":"public/archives/2024/06/index.html","hash":"9e0c6a1ac481d1e3265a0e992b9bd944e3ddc8d4","modified":1718510326277},{"_id":"public/2023/01/03/DM-数据旅程-02：分库分表悲观协调——03reSync/index.html","hash":"94ec463fa55fa8ae6e64d07c6c929ae312f08414","modified":1718522348024},{"_id":"source/_posts/DM-数据旅程-02：分库分表悲观协调——01准备过程.md","hash":"a56bc2ea0eb1314c0e75e639eccbb57940f9b6fb","modified":1718521804519},{"_id":"public/2023/01/03/DM-数据旅程-02：分库分表悲观协调——01准备过程/index.html","hash":"65754687493e48a685156d3240021114a57d15b7","modified":1718522348024}],"Category":[{"name":"年终总结","_id":"clxgdbzom0003xbdyhftahxry"},{"name":"DM 数据旅程","_id":"clxgfdvel0004fhdyg0rb7wuq"}],"Data":[],"Page":[{"title":"404 Not Found","date":"2021-03-08T02:41:27.000Z","_content":"\n<center>\n对不起，您所访问的页面不存在或者已删除。\n您可以<a href=\"https://okjiang.github.io>\">点击此处</a>返回首页。\n</center>\n\n<blockquote class=\"blockquote-center\">\n    okJiang\n</blockquote>","source":"404.md","raw":"---\ntitle: 404 Not Found\ndate: 2021-03-08 10:41:27\n---\n\n<center>\n对不起，您所访问的页面不存在或者已删除。\n您可以<a href=\"https://okjiang.github.io>\">点击此处</a>返回首页。\n</center>\n\n<blockquote class=\"blockquote-center\">\n    okJiang\n</blockquote>","updated":"2024-06-15T14:36:14.094Z","path":"404.html","comments":1,"layout":"page","_id":"clxgdbzoe0000xbdydomgf618","content":"<center>\n对不起，您所访问的页面不存在或者已删除。\n您可以<a href=\"https://okjiang.github.io>\">点击此处</a>返回首页。\n</center>\n\n<blockquote class=\"blockquote-center\">\n    okJiang\n</blockquote>","site":{"data":{}},"cover":false,"length":39,"excerpt":"","more":"<center>\n对不起，您所访问的页面不存在或者已删除。\n您可以<a href=\"https://okjiang.github.io>\">点击此处</a>返回首页。\n</center>\n\n<blockquote class=\"blockquote-center\">\n    okJiang\n</blockquote>"},{"title":"categories","date":"2023-01-01T11:33:56.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2023-01-01 19:33:56\ntype: categories\ncomments: false\n---\n","updated":"2024-06-15T14:36:14.094Z","path":"categories/index.html","layout":"page","_id":"clxgdbzok0002xbdy4qg22tn9","content":"","site":{"data":{}},"cover":false,"length":0,"excerpt":"","more":""},{"title":"tags","date":"2023-01-01T11:33:42.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2023-01-01 19:33:42\ntype: tags\ncomments: false\n---\n","updated":"2024-06-15T14:36:14.094Z","path":"tags/index.html","layout":"page","_id":"clxgdbzon0005xbdy5lm4cqcq","content":"","site":{"data":{}},"cover":false,"length":0,"excerpt":"","more":""}],"Post":[{"title":"2022年终总结——幸运开心的一年","date":"2023-01-01T12:00:52.000Z","_content":"\n第一次写年终总结呀，尝试记录一下。一年下来还真发生了不少事。看看自己有啥收获有啥成长。\n\n## 工作\n\n先说说工作吧。从南大毕业后，我去了 PingCAP（贵司）工作，现在在贵司的 DM（Data Migration）团队工作，差不多就在数据导入、数据迁移以及其对应的云上版本这些地方搬砖。去年就有在贵司实习，主要在维护 DM，也就是怎么把一条 binlog 写到下游 TiDB 里面，和 MySQL binlog 打交道比较多。今年入职后，顺应公司的战略，主要在 tidbcloud.com 上 CRUD，帮助用户在 cloud 上导入或迁移数据，和 k8s、CRUD 以及用户体验打交道比较多。\n\n简单总结一下学到的东西吧，从实习到现在：\n\n1. 单元测试、集成测试\n2. 多线程代码\n3. review 代码\n4. 写设计文档\n5. 理解一个需求是任何工作的第一步\n6. 对一个需求进行项目管理，以尽可能地按时交付（当然现在还做的不够好。。。）\n7. 学习了 K8s/CRD/Operator/AWS/Pulumi 相关的知识，能看懂代码，并编写简单的代码\n8. 更多地考虑用户体验\n9. 。。\n\n再谈谈工作的感受。对于我这第一份正式的工作，我是非常满意我当前的团队和公司的。不论是公司还是团队内，大佬非常多，可以在他们身上学到很多东西。团队内的人大家实事求是、互相帮助，我是没有遇到什么尔虞我诈，为了利益起冲突的情况，很 nice！虽然很多人诟病贵司已经不是以前的贵司了，之前的工程师文化没有那么纯粹了，但我还是帮公司说句话。今年 2022 年的环境大家还是可以看得到的，同样以工程师文化著称的小马，已经把 22 届大部分的应届生裁掉了，我有同学就在被裁名单里。所以对于一个同样是应届生的我，我还是很佩服公司的战略和定力，以帮助公司继续生存下去，毕竟活下去才有未来。我知道这两者也并不是冲突的，但我还是庆幸公司能让我有一个地方学习和成长。当然，大家也都会希望自己的公司能越来越好！\n\n记录一下：今年 1 月份全组人员齐聚北京团（mian）建（ji），第一次正式见到了来自成都、北京、杭州、上海的各位大佬，也跟着 mentor 没羞没臊地蹭吃蹭喝玩了两天哈哈。不得不说，太爽了哈哈哈🐶。\n\n## 学生生涯\n\n今年终于从硕士毕业了。坦诚地对硕士这三年做个简短的总结吧。自己在三年中几乎没有任何的成果，连一篇论文都没发过，在科研这条路上，我也算的上是彻底失败了。不过这三年比较幸运的是，我在研一下就意识到了自己不适合走科研这条路，所以花了很多时间在思考和实践自己以后要做什么这个问题上。也找到了自认为短中期内发展还不错的数据库这条道路。\n\n> 在读书期间，经常和同学调侃，读研最大的作用，就是发现了读研没用。哈哈哈，这句话可能有点过，但也是只有读研后，才能理解很多大佬说的，「国内的研究有些浮躁」中**浮躁**的含义吧（叹息）\n\n## 生活\n\n在毕业后，正式开启了我自己的生活。这一次和我之前的实习都不一样，我第一次拒绝了合租，选择了一个人整租一个小区里的一室一厅。在省钱和生活质量中选择了后者。当时在来广州之前就疯狂地看房，幻想着自己一个人自由的生活哈哈哈。来了广州之后就疯狂地找房子，一室一厅的小区房实在是太少了🤮。我遇到一个 2500/月 60 平的房子，下午 2 点看完饭，下午 4 点就被租出去了！就是被我后面一个看房的人租走了。。。这效率简直了。最后租到了一间 3000 出头的一室一厅，房东非常 nice，给配了新的马桶、电热水器、空调、抽油烟机和灶台，甚至还重新装修了厨房！虽然还有不足的地方，但我已经非常满足了！\n\n### 添置新物件\n\n#### 大桌子✅\n\n在自己租了房子之后，必然也是要整一个正经的小书桌的啦。在闲鱼上蹲了好几天，中间还去旁边的二手市场看了，最后花 220 蹲到了这张 160✖️70 的桌子（货拉拉都花了 100+ 😂）\n\n[![tk3cN.th.jpeg](https://i.328888.xyz/2023/01/02/tk3cN.th.jpeg)](https://imgloc.com/i/tk3cN)\n\n#### 洞洞板✅\n\n看 B 站视频还看到了这种立式的洞洞板，想到出租屋里也完全没有书架、小物件的收纳什么的，就整了一个。还行哈，比光秃秃的好多了。\n\n[![tkHFX.th.jpeg](https://i.328888.xyz/2023/01/02/tkHFX.th.jpeg)](https://imgloc.com/i/tkHFX)\n\n#### 人体工学椅✅\n\n毕竟工作需要，立马也整了个好椅子，可以用很久了\n\n[![t0jdv.th.jpeg](https://i.328888.xyz/2023/01/02/t0jdv.th.jpeg)](https://imgloc.com/i/t0jdv)\n\n#### 牙套✅\n\n从很多年前自己就觉得自己的牙齿不齐，想要做牙齿矫正，但无奈因为钱或者长住地不稳定等原因，一直没开始。所以在广州安顿下来之后，立马开始了牙齿矫正的进程。上下左右拔了 4 颗牙！妈耶，疼死我了。\n\n#### 打击垫✅\n\n我自己对音乐也一直挺感兴趣的，哈哈就想做点音乐相关的爱好。之前有关注一个绝地的主播，他玩的打击垫超酷！现在有自己的空间和生活了，就整了一个二手的入门款。\n\n[![twO4o.th.jpeg](https://i.328888.xyz/2023/01/02/twO4o.th.jpeg)](https://imgloc.com/i/twO4o)\n\n但是非常可惜，在练完入门曲 [Luz letter](https://www.bilibili.com/video/BV1bv4y1B7RL/?spm_id_from=333.999.0.0&vd_source=1d41e3899bfb8af8d65144aad99bbde1) 后，在另外挑了一首[进阶的曲子](https://www.bilibili.com/video/BV1q8411E7ts/?spm_id_from=333.999.0.0&vd_source=1d41e3899bfb8af8d65144aad99bbde1)练习过程中就发现了问题——灯光跟不上节奏。。。这个入门款的灯光频率太低了，尝试了很多次之后还是放弃了继续在这款上面继续练，然后荒废到现在（哎，可惜。\n\n#### PS5/大电视✅\n\n在双十一的时候，收了一个二手的 PS5，还配了一个大电视！这个小出租屋也终于可以看电视了。\n\n![t0Law.jpeg](https://i.328888.xyz/2023/01/02/t0Law.jpeg)\n\n顺带评价一下老头环吧，在 PS5 上玩的第一个游戏。之前也有玩过黑魂 3，1）所以并没有第一次玩魂类游戏那种冲击了，而且老头环的难度系数相比黑魂确实低了不少，转角杀少了特别多，所以老玩家在转角处回头的时候经常“失望”哈哈哈。2）还有一个点是堆料太严重了叭，重复的遗迹，重复的 boss，重复的墓地，单一的小怪，散落在交界地的各处，完全没有什么动力去一一扫图。。。3）对于剧情，我还是知道魂类游戏的套路的——剧情都散落在各个道具上，但我真的做不到全搜集呀！😭，而且由于地图太大，剧情太散，我真的记不住各个支线呀！4）对于开放世界，由于也玩过塞尔达这种神作，只能说宫崎英高把魂元素塞到了一个开放世界中，至于这个开放世界它“开放”吗？这管我啥事。\n\n哈哈哈，吐槽完了，但还是要说我玩了几十个小时，每次一玩就是五六个小时起步，还是很不错的游戏的，只不过在后期感受到了乏味，没能成为艾尔登之王。\n\n### 做饭\n\n要有生活气息，一定离不开自己做饭！今年自己和女朋友一起做了好多好多的菜！而且少有失败，哈哈哈女票直称我为厨房小天才哈哈（也不排除她是为了让我多做饭🐶）。自己做饭真的没那么难，而且味道也比大部分城中村的外卖好吃，就是收拾厨房、洗碗什么的太麻烦了，做完饭吃完饭收拾完基本晚上就啥都不想干了只想瘫着。不知道什么时候能买个洗碗机呀。\n\n<img src=https://cdn-us.imgs.moe/2023/01/02/63b2c89a14f9a.jpg width=30% />\n\n### 看书\n\n今年看书的目标算是达到了，一共看完了 13 本书。感觉自己看书的输入效率还不够。。。还需要继续学习😂\n\n- 浪潮之巅\n- 程序员的修炼之道\n- 小王子的领悟\n- MySQL 是怎么运行的\n- 黑客与画家\n- 悉达多\n- kubernetes in action\n- 异乡人\n- 沙发上的心理学\n- 数据生态：MySQL 复制技术与生产实践\n- 宇宙的最后三分钟\n- shell 脚本基础教程\n- 枪炮、病菌与钢铁\n\n### 爱情\n\n今年是和我女朋友（以后就叫她小懒虫吧！）在一起的第一年～算是收获了梦想中甜蜜的爱情了（痴汉笑😊）。这一年我们先是度过了恋爱中最难熬的异地恋！最长有三个月的时间没有见面，可能以后都不会再有这么长时间不见面的机会了吧。\n\n今年和小懒虫度过了超级多的第一次。\n\n- 第一次收到新年礼物\n\n[![tN1da.th.jpeg](https://i.328888.xyz/2023/01/03/tN1da.th.jpeg)](https://imgloc.com/i/tN1da)\n\n- 第一次一起弹钢琴\n\n- 第一次一起旅游、看海、帆船、桨板、海边露营、日出\n\n[![tN9TV.th.jpeg](https://i.328888.xyz/2023/01/03/tN9TV.th.jpeg)](https://imgloc.com/i/tN9TV)\n\n- 第一次恐怖密室\n\n[![tNLpb.th.png](https://i.328888.xyz/2023/01/03/tNLpb.th.png)](https://imgloc.com/i/tNLpb)\n\n- 第一次通关游戏\n\n[![trjhJ.th.jpeg](https://i.328888.xyz/2023/01/03/trjhJ.th.jpeg)](https://imgloc.com/i/trjhJ)\n\n- 第一次脱口秀\n\n[![try93.th.jpeg](https://i.328888.xyz/2023/01/03/try93.th.jpeg)](https://imgloc.com/i/try93)\n\n### 疫情\n\n在 2022 年的年末，疫情终于算是“结束”了。。。在毕业前由于江苏教育局的政策「上海一天不解封，南京高校也不解封」，结果导致我们在南大被封了两个月！这让我们论文写完了，答辩完了也没有机会出校。这直接导致我在能毕业离校的第一时间离开了学校，并不带一点留恋。本来打算在南京好好玩一下的也没有时间了。异地恋的影响也在这两个月里达到了顶峰。。。真是太煎熬了。\n\n另外，从今年年底广州疫情开始，自己几乎就一直 remote 到了现在，完全改变了工作习惯。。。放开后也阳了一次，但还不算严重，也就烧了一天多，发烧的时候基本在睡觉，退烧后基本就没什么事了。\n\n我认为只要不再搞什么类似封城的事情，疫情就算是过去了。因为这是不可避免的事情呀，在读完《枪炮、病菌与钢铁》后知道，人类**从来**没有战胜过病毒。这是客观事实。一旦放开后，我们就再也回不去了，亦或者说我们瞬间就回到了过去。有病治病，挺好的。\n\n## 2023\n\n2023 年要做些什么呢？\n\n- 工作上，think more and do more\n- 读书和做饭的习惯能继续保持\n- 计划中的锻炼别拉下了，多跑步，参加一场半马\n- 楼下就有网球场，大学学的网球一定要捡起来玩玩\n- 去更多地方旅行（哈尔滨、潮汕\n- 换个好点的 launchpad 继续玩玩\n\n总之，2022 还行，2023 继续加油💪\n","source":"_posts/2022年终总结.md","raw":"---\ntitle: 2022年终总结——幸运开心的一年\ndate: 2023-01-01 20:00:52\ntags:\n- 生活\n- 工作\ncategories:\n- 年终总结\n---\n\n第一次写年终总结呀，尝试记录一下。一年下来还真发生了不少事。看看自己有啥收获有啥成长。\n\n## 工作\n\n先说说工作吧。从南大毕业后，我去了 PingCAP（贵司）工作，现在在贵司的 DM（Data Migration）团队工作，差不多就在数据导入、数据迁移以及其对应的云上版本这些地方搬砖。去年就有在贵司实习，主要在维护 DM，也就是怎么把一条 binlog 写到下游 TiDB 里面，和 MySQL binlog 打交道比较多。今年入职后，顺应公司的战略，主要在 tidbcloud.com 上 CRUD，帮助用户在 cloud 上导入或迁移数据，和 k8s、CRUD 以及用户体验打交道比较多。\n\n简单总结一下学到的东西吧，从实习到现在：\n\n1. 单元测试、集成测试\n2. 多线程代码\n3. review 代码\n4. 写设计文档\n5. 理解一个需求是任何工作的第一步\n6. 对一个需求进行项目管理，以尽可能地按时交付（当然现在还做的不够好。。。）\n7. 学习了 K8s/CRD/Operator/AWS/Pulumi 相关的知识，能看懂代码，并编写简单的代码\n8. 更多地考虑用户体验\n9. 。。\n\n再谈谈工作的感受。对于我这第一份正式的工作，我是非常满意我当前的团队和公司的。不论是公司还是团队内，大佬非常多，可以在他们身上学到很多东西。团队内的人大家实事求是、互相帮助，我是没有遇到什么尔虞我诈，为了利益起冲突的情况，很 nice！虽然很多人诟病贵司已经不是以前的贵司了，之前的工程师文化没有那么纯粹了，但我还是帮公司说句话。今年 2022 年的环境大家还是可以看得到的，同样以工程师文化著称的小马，已经把 22 届大部分的应届生裁掉了，我有同学就在被裁名单里。所以对于一个同样是应届生的我，我还是很佩服公司的战略和定力，以帮助公司继续生存下去，毕竟活下去才有未来。我知道这两者也并不是冲突的，但我还是庆幸公司能让我有一个地方学习和成长。当然，大家也都会希望自己的公司能越来越好！\n\n记录一下：今年 1 月份全组人员齐聚北京团（mian）建（ji），第一次正式见到了来自成都、北京、杭州、上海的各位大佬，也跟着 mentor 没羞没臊地蹭吃蹭喝玩了两天哈哈。不得不说，太爽了哈哈哈🐶。\n\n## 学生生涯\n\n今年终于从硕士毕业了。坦诚地对硕士这三年做个简短的总结吧。自己在三年中几乎没有任何的成果，连一篇论文都没发过，在科研这条路上，我也算的上是彻底失败了。不过这三年比较幸运的是，我在研一下就意识到了自己不适合走科研这条路，所以花了很多时间在思考和实践自己以后要做什么这个问题上。也找到了自认为短中期内发展还不错的数据库这条道路。\n\n> 在读书期间，经常和同学调侃，读研最大的作用，就是发现了读研没用。哈哈哈，这句话可能有点过，但也是只有读研后，才能理解很多大佬说的，「国内的研究有些浮躁」中**浮躁**的含义吧（叹息）\n\n## 生活\n\n在毕业后，正式开启了我自己的生活。这一次和我之前的实习都不一样，我第一次拒绝了合租，选择了一个人整租一个小区里的一室一厅。在省钱和生活质量中选择了后者。当时在来广州之前就疯狂地看房，幻想着自己一个人自由的生活哈哈哈。来了广州之后就疯狂地找房子，一室一厅的小区房实在是太少了🤮。我遇到一个 2500/月 60 平的房子，下午 2 点看完饭，下午 4 点就被租出去了！就是被我后面一个看房的人租走了。。。这效率简直了。最后租到了一间 3000 出头的一室一厅，房东非常 nice，给配了新的马桶、电热水器、空调、抽油烟机和灶台，甚至还重新装修了厨房！虽然还有不足的地方，但我已经非常满足了！\n\n### 添置新物件\n\n#### 大桌子✅\n\n在自己租了房子之后，必然也是要整一个正经的小书桌的啦。在闲鱼上蹲了好几天，中间还去旁边的二手市场看了，最后花 220 蹲到了这张 160✖️70 的桌子（货拉拉都花了 100+ 😂）\n\n[![tk3cN.th.jpeg](https://i.328888.xyz/2023/01/02/tk3cN.th.jpeg)](https://imgloc.com/i/tk3cN)\n\n#### 洞洞板✅\n\n看 B 站视频还看到了这种立式的洞洞板，想到出租屋里也完全没有书架、小物件的收纳什么的，就整了一个。还行哈，比光秃秃的好多了。\n\n[![tkHFX.th.jpeg](https://i.328888.xyz/2023/01/02/tkHFX.th.jpeg)](https://imgloc.com/i/tkHFX)\n\n#### 人体工学椅✅\n\n毕竟工作需要，立马也整了个好椅子，可以用很久了\n\n[![t0jdv.th.jpeg](https://i.328888.xyz/2023/01/02/t0jdv.th.jpeg)](https://imgloc.com/i/t0jdv)\n\n#### 牙套✅\n\n从很多年前自己就觉得自己的牙齿不齐，想要做牙齿矫正，但无奈因为钱或者长住地不稳定等原因，一直没开始。所以在广州安顿下来之后，立马开始了牙齿矫正的进程。上下左右拔了 4 颗牙！妈耶，疼死我了。\n\n#### 打击垫✅\n\n我自己对音乐也一直挺感兴趣的，哈哈就想做点音乐相关的爱好。之前有关注一个绝地的主播，他玩的打击垫超酷！现在有自己的空间和生活了，就整了一个二手的入门款。\n\n[![twO4o.th.jpeg](https://i.328888.xyz/2023/01/02/twO4o.th.jpeg)](https://imgloc.com/i/twO4o)\n\n但是非常可惜，在练完入门曲 [Luz letter](https://www.bilibili.com/video/BV1bv4y1B7RL/?spm_id_from=333.999.0.0&vd_source=1d41e3899bfb8af8d65144aad99bbde1) 后，在另外挑了一首[进阶的曲子](https://www.bilibili.com/video/BV1q8411E7ts/?spm_id_from=333.999.0.0&vd_source=1d41e3899bfb8af8d65144aad99bbde1)练习过程中就发现了问题——灯光跟不上节奏。。。这个入门款的灯光频率太低了，尝试了很多次之后还是放弃了继续在这款上面继续练，然后荒废到现在（哎，可惜。\n\n#### PS5/大电视✅\n\n在双十一的时候，收了一个二手的 PS5，还配了一个大电视！这个小出租屋也终于可以看电视了。\n\n![t0Law.jpeg](https://i.328888.xyz/2023/01/02/t0Law.jpeg)\n\n顺带评价一下老头环吧，在 PS5 上玩的第一个游戏。之前也有玩过黑魂 3，1）所以并没有第一次玩魂类游戏那种冲击了，而且老头环的难度系数相比黑魂确实低了不少，转角杀少了特别多，所以老玩家在转角处回头的时候经常“失望”哈哈哈。2）还有一个点是堆料太严重了叭，重复的遗迹，重复的 boss，重复的墓地，单一的小怪，散落在交界地的各处，完全没有什么动力去一一扫图。。。3）对于剧情，我还是知道魂类游戏的套路的——剧情都散落在各个道具上，但我真的做不到全搜集呀！😭，而且由于地图太大，剧情太散，我真的记不住各个支线呀！4）对于开放世界，由于也玩过塞尔达这种神作，只能说宫崎英高把魂元素塞到了一个开放世界中，至于这个开放世界它“开放”吗？这管我啥事。\n\n哈哈哈，吐槽完了，但还是要说我玩了几十个小时，每次一玩就是五六个小时起步，还是很不错的游戏的，只不过在后期感受到了乏味，没能成为艾尔登之王。\n\n### 做饭\n\n要有生活气息，一定离不开自己做饭！今年自己和女朋友一起做了好多好多的菜！而且少有失败，哈哈哈女票直称我为厨房小天才哈哈（也不排除她是为了让我多做饭🐶）。自己做饭真的没那么难，而且味道也比大部分城中村的外卖好吃，就是收拾厨房、洗碗什么的太麻烦了，做完饭吃完饭收拾完基本晚上就啥都不想干了只想瘫着。不知道什么时候能买个洗碗机呀。\n\n<img src=https://cdn-us.imgs.moe/2023/01/02/63b2c89a14f9a.jpg width=30% />\n\n### 看书\n\n今年看书的目标算是达到了，一共看完了 13 本书。感觉自己看书的输入效率还不够。。。还需要继续学习😂\n\n- 浪潮之巅\n- 程序员的修炼之道\n- 小王子的领悟\n- MySQL 是怎么运行的\n- 黑客与画家\n- 悉达多\n- kubernetes in action\n- 异乡人\n- 沙发上的心理学\n- 数据生态：MySQL 复制技术与生产实践\n- 宇宙的最后三分钟\n- shell 脚本基础教程\n- 枪炮、病菌与钢铁\n\n### 爱情\n\n今年是和我女朋友（以后就叫她小懒虫吧！）在一起的第一年～算是收获了梦想中甜蜜的爱情了（痴汉笑😊）。这一年我们先是度过了恋爱中最难熬的异地恋！最长有三个月的时间没有见面，可能以后都不会再有这么长时间不见面的机会了吧。\n\n今年和小懒虫度过了超级多的第一次。\n\n- 第一次收到新年礼物\n\n[![tN1da.th.jpeg](https://i.328888.xyz/2023/01/03/tN1da.th.jpeg)](https://imgloc.com/i/tN1da)\n\n- 第一次一起弹钢琴\n\n- 第一次一起旅游、看海、帆船、桨板、海边露营、日出\n\n[![tN9TV.th.jpeg](https://i.328888.xyz/2023/01/03/tN9TV.th.jpeg)](https://imgloc.com/i/tN9TV)\n\n- 第一次恐怖密室\n\n[![tNLpb.th.png](https://i.328888.xyz/2023/01/03/tNLpb.th.png)](https://imgloc.com/i/tNLpb)\n\n- 第一次通关游戏\n\n[![trjhJ.th.jpeg](https://i.328888.xyz/2023/01/03/trjhJ.th.jpeg)](https://imgloc.com/i/trjhJ)\n\n- 第一次脱口秀\n\n[![try93.th.jpeg](https://i.328888.xyz/2023/01/03/try93.th.jpeg)](https://imgloc.com/i/try93)\n\n### 疫情\n\n在 2022 年的年末，疫情终于算是“结束”了。。。在毕业前由于江苏教育局的政策「上海一天不解封，南京高校也不解封」，结果导致我们在南大被封了两个月！这让我们论文写完了，答辩完了也没有机会出校。这直接导致我在能毕业离校的第一时间离开了学校，并不带一点留恋。本来打算在南京好好玩一下的也没有时间了。异地恋的影响也在这两个月里达到了顶峰。。。真是太煎熬了。\n\n另外，从今年年底广州疫情开始，自己几乎就一直 remote 到了现在，完全改变了工作习惯。。。放开后也阳了一次，但还不算严重，也就烧了一天多，发烧的时候基本在睡觉，退烧后基本就没什么事了。\n\n我认为只要不再搞什么类似封城的事情，疫情就算是过去了。因为这是不可避免的事情呀，在读完《枪炮、病菌与钢铁》后知道，人类**从来**没有战胜过病毒。这是客观事实。一旦放开后，我们就再也回不去了，亦或者说我们瞬间就回到了过去。有病治病，挺好的。\n\n## 2023\n\n2023 年要做些什么呢？\n\n- 工作上，think more and do more\n- 读书和做饭的习惯能继续保持\n- 计划中的锻炼别拉下了，多跑步，参加一场半马\n- 楼下就有网球场，大学学的网球一定要捡起来玩玩\n- 去更多地方旅行（哈尔滨、潮汕\n- 换个好点的 launchpad 继续玩玩\n\n总之，2022 还行，2023 继续加油💪\n","slug":"2022年终总结","published":1,"updated":"2024-06-15T14:36:14.094Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clxgdbzoh0001xbdygyu7c36p","content":"<p>第一次写年终总结呀，尝试记录一下。一年下来还真发生了不少事。看看自己有啥收获有啥成长。</p>\n<h2 id=\"工作\"><a href=\"#工作\" class=\"headerlink\" title=\"工作\"></a>工作</h2><p>先说说工作吧。从南大毕业后，我去了 PingCAP（贵司）工作，现在在贵司的 DM（Data Migration）团队工作，差不多就在数据导入、数据迁移以及其对应的云上版本这些地方搬砖。去年就有在贵司实习，主要在维护 DM，也就是怎么把一条 binlog 写到下游 TiDB 里面，和 MySQL binlog 打交道比较多。今年入职后，顺应公司的战略，主要在 tidbcloud.com 上 CRUD，帮助用户在 cloud 上导入或迁移数据，和 k8s、CRUD 以及用户体验打交道比较多。</p>\n<p>简单总结一下学到的东西吧，从实习到现在：</p>\n<ol>\n<li>单元测试、集成测试</li>\n<li>多线程代码</li>\n<li>review 代码</li>\n<li>写设计文档</li>\n<li>理解一个需求是任何工作的第一步</li>\n<li>对一个需求进行项目管理，以尽可能地按时交付（当然现在还做的不够好。。。）</li>\n<li>学习了 K8s/CRD/Operator/AWS/Pulumi 相关的知识，能看懂代码，并编写简单的代码</li>\n<li>更多地考虑用户体验</li>\n<li>。。</li>\n</ol>\n<p>再谈谈工作的感受。对于我这第一份正式的工作，我是非常满意我当前的团队和公司的。不论是公司还是团队内，大佬非常多，可以在他们身上学到很多东西。团队内的人大家实事求是、互相帮助，我是没有遇到什么尔虞我诈，为了利益起冲突的情况，很 nice！虽然很多人诟病贵司已经不是以前的贵司了，之前的工程师文化没有那么纯粹了，但我还是帮公司说句话。今年 2022 年的环境大家还是可以看得到的，同样以工程师文化著称的小马，已经把 22 届大部分的应届生裁掉了，我有同学就在被裁名单里。所以对于一个同样是应届生的我，我还是很佩服公司的战略和定力，以帮助公司继续生存下去，毕竟活下去才有未来。我知道这两者也并不是冲突的，但我还是庆幸公司能让我有一个地方学习和成长。当然，大家也都会希望自己的公司能越来越好！</p>\n<p>记录一下：今年 1 月份全组人员齐聚北京团（mian）建（ji），第一次正式见到了来自成都、北京、杭州、上海的各位大佬，也跟着 mentor 没羞没臊地蹭吃蹭喝玩了两天哈哈。不得不说，太爽了哈哈哈🐶。</p>\n<h2 id=\"学生生涯\"><a href=\"#学生生涯\" class=\"headerlink\" title=\"学生生涯\"></a>学生生涯</h2><p>今年终于从硕士毕业了。坦诚地对硕士这三年做个简短的总结吧。自己在三年中几乎没有任何的成果，连一篇论文都没发过，在科研这条路上，我也算的上是彻底失败了。不过这三年比较幸运的是，我在研一下就意识到了自己不适合走科研这条路，所以花了很多时间在思考和实践自己以后要做什么这个问题上。也找到了自认为短中期内发展还不错的数据库这条道路。</p>\n<blockquote>\n<p>在读书期间，经常和同学调侃，读研最大的作用，就是发现了读研没用。哈哈哈，这句话可能有点过，但也是只有读研后，才能理解很多大佬说的，「国内的研究有些浮躁」中<strong>浮躁</strong>的含义吧（叹息）</p>\n</blockquote>\n<h2 id=\"生活\"><a href=\"#生活\" class=\"headerlink\" title=\"生活\"></a>生活</h2><p>在毕业后，正式开启了我自己的生活。这一次和我之前的实习都不一样，我第一次拒绝了合租，选择了一个人整租一个小区里的一室一厅。在省钱和生活质量中选择了后者。当时在来广州之前就疯狂地看房，幻想着自己一个人自由的生活哈哈哈。来了广州之后就疯狂地找房子，一室一厅的小区房实在是太少了🤮。我遇到一个 2500/月 60 平的房子，下午 2 点看完饭，下午 4 点就被租出去了！就是被我后面一个看房的人租走了。。。这效率简直了。最后租到了一间 3000 出头的一室一厅，房东非常 nice，给配了新的马桶、电热水器、空调、抽油烟机和灶台，甚至还重新装修了厨房！虽然还有不足的地方，但我已经非常满足了！</p>\n<h3 id=\"添置新物件\"><a href=\"#添置新物件\" class=\"headerlink\" title=\"添置新物件\"></a>添置新物件</h3><h4 id=\"大桌子✅\"><a href=\"#大桌子✅\" class=\"headerlink\" title=\"大桌子✅\"></a>大桌子✅</h4><p>在自己租了房子之后，必然也是要整一个正经的小书桌的啦。在闲鱼上蹲了好几天，中间还去旁边的二手市场看了，最后花 220 蹲到了这张 160✖️70 的桌子（货拉拉都花了 100+ 😂）</p>\n<p><a href=\"https://imgloc.com/i/tk3cN\"><img src=\"https://i.328888.xyz/2023/01/02/tk3cN.th.jpeg\" alt=\"tk3cN.th.jpeg\"></a></p>\n<h4 id=\"洞洞板✅\"><a href=\"#洞洞板✅\" class=\"headerlink\" title=\"洞洞板✅\"></a>洞洞板✅</h4><p>看 B 站视频还看到了这种立式的洞洞板，想到出租屋里也完全没有书架、小物件的收纳什么的，就整了一个。还行哈，比光秃秃的好多了。</p>\n<p><a href=\"https://imgloc.com/i/tkHFX\"><img src=\"https://i.328888.xyz/2023/01/02/tkHFX.th.jpeg\" alt=\"tkHFX.th.jpeg\"></a></p>\n<h4 id=\"人体工学椅✅\"><a href=\"#人体工学椅✅\" class=\"headerlink\" title=\"人体工学椅✅\"></a>人体工学椅✅</h4><p>毕竟工作需要，立马也整了个好椅子，可以用很久了</p>\n<p><a href=\"https://imgloc.com/i/t0jdv\"><img src=\"https://i.328888.xyz/2023/01/02/t0jdv.th.jpeg\" alt=\"t0jdv.th.jpeg\"></a></p>\n<h4 id=\"牙套✅\"><a href=\"#牙套✅\" class=\"headerlink\" title=\"牙套✅\"></a>牙套✅</h4><p>从很多年前自己就觉得自己的牙齿不齐，想要做牙齿矫正，但无奈因为钱或者长住地不稳定等原因，一直没开始。所以在广州安顿下来之后，立马开始了牙齿矫正的进程。上下左右拔了 4 颗牙！妈耶，疼死我了。</p>\n<h4 id=\"打击垫✅\"><a href=\"#打击垫✅\" class=\"headerlink\" title=\"打击垫✅\"></a>打击垫✅</h4><p>我自己对音乐也一直挺感兴趣的，哈哈就想做点音乐相关的爱好。之前有关注一个绝地的主播，他玩的打击垫超酷！现在有自己的空间和生活了，就整了一个二手的入门款。</p>\n<p><a href=\"https://imgloc.com/i/twO4o\"><img src=\"https://i.328888.xyz/2023/01/02/twO4o.th.jpeg\" alt=\"twO4o.th.jpeg\"></a></p>\n<p>但是非常可惜，在练完入门曲 <a href=\"https://www.bilibili.com/video/BV1bv4y1B7RL/?spm_id_from=333.999.0.0&vd_source=1d41e3899bfb8af8d65144aad99bbde1\">Luz letter</a> 后，在另外挑了一首<a href=\"https://www.bilibili.com/video/BV1q8411E7ts/?spm_id_from=333.999.0.0&vd_source=1d41e3899bfb8af8d65144aad99bbde1\">进阶的曲子</a>练习过程中就发现了问题——灯光跟不上节奏。。。这个入门款的灯光频率太低了，尝试了很多次之后还是放弃了继续在这款上面继续练，然后荒废到现在（哎，可惜。</p>\n<h4 id=\"PS5-大电视✅\"><a href=\"#PS5-大电视✅\" class=\"headerlink\" title=\"PS5/大电视✅\"></a>PS5/大电视✅</h4><p>在双十一的时候，收了一个二手的 PS5，还配了一个大电视！这个小出租屋也终于可以看电视了。</p>\n<p><img src=\"https://i.328888.xyz/2023/01/02/t0Law.jpeg\" alt=\"t0Law.jpeg\"></p>\n<p>顺带评价一下老头环吧，在 PS5 上玩的第一个游戏。之前也有玩过黑魂 3，1）所以并没有第一次玩魂类游戏那种冲击了，而且老头环的难度系数相比黑魂确实低了不少，转角杀少了特别多，所以老玩家在转角处回头的时候经常“失望”哈哈哈。2）还有一个点是堆料太严重了叭，重复的遗迹，重复的 boss，重复的墓地，单一的小怪，散落在交界地的各处，完全没有什么动力去一一扫图。。。3）对于剧情，我还是知道魂类游戏的套路的——剧情都散落在各个道具上，但我真的做不到全搜集呀！😭，而且由于地图太大，剧情太散，我真的记不住各个支线呀！4）对于开放世界，由于也玩过塞尔达这种神作，只能说宫崎英高把魂元素塞到了一个开放世界中，至于这个开放世界它“开放”吗？这管我啥事。</p>\n<p>哈哈哈，吐槽完了，但还是要说我玩了几十个小时，每次一玩就是五六个小时起步，还是很不错的游戏的，只不过在后期感受到了乏味，没能成为艾尔登之王。</p>\n<h3 id=\"做饭\"><a href=\"#做饭\" class=\"headerlink\" title=\"做饭\"></a>做饭</h3><p>要有生活气息，一定离不开自己做饭！今年自己和女朋友一起做了好多好多的菜！而且少有失败，哈哈哈女票直称我为厨房小天才哈哈（也不排除她是为了让我多做饭🐶）。自己做饭真的没那么难，而且味道也比大部分城中村的外卖好吃，就是收拾厨房、洗碗什么的太麻烦了，做完饭吃完饭收拾完基本晚上就啥都不想干了只想瘫着。不知道什么时候能买个洗碗机呀。</p>\n<img src=https://cdn-us.imgs.moe/2023/01/02/63b2c89a14f9a.jpg width=30% />\n\n<h3 id=\"看书\"><a href=\"#看书\" class=\"headerlink\" title=\"看书\"></a>看书</h3><p>今年看书的目标算是达到了，一共看完了 13 本书。感觉自己看书的输入效率还不够。。。还需要继续学习😂</p>\n<ul>\n<li>浪潮之巅</li>\n<li>程序员的修炼之道</li>\n<li>小王子的领悟</li>\n<li>MySQL 是怎么运行的</li>\n<li>黑客与画家</li>\n<li>悉达多</li>\n<li>kubernetes in action</li>\n<li>异乡人</li>\n<li>沙发上的心理学</li>\n<li>数据生态：MySQL 复制技术与生产实践</li>\n<li>宇宙的最后三分钟</li>\n<li>shell 脚本基础教程</li>\n<li>枪炮、病菌与钢铁</li>\n</ul>\n<h3 id=\"爱情\"><a href=\"#爱情\" class=\"headerlink\" title=\"爱情\"></a>爱情</h3><p>今年是和我女朋友（以后就叫她小懒虫吧！）在一起的第一年～算是收获了梦想中甜蜜的爱情了（痴汉笑😊）。这一年我们先是度过了恋爱中最难熬的异地恋！最长有三个月的时间没有见面，可能以后都不会再有这么长时间不见面的机会了吧。</p>\n<p>今年和小懒虫度过了超级多的第一次。</p>\n<ul>\n<li>第一次收到新年礼物</li>\n</ul>\n<p><a href=\"https://imgloc.com/i/tN1da\"><img src=\"https://i.328888.xyz/2023/01/03/tN1da.th.jpeg\" alt=\"tN1da.th.jpeg\"></a></p>\n<ul>\n<li><p>第一次一起弹钢琴</p>\n</li>\n<li><p>第一次一起旅游、看海、帆船、桨板、海边露营、日出</p>\n</li>\n</ul>\n<p><a href=\"https://imgloc.com/i/tN9TV\"><img src=\"https://i.328888.xyz/2023/01/03/tN9TV.th.jpeg\" alt=\"tN9TV.th.jpeg\"></a></p>\n<ul>\n<li>第一次恐怖密室</li>\n</ul>\n<p><a href=\"https://imgloc.com/i/tNLpb\"><img src=\"https://i.328888.xyz/2023/01/03/tNLpb.th.png\" alt=\"tNLpb.th.png\"></a></p>\n<ul>\n<li>第一次通关游戏</li>\n</ul>\n<p><a href=\"https://imgloc.com/i/trjhJ\"><img src=\"https://i.328888.xyz/2023/01/03/trjhJ.th.jpeg\" alt=\"trjhJ.th.jpeg\"></a></p>\n<ul>\n<li>第一次脱口秀</li>\n</ul>\n<p><a href=\"https://imgloc.com/i/try93\"><img src=\"https://i.328888.xyz/2023/01/03/try93.th.jpeg\" alt=\"try93.th.jpeg\"></a></p>\n<h3 id=\"疫情\"><a href=\"#疫情\" class=\"headerlink\" title=\"疫情\"></a>疫情</h3><p>在 2022 年的年末，疫情终于算是“结束”了。。。在毕业前由于江苏教育局的政策「上海一天不解封，南京高校也不解封」，结果导致我们在南大被封了两个月！这让我们论文写完了，答辩完了也没有机会出校。这直接导致我在能毕业离校的第一时间离开了学校，并不带一点留恋。本来打算在南京好好玩一下的也没有时间了。异地恋的影响也在这两个月里达到了顶峰。。。真是太煎熬了。</p>\n<p>另外，从今年年底广州疫情开始，自己几乎就一直 remote 到了现在，完全改变了工作习惯。。。放开后也阳了一次，但还不算严重，也就烧了一天多，发烧的时候基本在睡觉，退烧后基本就没什么事了。</p>\n<p>我认为只要不再搞什么类似封城的事情，疫情就算是过去了。因为这是不可避免的事情呀，在读完《枪炮、病菌与钢铁》后知道，人类<strong>从来</strong>没有战胜过病毒。这是客观事实。一旦放开后，我们就再也回不去了，亦或者说我们瞬间就回到了过去。有病治病，挺好的。</p>\n<h2 id=\"2023\"><a href=\"#2023\" class=\"headerlink\" title=\"2023\"></a>2023</h2><p>2023 年要做些什么呢？</p>\n<ul>\n<li>工作上，think more and do more</li>\n<li>读书和做饭的习惯能继续保持</li>\n<li>计划中的锻炼别拉下了，多跑步，参加一场半马</li>\n<li>楼下就有网球场，大学学的网球一定要捡起来玩玩</li>\n<li>去更多地方旅行（哈尔滨、潮汕</li>\n<li>换个好点的 launchpad 继续玩玩</li>\n</ul>\n<p>总之，2022 还行，2023 继续加油💪</p>\n","site":{"data":{}},"cover":false,"length":3365,"excerpt":"","more":"<p>第一次写年终总结呀，尝试记录一下。一年下来还真发生了不少事。看看自己有啥收获有啥成长。</p>\n<h2 id=\"工作\"><a href=\"#工作\" class=\"headerlink\" title=\"工作\"></a>工作</h2><p>先说说工作吧。从南大毕业后，我去了 PingCAP（贵司）工作，现在在贵司的 DM（Data Migration）团队工作，差不多就在数据导入、数据迁移以及其对应的云上版本这些地方搬砖。去年就有在贵司实习，主要在维护 DM，也就是怎么把一条 binlog 写到下游 TiDB 里面，和 MySQL binlog 打交道比较多。今年入职后，顺应公司的战略，主要在 tidbcloud.com 上 CRUD，帮助用户在 cloud 上导入或迁移数据，和 k8s、CRUD 以及用户体验打交道比较多。</p>\n<p>简单总结一下学到的东西吧，从实习到现在：</p>\n<ol>\n<li>单元测试、集成测试</li>\n<li>多线程代码</li>\n<li>review 代码</li>\n<li>写设计文档</li>\n<li>理解一个需求是任何工作的第一步</li>\n<li>对一个需求进行项目管理，以尽可能地按时交付（当然现在还做的不够好。。。）</li>\n<li>学习了 K8s/CRD/Operator/AWS/Pulumi 相关的知识，能看懂代码，并编写简单的代码</li>\n<li>更多地考虑用户体验</li>\n<li>。。</li>\n</ol>\n<p>再谈谈工作的感受。对于我这第一份正式的工作，我是非常满意我当前的团队和公司的。不论是公司还是团队内，大佬非常多，可以在他们身上学到很多东西。团队内的人大家实事求是、互相帮助，我是没有遇到什么尔虞我诈，为了利益起冲突的情况，很 nice！虽然很多人诟病贵司已经不是以前的贵司了，之前的工程师文化没有那么纯粹了，但我还是帮公司说句话。今年 2022 年的环境大家还是可以看得到的，同样以工程师文化著称的小马，已经把 22 届大部分的应届生裁掉了，我有同学就在被裁名单里。所以对于一个同样是应届生的我，我还是很佩服公司的战略和定力，以帮助公司继续生存下去，毕竟活下去才有未来。我知道这两者也并不是冲突的，但我还是庆幸公司能让我有一个地方学习和成长。当然，大家也都会希望自己的公司能越来越好！</p>\n<p>记录一下：今年 1 月份全组人员齐聚北京团（mian）建（ji），第一次正式见到了来自成都、北京、杭州、上海的各位大佬，也跟着 mentor 没羞没臊地蹭吃蹭喝玩了两天哈哈。不得不说，太爽了哈哈哈🐶。</p>\n<h2 id=\"学生生涯\"><a href=\"#学生生涯\" class=\"headerlink\" title=\"学生生涯\"></a>学生生涯</h2><p>今年终于从硕士毕业了。坦诚地对硕士这三年做个简短的总结吧。自己在三年中几乎没有任何的成果，连一篇论文都没发过，在科研这条路上，我也算的上是彻底失败了。不过这三年比较幸运的是，我在研一下就意识到了自己不适合走科研这条路，所以花了很多时间在思考和实践自己以后要做什么这个问题上。也找到了自认为短中期内发展还不错的数据库这条道路。</p>\n<blockquote>\n<p>在读书期间，经常和同学调侃，读研最大的作用，就是发现了读研没用。哈哈哈，这句话可能有点过，但也是只有读研后，才能理解很多大佬说的，「国内的研究有些浮躁」中<strong>浮躁</strong>的含义吧（叹息）</p>\n</blockquote>\n<h2 id=\"生活\"><a href=\"#生活\" class=\"headerlink\" title=\"生活\"></a>生活</h2><p>在毕业后，正式开启了我自己的生活。这一次和我之前的实习都不一样，我第一次拒绝了合租，选择了一个人整租一个小区里的一室一厅。在省钱和生活质量中选择了后者。当时在来广州之前就疯狂地看房，幻想着自己一个人自由的生活哈哈哈。来了广州之后就疯狂地找房子，一室一厅的小区房实在是太少了🤮。我遇到一个 2500/月 60 平的房子，下午 2 点看完饭，下午 4 点就被租出去了！就是被我后面一个看房的人租走了。。。这效率简直了。最后租到了一间 3000 出头的一室一厅，房东非常 nice，给配了新的马桶、电热水器、空调、抽油烟机和灶台，甚至还重新装修了厨房！虽然还有不足的地方，但我已经非常满足了！</p>\n<h3 id=\"添置新物件\"><a href=\"#添置新物件\" class=\"headerlink\" title=\"添置新物件\"></a>添置新物件</h3><h4 id=\"大桌子✅\"><a href=\"#大桌子✅\" class=\"headerlink\" title=\"大桌子✅\"></a>大桌子✅</h4><p>在自己租了房子之后，必然也是要整一个正经的小书桌的啦。在闲鱼上蹲了好几天，中间还去旁边的二手市场看了，最后花 220 蹲到了这张 160✖️70 的桌子（货拉拉都花了 100+ 😂）</p>\n<p><a href=\"https://imgloc.com/i/tk3cN\"><img src=\"https://i.328888.xyz/2023/01/02/tk3cN.th.jpeg\" alt=\"tk3cN.th.jpeg\"></a></p>\n<h4 id=\"洞洞板✅\"><a href=\"#洞洞板✅\" class=\"headerlink\" title=\"洞洞板✅\"></a>洞洞板✅</h4><p>看 B 站视频还看到了这种立式的洞洞板，想到出租屋里也完全没有书架、小物件的收纳什么的，就整了一个。还行哈，比光秃秃的好多了。</p>\n<p><a href=\"https://imgloc.com/i/tkHFX\"><img src=\"https://i.328888.xyz/2023/01/02/tkHFX.th.jpeg\" alt=\"tkHFX.th.jpeg\"></a></p>\n<h4 id=\"人体工学椅✅\"><a href=\"#人体工学椅✅\" class=\"headerlink\" title=\"人体工学椅✅\"></a>人体工学椅✅</h4><p>毕竟工作需要，立马也整了个好椅子，可以用很久了</p>\n<p><a href=\"https://imgloc.com/i/t0jdv\"><img src=\"https://i.328888.xyz/2023/01/02/t0jdv.th.jpeg\" alt=\"t0jdv.th.jpeg\"></a></p>\n<h4 id=\"牙套✅\"><a href=\"#牙套✅\" class=\"headerlink\" title=\"牙套✅\"></a>牙套✅</h4><p>从很多年前自己就觉得自己的牙齿不齐，想要做牙齿矫正，但无奈因为钱或者长住地不稳定等原因，一直没开始。所以在广州安顿下来之后，立马开始了牙齿矫正的进程。上下左右拔了 4 颗牙！妈耶，疼死我了。</p>\n<h4 id=\"打击垫✅\"><a href=\"#打击垫✅\" class=\"headerlink\" title=\"打击垫✅\"></a>打击垫✅</h4><p>我自己对音乐也一直挺感兴趣的，哈哈就想做点音乐相关的爱好。之前有关注一个绝地的主播，他玩的打击垫超酷！现在有自己的空间和生活了，就整了一个二手的入门款。</p>\n<p><a href=\"https://imgloc.com/i/twO4o\"><img src=\"https://i.328888.xyz/2023/01/02/twO4o.th.jpeg\" alt=\"twO4o.th.jpeg\"></a></p>\n<p>但是非常可惜，在练完入门曲 <a href=\"https://www.bilibili.com/video/BV1bv4y1B7RL/?spm_id_from=333.999.0.0&vd_source=1d41e3899bfb8af8d65144aad99bbde1\">Luz letter</a> 后，在另外挑了一首<a href=\"https://www.bilibili.com/video/BV1q8411E7ts/?spm_id_from=333.999.0.0&vd_source=1d41e3899bfb8af8d65144aad99bbde1\">进阶的曲子</a>练习过程中就发现了问题——灯光跟不上节奏。。。这个入门款的灯光频率太低了，尝试了很多次之后还是放弃了继续在这款上面继续练，然后荒废到现在（哎，可惜。</p>\n<h4 id=\"PS5-大电视✅\"><a href=\"#PS5-大电视✅\" class=\"headerlink\" title=\"PS5/大电视✅\"></a>PS5/大电视✅</h4><p>在双十一的时候，收了一个二手的 PS5，还配了一个大电视！这个小出租屋也终于可以看电视了。</p>\n<p><img src=\"https://i.328888.xyz/2023/01/02/t0Law.jpeg\" alt=\"t0Law.jpeg\"></p>\n<p>顺带评价一下老头环吧，在 PS5 上玩的第一个游戏。之前也有玩过黑魂 3，1）所以并没有第一次玩魂类游戏那种冲击了，而且老头环的难度系数相比黑魂确实低了不少，转角杀少了特别多，所以老玩家在转角处回头的时候经常“失望”哈哈哈。2）还有一个点是堆料太严重了叭，重复的遗迹，重复的 boss，重复的墓地，单一的小怪，散落在交界地的各处，完全没有什么动力去一一扫图。。。3）对于剧情，我还是知道魂类游戏的套路的——剧情都散落在各个道具上，但我真的做不到全搜集呀！😭，而且由于地图太大，剧情太散，我真的记不住各个支线呀！4）对于开放世界，由于也玩过塞尔达这种神作，只能说宫崎英高把魂元素塞到了一个开放世界中，至于这个开放世界它“开放”吗？这管我啥事。</p>\n<p>哈哈哈，吐槽完了，但还是要说我玩了几十个小时，每次一玩就是五六个小时起步，还是很不错的游戏的，只不过在后期感受到了乏味，没能成为艾尔登之王。</p>\n<h3 id=\"做饭\"><a href=\"#做饭\" class=\"headerlink\" title=\"做饭\"></a>做饭</h3><p>要有生活气息，一定离不开自己做饭！今年自己和女朋友一起做了好多好多的菜！而且少有失败，哈哈哈女票直称我为厨房小天才哈哈（也不排除她是为了让我多做饭🐶）。自己做饭真的没那么难，而且味道也比大部分城中村的外卖好吃，就是收拾厨房、洗碗什么的太麻烦了，做完饭吃完饭收拾完基本晚上就啥都不想干了只想瘫着。不知道什么时候能买个洗碗机呀。</p>\n<img src=https://cdn-us.imgs.moe/2023/01/02/63b2c89a14f9a.jpg width=30% />\n\n<h3 id=\"看书\"><a href=\"#看书\" class=\"headerlink\" title=\"看书\"></a>看书</h3><p>今年看书的目标算是达到了，一共看完了 13 本书。感觉自己看书的输入效率还不够。。。还需要继续学习😂</p>\n<ul>\n<li>浪潮之巅</li>\n<li>程序员的修炼之道</li>\n<li>小王子的领悟</li>\n<li>MySQL 是怎么运行的</li>\n<li>黑客与画家</li>\n<li>悉达多</li>\n<li>kubernetes in action</li>\n<li>异乡人</li>\n<li>沙发上的心理学</li>\n<li>数据生态：MySQL 复制技术与生产实践</li>\n<li>宇宙的最后三分钟</li>\n<li>shell 脚本基础教程</li>\n<li>枪炮、病菌与钢铁</li>\n</ul>\n<h3 id=\"爱情\"><a href=\"#爱情\" class=\"headerlink\" title=\"爱情\"></a>爱情</h3><p>今年是和我女朋友（以后就叫她小懒虫吧！）在一起的第一年～算是收获了梦想中甜蜜的爱情了（痴汉笑😊）。这一年我们先是度过了恋爱中最难熬的异地恋！最长有三个月的时间没有见面，可能以后都不会再有这么长时间不见面的机会了吧。</p>\n<p>今年和小懒虫度过了超级多的第一次。</p>\n<ul>\n<li>第一次收到新年礼物</li>\n</ul>\n<p><a href=\"https://imgloc.com/i/tN1da\"><img src=\"https://i.328888.xyz/2023/01/03/tN1da.th.jpeg\" alt=\"tN1da.th.jpeg\"></a></p>\n<ul>\n<li><p>第一次一起弹钢琴</p>\n</li>\n<li><p>第一次一起旅游、看海、帆船、桨板、海边露营、日出</p>\n</li>\n</ul>\n<p><a href=\"https://imgloc.com/i/tN9TV\"><img src=\"https://i.328888.xyz/2023/01/03/tN9TV.th.jpeg\" alt=\"tN9TV.th.jpeg\"></a></p>\n<ul>\n<li>第一次恐怖密室</li>\n</ul>\n<p><a href=\"https://imgloc.com/i/tNLpb\"><img src=\"https://i.328888.xyz/2023/01/03/tNLpb.th.png\" alt=\"tNLpb.th.png\"></a></p>\n<ul>\n<li>第一次通关游戏</li>\n</ul>\n<p><a href=\"https://imgloc.com/i/trjhJ\"><img src=\"https://i.328888.xyz/2023/01/03/trjhJ.th.jpeg\" alt=\"trjhJ.th.jpeg\"></a></p>\n<ul>\n<li>第一次脱口秀</li>\n</ul>\n<p><a href=\"https://imgloc.com/i/try93\"><img src=\"https://i.328888.xyz/2023/01/03/try93.th.jpeg\" alt=\"try93.th.jpeg\"></a></p>\n<h3 id=\"疫情\"><a href=\"#疫情\" class=\"headerlink\" title=\"疫情\"></a>疫情</h3><p>在 2022 年的年末，疫情终于算是“结束”了。。。在毕业前由于江苏教育局的政策「上海一天不解封，南京高校也不解封」，结果导致我们在南大被封了两个月！这让我们论文写完了，答辩完了也没有机会出校。这直接导致我在能毕业离校的第一时间离开了学校，并不带一点留恋。本来打算在南京好好玩一下的也没有时间了。异地恋的影响也在这两个月里达到了顶峰。。。真是太煎熬了。</p>\n<p>另外，从今年年底广州疫情开始，自己几乎就一直 remote 到了现在，完全改变了工作习惯。。。放开后也阳了一次，但还不算严重，也就烧了一天多，发烧的时候基本在睡觉，退烧后基本就没什么事了。</p>\n<p>我认为只要不再搞什么类似封城的事情，疫情就算是过去了。因为这是不可避免的事情呀，在读完《枪炮、病菌与钢铁》后知道，人类<strong>从来</strong>没有战胜过病毒。这是客观事实。一旦放开后，我们就再也回不去了，亦或者说我们瞬间就回到了过去。有病治病，挺好的。</p>\n<h2 id=\"2023\"><a href=\"#2023\" class=\"headerlink\" title=\"2023\"></a>2023</h2><p>2023 年要做些什么呢？</p>\n<ul>\n<li>工作上，think more and do more</li>\n<li>读书和做饭的习惯能继续保持</li>\n<li>计划中的锻炼别拉下了，多跑步，参加一场半马</li>\n<li>楼下就有网球场，大学学的网球一定要捡起来玩玩</li>\n<li>去更多地方旅行（哈尔滨、潮汕</li>\n<li>换个好点的 launchpad 继续玩玩</li>\n</ul>\n<p>总之，2022 还行，2023 继续加油💪</p>\n"},{"title":"DM 数据旅程 00：序言","date":"2023-01-02T17:58:33.000Z","top_img":"img/category/dm_repo.png","cover":"img/category/dm_repo.png","_content":"\n# 背景\n在此之前已经有官方很多关于 DM 的优秀文章了，比如\n\n- [TiDB Ecosystem Tools 原理解读系列（三）TiDB Data Migration 架构设计与实现原理](https://pingcap.com/zh/blog/tidb-ecosystem-tools-3)\n- [DM 源码解读](https://pingcap.com/zh/blog?tag=DM%20%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB)\n\n这些文章从原理方面非常详尽地介绍了 DM 的相关功能，是非常好的学习资料。但是\n\n- 它讲述的内容跨度较大，对读者有一定的门槛，[DM 源码阅读系列文章（一）序：背景知识](https://pingcap.com/zh/blog/dm-source-code-reading-1#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86)\n- 编辑时间太过久远，已经过去两年多了。DM 新增了一些新特性，对很多旧功能也进行了更新优化。所以原文中有很多内容已经过时（但大部分仍有参考价值）。例如：[DM 使用 Dumpling 替换了 MyDumper](https://github.com/pingcap/dm/pull/540)，[新增乐观模式](https://github.com/pingcap/dm/pull/568)等等。\n\n而外部的文章则大部分集中在 DM 的使用上而不是实现上。\n\n基于此，我想开一个坑《DM 数据旅程系列》，每一篇文章将以一个个小功能为线索，带大家理解 DM 中的各种实现。如果要讲的功能太大，也会拆分成小模块放出。每一步都会尽量放出 GitHub 地址，方便大家跟踪学习～\n\n> 数据旅程出自于龙少 PPT 中提到的用户旅程和数据旅程，指我们可以通过数据（字节）传输的途径。在看一段代码时，我们可以思考这个字节是从哪里来的，到哪里去，作用是什么，通过理解数据旅程来理解整个产品它的深层原理，并且可以通过改变数据规模（提升/降低数据数量级）和场景（不同的时间不同的位置）来理解产品的缺点（bug）。\n\n> 以上都是个人拙见（废话），欢迎提意见～\n\n当然，现在的 DM 正在飞速的发展迭代中，本系列的内容也可能马上就会过时，现在是 2021 年 10 月 31 日，本系列文章预计将会覆盖 DM v5.3.0-vx.x.x 的代码逻辑。\n\n如果认为文章中有任何可以改进的地方， 欢迎大家提出自己的想法。同样地，因为 DM 还在快速迭代，还有很多地方都有改进的地方，如果大家对代码实现有任何疑问，也都可以去 repo 中直接提 issue。\n\n# 读者要求\n- 能看懂 Golang 语法\n- 了解 grpc、etcd\n- 计划章节\n- Start task\n- Stop task\n- Pause task\n- Resume task\n- Full mode（dumpling）\n- Incremental mode（syncer）\n- Block-allow list\n- Binlog-filter\n- Enable relay log\n- Permistic sharding ddl\n- Optimistic sharding ddl\n- 。。。","source":"_posts/DM-数据旅程-00：序言.md","raw":"---\ntitle: DM 数据旅程 00：序言\ndate: 2023-01-03 01:58:33\ntags:\n- DM\n- 源码阅读\ncategories:\n- DM 数据旅程\ntop_img: img/category/dm_repo.png\ncover: img/category/dm_repo.png\n---\n\n# 背景\n在此之前已经有官方很多关于 DM 的优秀文章了，比如\n\n- [TiDB Ecosystem Tools 原理解读系列（三）TiDB Data Migration 架构设计与实现原理](https://pingcap.com/zh/blog/tidb-ecosystem-tools-3)\n- [DM 源码解读](https://pingcap.com/zh/blog?tag=DM%20%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB)\n\n这些文章从原理方面非常详尽地介绍了 DM 的相关功能，是非常好的学习资料。但是\n\n- 它讲述的内容跨度较大，对读者有一定的门槛，[DM 源码阅读系列文章（一）序：背景知识](https://pingcap.com/zh/blog/dm-source-code-reading-1#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86)\n- 编辑时间太过久远，已经过去两年多了。DM 新增了一些新特性，对很多旧功能也进行了更新优化。所以原文中有很多内容已经过时（但大部分仍有参考价值）。例如：[DM 使用 Dumpling 替换了 MyDumper](https://github.com/pingcap/dm/pull/540)，[新增乐观模式](https://github.com/pingcap/dm/pull/568)等等。\n\n而外部的文章则大部分集中在 DM 的使用上而不是实现上。\n\n基于此，我想开一个坑《DM 数据旅程系列》，每一篇文章将以一个个小功能为线索，带大家理解 DM 中的各种实现。如果要讲的功能太大，也会拆分成小模块放出。每一步都会尽量放出 GitHub 地址，方便大家跟踪学习～\n\n> 数据旅程出自于龙少 PPT 中提到的用户旅程和数据旅程，指我们可以通过数据（字节）传输的途径。在看一段代码时，我们可以思考这个字节是从哪里来的，到哪里去，作用是什么，通过理解数据旅程来理解整个产品它的深层原理，并且可以通过改变数据规模（提升/降低数据数量级）和场景（不同的时间不同的位置）来理解产品的缺点（bug）。\n\n> 以上都是个人拙见（废话），欢迎提意见～\n\n当然，现在的 DM 正在飞速的发展迭代中，本系列的内容也可能马上就会过时，现在是 2021 年 10 月 31 日，本系列文章预计将会覆盖 DM v5.3.0-vx.x.x 的代码逻辑。\n\n如果认为文章中有任何可以改进的地方， 欢迎大家提出自己的想法。同样地，因为 DM 还在快速迭代，还有很多地方都有改进的地方，如果大家对代码实现有任何疑问，也都可以去 repo 中直接提 issue。\n\n# 读者要求\n- 能看懂 Golang 语法\n- 了解 grpc、etcd\n- 计划章节\n- Start task\n- Stop task\n- Pause task\n- Resume task\n- Full mode（dumpling）\n- Incremental mode（syncer）\n- Block-allow list\n- Binlog-filter\n- Enable relay log\n- Permistic sharding ddl\n- Optimistic sharding ddl\n- 。。。","slug":"DM-数据旅程-00：序言","published":1,"updated":"2024-06-16T07:03:47.893Z","_id":"clxgfc6d300007odyg8gg1y4w","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>在此之前已经有官方很多关于 DM 的优秀文章了，比如</p>\n<ul>\n<li><a href=\"https://pingcap.com/zh/blog/tidb-ecosystem-tools-3\">TiDB Ecosystem Tools 原理解读系列（三）TiDB Data Migration 架构设计与实现原理</a></li>\n<li><a href=\"https://pingcap.com/zh/blog?tag=DM%20%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB\">DM 源码解读</a></li>\n</ul>\n<p>这些文章从原理方面非常详尽地介绍了 DM 的相关功能，是非常好的学习资料。但是</p>\n<ul>\n<li>它讲述的内容跨度较大，对读者有一定的门槛，<a href=\"https://pingcap.com/zh/blog/dm-source-code-reading-1#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86\">DM 源码阅读系列文章（一）序：背景知识</a></li>\n<li>编辑时间太过久远，已经过去两年多了。DM 新增了一些新特性，对很多旧功能也进行了更新优化。所以原文中有很多内容已经过时（但大部分仍有参考价值）。例如：<a href=\"https://github.com/pingcap/dm/pull/540\">DM 使用 Dumpling 替换了 MyDumper</a>，<a href=\"https://github.com/pingcap/dm/pull/568\">新增乐观模式</a>等等。</li>\n</ul>\n<p>而外部的文章则大部分集中在 DM 的使用上而不是实现上。</p>\n<p>基于此，我想开一个坑《DM 数据旅程系列》，每一篇文章将以一个个小功能为线索，带大家理解 DM 中的各种实现。如果要讲的功能太大，也会拆分成小模块放出。每一步都会尽量放出 GitHub 地址，方便大家跟踪学习～</p>\n<blockquote>\n<p>数据旅程出自于龙少 PPT 中提到的用户旅程和数据旅程，指我们可以通过数据（字节）传输的途径。在看一段代码时，我们可以思考这个字节是从哪里来的，到哪里去，作用是什么，通过理解数据旅程来理解整个产品它的深层原理，并且可以通过改变数据规模（提升/降低数据数量级）和场景（不同的时间不同的位置）来理解产品的缺点（bug）。</p>\n</blockquote>\n<blockquote>\n<p>以上都是个人拙见（废话），欢迎提意见～</p>\n</blockquote>\n<p>当然，现在的 DM 正在飞速的发展迭代中，本系列的内容也可能马上就会过时，现在是 2021 年 10 月 31 日，本系列文章预计将会覆盖 DM v5.3.0-vx.x.x 的代码逻辑。</p>\n<p>如果认为文章中有任何可以改进的地方， 欢迎大家提出自己的想法。同样地，因为 DM 还在快速迭代，还有很多地方都有改进的地方，如果大家对代码实现有任何疑问，也都可以去 repo 中直接提 issue。</p>\n<h1 id=\"读者要求\"><a href=\"#读者要求\" class=\"headerlink\" title=\"读者要求\"></a>读者要求</h1><ul>\n<li>能看懂 Golang 语法</li>\n<li>了解 grpc、etcd</li>\n<li>计划章节</li>\n<li>Start task</li>\n<li>Stop task</li>\n<li>Pause task</li>\n<li>Resume task</li>\n<li>Full mode（dumpling）</li>\n<li>Incremental mode（syncer）</li>\n<li>Block-allow list</li>\n<li>Binlog-filter</li>\n<li>Enable relay log</li>\n<li>Permistic sharding ddl</li>\n<li>Optimistic sharding ddl</li>\n<li>。。。</li>\n</ul>\n","site":{"data":{}},"cover_type":"img","length":938,"excerpt":"","more":"<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>在此之前已经有官方很多关于 DM 的优秀文章了，比如</p>\n<ul>\n<li><a href=\"https://pingcap.com/zh/blog/tidb-ecosystem-tools-3\">TiDB Ecosystem Tools 原理解读系列（三）TiDB Data Migration 架构设计与实现原理</a></li>\n<li><a href=\"https://pingcap.com/zh/blog?tag=DM%20%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB\">DM 源码解读</a></li>\n</ul>\n<p>这些文章从原理方面非常详尽地介绍了 DM 的相关功能，是非常好的学习资料。但是</p>\n<ul>\n<li>它讲述的内容跨度较大，对读者有一定的门槛，<a href=\"https://pingcap.com/zh/blog/dm-source-code-reading-1#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86\">DM 源码阅读系列文章（一）序：背景知识</a></li>\n<li>编辑时间太过久远，已经过去两年多了。DM 新增了一些新特性，对很多旧功能也进行了更新优化。所以原文中有很多内容已经过时（但大部分仍有参考价值）。例如：<a href=\"https://github.com/pingcap/dm/pull/540\">DM 使用 Dumpling 替换了 MyDumper</a>，<a href=\"https://github.com/pingcap/dm/pull/568\">新增乐观模式</a>等等。</li>\n</ul>\n<p>而外部的文章则大部分集中在 DM 的使用上而不是实现上。</p>\n<p>基于此，我想开一个坑《DM 数据旅程系列》，每一篇文章将以一个个小功能为线索，带大家理解 DM 中的各种实现。如果要讲的功能太大，也会拆分成小模块放出。每一步都会尽量放出 GitHub 地址，方便大家跟踪学习～</p>\n<blockquote>\n<p>数据旅程出自于龙少 PPT 中提到的用户旅程和数据旅程，指我们可以通过数据（字节）传输的途径。在看一段代码时，我们可以思考这个字节是从哪里来的，到哪里去，作用是什么，通过理解数据旅程来理解整个产品它的深层原理，并且可以通过改变数据规模（提升/降低数据数量级）和场景（不同的时间不同的位置）来理解产品的缺点（bug）。</p>\n</blockquote>\n<blockquote>\n<p>以上都是个人拙见（废话），欢迎提意见～</p>\n</blockquote>\n<p>当然，现在的 DM 正在飞速的发展迭代中，本系列的内容也可能马上就会过时，现在是 2021 年 10 月 31 日，本系列文章预计将会覆盖 DM v5.3.0-vx.x.x 的代码逻辑。</p>\n<p>如果认为文章中有任何可以改进的地方， 欢迎大家提出自己的想法。同样地，因为 DM 还在快速迭代，还有很多地方都有改进的地方，如果大家对代码实现有任何疑问，也都可以去 repo 中直接提 issue。</p>\n<h1 id=\"读者要求\"><a href=\"#读者要求\" class=\"headerlink\" title=\"读者要求\"></a>读者要求</h1><ul>\n<li>能看懂 Golang 语法</li>\n<li>了解 grpc、etcd</li>\n<li>计划章节</li>\n<li>Start task</li>\n<li>Stop task</li>\n<li>Pause task</li>\n<li>Resume task</li>\n<li>Full mode（dumpling）</li>\n<li>Incremental mode（syncer）</li>\n<li>Block-allow list</li>\n<li>Binlog-filter</li>\n<li>Enable relay log</li>\n<li>Permistic sharding ddl</li>\n<li>Optimistic sharding ddl</li>\n<li>。。。</li>\n</ul>\n"},{"title":"DM 数据旅程 01：第一次 start task","date":"2023-01-02T18:58:33.000Z","top_img":"/img/category/first_dm_job.png","cover":"/img/category/first_dm_job.png","_content":"\n# 一、概述\n\n本文以 start task 为目的，带着读者从 0 到 1 启动一个数据迁移任务，旨在让读者了解到最基础的 DM 逻辑。本文将直接参照集成测试 [start\\_task](https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L27-L36) 的过程，从以下几个方面展开：\n\n1. Start dm-master\n2. Start dm-worker\n3. 绑定 source 和 dm-worker\n4. Start task\n\n> 注：为了专注于我们的目的（start task），本文不会对无关代码进行解读\n\n> 大家可使用 [start/stop 流程](https://pingcap.feishu.cn/mindnotes/bmncnqlO5BCrkgxFqabTLaz6EQh#mindmap) 辅助阅读\n>\n> 由于写这篇的文章的时间是 2021 年 12 月份，所以所有的链接都是原 DM repo 的😂\n\n# 二、start dm-master\n\n1. [./dm-master](https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L27)（in [run\\_dm\\_master](https://github.com/pingcap/dm/blob/master/tests/_utils/run_dm_master)） 启动二进制文件，即调用 [main 函数](https://github.com/pingcap/dm/blob/master/cmd/dm-master/main.go#L35)，其中 [master-server start](https://github.com/pingcap/dm/blob/master/cmd/dm-master/main.go#L69)\n2. [go electionNotify](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L232)：这个是为了[等待 ](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L55)`etcd election`[ 成功](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L55)，并在其成功后做⬇️\n\n> DM master 中内嵌了一个 [etcd](https://etcd.io/)，用于存储各种元数据，并且借此保证 DM master 的高可用。后面非常多的数据存储都会用到 etcd。\n\n3. [startLeaderComponent](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L71)，其中我们这次只需要关注 [s.scheduler.Start](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L173) 中的[go observeWorkerEvent](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L243)，主要分为两部分\n\n   1. [go WatchWorkerEvent](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1617)：该函数通过 etcd client 监听[是否有 workerEvent 出现](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L198)\n\n   2. [handleWorkerEv](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1619)：有 workerEvent 出现时，handle it\n\n      1. [handleWorkerOffline](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1580)\n      2. [handleWorkerOnline](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1582)\n\n4. 这个时候，dm-master 等待 workerEvent 到来\n\n# 三、start dm-worker\n\n1. [./dm-worker](https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L29)（in [run\\_dm\\_worker](https://github.com/pingcap/dm/blob/master/tests/_utils/run_dm_worker)）启动二进制文件，即调用 [main 函数](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go)，其中[ worker-server start](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go#L89)\n\n2. [JoinMaster](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go#L78)：先告诉 master，我来了！\n\n   1. worker 先在这 [RegisterWorker](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/join.go#L72)，然后会触发 master 调用 [RegisterWorker](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L298)\n   2. Master 会调用 [AddWorker](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L308)，然后 [PutWorkerInfo](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L907)，把相应的 key-value [写到 etcd](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/worker.go#L69) 中\n   3. 可以看到写到 etcd 用的是 `clientv3.OpPut(key, value)`，也就是说 kv 要执行 put 操作\n   4. 之前的 [go WatchWorkerEvent](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1617) 中就监听到有事件来了，并且判断其为 `mvccpb.PUT`[ 类型](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L224)，event 处理之后会通过 [outCh](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L242) 传到 handleWorkerEv 中进行具体的[上线处理](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1582)\n   5. 刚上线的时候，就会去各种找 source 去 bound，但是现在我们还没有 create source，所以也找不到 source，暂时可以不关注这里\n\n3. Start task 还需要 bound source，那 worker 首先要做的就是 [observeSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L169)，这里同 [observeWorkerEvent](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L243) 是类似的：\n\n   1. [go WatchSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L404)：通过 etcd client 监听[是否有 sourceBound 出现](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/bound.go#L265)\n   2. [handleSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L406)：上面监听到了之后，则 [operateSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L582)\n\n4. 接下来，dm-worker 等待 source bound\n\n# 四、operate-source create\n\n> DM 用的命令行工具是 [cobra](https://github.com/spf13/cobra)，有兴趣的读者可深入了解一下\n\n1. 命令行执行 [operate-source create](https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L34)（in [test\\_prepare](https://github.com/pingcap/dm/blob/master/tests/_utils/test_prepare#L128-L136)），`operate-source` 这个命令在 [NewOperateSourceCmd](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/ctl.go#L68) 注册，具体实现在 [operateSourceFunc](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L39)\n\n2. 读取到该命令后，开始[解析](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L89)第一个参数（即 `create`）并[转换](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L47-L48)，最后被[打包送](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L143-L152)到 master，开始执行 master 的 [OperateSource](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1186) 函数\n\n3. 该函数中，master 会从命令行中给出的配置文件路径\n\n   1. [解析并调整](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1205) source config\n   2. [把 source cfg 也存到 etcd 里](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1227)，因为 worker 待会要用\n   3. [Try to bound it to a free worker](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L318-L319)：因为我们是第一次 start task，并且也没有开启 relay 功能（[test](https://github.com/pingcap/dm/blob/master/tests/start_task/conf/source1.yaml#L4) 中是开启了，但本篇文章假设不开启），所以我们就只能 [bound a free worker](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1904-L1915) 了。\n   4. 最终，通过 [PutSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1936)，把 SourceBound [通过 etcd client 发送](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/bound.go#L100)\n\n4. 发送之后，worker 就通过 [go WatchSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L404) 监听到有 SourceBound 出现，然后进行 [operateSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L582)\n\n   1. 首先需要[拿到 source cfg](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L649)，因为上面的操作都是在 master 执行的，worker 这里并没有 source cfg\n   2. Source cfg 也是通过 [etcd](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/source.go#L83) 拿到的，正好上面存了\n\n5. 之后就可以[开始 subtask 了吧](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L658)！\n\n   1. 但是并没有。。。我们还没开始 start task 呢！\n   2. 所以 [fetchSubTasksAndAdjust](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L396) 并不能拿到 subtask。拿到是空的\n\n6. 那没办法了，继续[等](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L422)呗（又是同样的 watch/handle 机制）\n\n   1. [go WatchSubTaskStage](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L638)\n   2. [handleSubTaskStage](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L640)\n\n# 五、start-task\n\n1. 命令行执行 [start-task](https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L36)（in [test\\_prepare](https://github.com/pingcap/dm/blob/master/tests/_utils/test_prepare#L53-L64)），`start-task` 命令的注册和实现参考 `operate-source`，最后执行 master 的 [StartTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L404) 函数\n\n2. 直接开始就 [generateSubTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L426)（`req.Task` 直接传递的就是解析好的 `task.yaml` 字符串，原来在命令的实现中就帮我们解析好啦）。简单的说，就是经过一些 adjust 和 check， 帮助我们生成了 [SubTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/config/subtask.go#L184) struct\n\n3. 重点来了，[AddSubTasks](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L489) -> [NewSubTaskStage](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L727)，subTask 终于创建好了，stage=running；再 [put](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L739) 进 etcd，完美。可以看到我们分别把 [SubTaskCfg](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/ops.go#L91) 和 [SubTaskStage](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/ops.go#L95) 都 put 进 etcd 了。\n\n4. 那上面就 watch 到 stage 来了，对 SubTaskCfg 进行[处理](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L682)，如果我们是要进行 run 的操作，我们还得[先把 cfg 拿出来](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L735-L743)，最后 [startSubTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L716)\n\n5. startSubTask 中，会 [NewSubTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L481)，再 [runSubTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L504)。subTask 内部具体的执行组建是由 [unit](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/unit/unit.go#L32-L67) 负责的，所以它会\n\n   1. [initUnits](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L200)\n   2. [st.run](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L207) 其实也是由 [currentUnit](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L228) 来 [Process](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L233)\n\n# 六、结语\n\n在 unit Process 后，start-task 就结束啦！是不是还意犹未尽呢？到底有哪些 unit 呢？这些 unit 内部到底是怎么 Process 的呢？在后续的文章中会陆续和大家见面哦。\n\n其实再复读一下全文，我们发现本篇文章并没有太多很难的东西，大部分篇幅都在描述一些「准备活动」，全程用 etcd watch——master 等待 worker 到来、worker 等待 source 到来、source-worker 等待 subtask 到来。等就完事了。\n\n任何建议和反馈都欢迎告诉我。下期再见！\n","source":"_posts/DM-数据旅程-01：第一次-start-task.md","raw":"---\ntitle: DM 数据旅程 01：第一次 start task\ndate: 2023-01-03 02:58:33\ntags:\n- DM\n- 源码阅读\ncategories:\n- DM 数据旅程\ntop_img: /img/category/first_dm_job.png\ncover: /img/category/first_dm_job.png\n---\n\n# 一、概述\n\n本文以 start task 为目的，带着读者从 0 到 1 启动一个数据迁移任务，旨在让读者了解到最基础的 DM 逻辑。本文将直接参照集成测试 [start\\_task](https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L27-L36) 的过程，从以下几个方面展开：\n\n1. Start dm-master\n2. Start dm-worker\n3. 绑定 source 和 dm-worker\n4. Start task\n\n> 注：为了专注于我们的目的（start task），本文不会对无关代码进行解读\n\n> 大家可使用 [start/stop 流程](https://pingcap.feishu.cn/mindnotes/bmncnqlO5BCrkgxFqabTLaz6EQh#mindmap) 辅助阅读\n>\n> 由于写这篇的文章的时间是 2021 年 12 月份，所以所有的链接都是原 DM repo 的😂\n\n# 二、start dm-master\n\n1. [./dm-master](https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L27)（in [run\\_dm\\_master](https://github.com/pingcap/dm/blob/master/tests/_utils/run_dm_master)） 启动二进制文件，即调用 [main 函数](https://github.com/pingcap/dm/blob/master/cmd/dm-master/main.go#L35)，其中 [master-server start](https://github.com/pingcap/dm/blob/master/cmd/dm-master/main.go#L69)\n2. [go electionNotify](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L232)：这个是为了[等待 ](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L55)`etcd election`[ 成功](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L55)，并在其成功后做⬇️\n\n> DM master 中内嵌了一个 [etcd](https://etcd.io/)，用于存储各种元数据，并且借此保证 DM master 的高可用。后面非常多的数据存储都会用到 etcd。\n\n3. [startLeaderComponent](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L71)，其中我们这次只需要关注 [s.scheduler.Start](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L173) 中的[go observeWorkerEvent](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L243)，主要分为两部分\n\n   1. [go WatchWorkerEvent](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1617)：该函数通过 etcd client 监听[是否有 workerEvent 出现](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L198)\n\n   2. [handleWorkerEv](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1619)：有 workerEvent 出现时，handle it\n\n      1. [handleWorkerOffline](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1580)\n      2. [handleWorkerOnline](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1582)\n\n4. 这个时候，dm-master 等待 workerEvent 到来\n\n# 三、start dm-worker\n\n1. [./dm-worker](https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L29)（in [run\\_dm\\_worker](https://github.com/pingcap/dm/blob/master/tests/_utils/run_dm_worker)）启动二进制文件，即调用 [main 函数](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go)，其中[ worker-server start](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go#L89)\n\n2. [JoinMaster](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go#L78)：先告诉 master，我来了！\n\n   1. worker 先在这 [RegisterWorker](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/join.go#L72)，然后会触发 master 调用 [RegisterWorker](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L298)\n   2. Master 会调用 [AddWorker](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L308)，然后 [PutWorkerInfo](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L907)，把相应的 key-value [写到 etcd](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/worker.go#L69) 中\n   3. 可以看到写到 etcd 用的是 `clientv3.OpPut(key, value)`，也就是说 kv 要执行 put 操作\n   4. 之前的 [go WatchWorkerEvent](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1617) 中就监听到有事件来了，并且判断其为 `mvccpb.PUT`[ 类型](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L224)，event 处理之后会通过 [outCh](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L242) 传到 handleWorkerEv 中进行具体的[上线处理](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1582)\n   5. 刚上线的时候，就会去各种找 source 去 bound，但是现在我们还没有 create source，所以也找不到 source，暂时可以不关注这里\n\n3. Start task 还需要 bound source，那 worker 首先要做的就是 [observeSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L169)，这里同 [observeWorkerEvent](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L243) 是类似的：\n\n   1. [go WatchSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L404)：通过 etcd client 监听[是否有 sourceBound 出现](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/bound.go#L265)\n   2. [handleSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L406)：上面监听到了之后，则 [operateSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L582)\n\n4. 接下来，dm-worker 等待 source bound\n\n# 四、operate-source create\n\n> DM 用的命令行工具是 [cobra](https://github.com/spf13/cobra)，有兴趣的读者可深入了解一下\n\n1. 命令行执行 [operate-source create](https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L34)（in [test\\_prepare](https://github.com/pingcap/dm/blob/master/tests/_utils/test_prepare#L128-L136)），`operate-source` 这个命令在 [NewOperateSourceCmd](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/ctl.go#L68) 注册，具体实现在 [operateSourceFunc](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L39)\n\n2. 读取到该命令后，开始[解析](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L89)第一个参数（即 `create`）并[转换](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L47-L48)，最后被[打包送](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L143-L152)到 master，开始执行 master 的 [OperateSource](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1186) 函数\n\n3. 该函数中，master 会从命令行中给出的配置文件路径\n\n   1. [解析并调整](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1205) source config\n   2. [把 source cfg 也存到 etcd 里](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1227)，因为 worker 待会要用\n   3. [Try to bound it to a free worker](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L318-L319)：因为我们是第一次 start task，并且也没有开启 relay 功能（[test](https://github.com/pingcap/dm/blob/master/tests/start_task/conf/source1.yaml#L4) 中是开启了，但本篇文章假设不开启），所以我们就只能 [bound a free worker](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1904-L1915) 了。\n   4. 最终，通过 [PutSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1936)，把 SourceBound [通过 etcd client 发送](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/bound.go#L100)\n\n4. 发送之后，worker 就通过 [go WatchSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L404) 监听到有 SourceBound 出现，然后进行 [operateSourceBound](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L582)\n\n   1. 首先需要[拿到 source cfg](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L649)，因为上面的操作都是在 master 执行的，worker 这里并没有 source cfg\n   2. Source cfg 也是通过 [etcd](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/source.go#L83) 拿到的，正好上面存了\n\n5. 之后就可以[开始 subtask 了吧](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L658)！\n\n   1. 但是并没有。。。我们还没开始 start task 呢！\n   2. 所以 [fetchSubTasksAndAdjust](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L396) 并不能拿到 subtask。拿到是空的\n\n6. 那没办法了，继续[等](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L422)呗（又是同样的 watch/handle 机制）\n\n   1. [go WatchSubTaskStage](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L638)\n   2. [handleSubTaskStage](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L640)\n\n# 五、start-task\n\n1. 命令行执行 [start-task](https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L36)（in [test\\_prepare](https://github.com/pingcap/dm/blob/master/tests/_utils/test_prepare#L53-L64)），`start-task` 命令的注册和实现参考 `operate-source`，最后执行 master 的 [StartTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L404) 函数\n\n2. 直接开始就 [generateSubTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L426)（`req.Task` 直接传递的就是解析好的 `task.yaml` 字符串，原来在命令的实现中就帮我们解析好啦）。简单的说，就是经过一些 adjust 和 check， 帮助我们生成了 [SubTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/config/subtask.go#L184) struct\n\n3. 重点来了，[AddSubTasks](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L489) -> [NewSubTaskStage](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L727)，subTask 终于创建好了，stage=running；再 [put](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L739) 进 etcd，完美。可以看到我们分别把 [SubTaskCfg](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/ops.go#L91) 和 [SubTaskStage](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/ops.go#L95) 都 put 进 etcd 了。\n\n4. 那上面就 watch 到 stage 来了，对 SubTaskCfg 进行[处理](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L682)，如果我们是要进行 run 的操作，我们还得[先把 cfg 拿出来](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L735-L743)，最后 [startSubTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L716)\n\n5. startSubTask 中，会 [NewSubTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L481)，再 [runSubTask](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L504)。subTask 内部具体的执行组建是由 [unit](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/unit/unit.go#L32-L67) 负责的，所以它会\n\n   1. [initUnits](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L200)\n   2. [st.run](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L207) 其实也是由 [currentUnit](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L228) 来 [Process](https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L233)\n\n# 六、结语\n\n在 unit Process 后，start-task 就结束啦！是不是还意犹未尽呢？到底有哪些 unit 呢？这些 unit 内部到底是怎么 Process 的呢？在后续的文章中会陆续和大家见面哦。\n\n其实再复读一下全文，我们发现本篇文章并没有太多很难的东西，大部分篇幅都在描述一些「准备活动」，全程用 etcd watch——master 等待 worker 到来、worker 等待 source 到来、source-worker 等待 subtask 到来。等就完事了。\n\n任何建议和反馈都欢迎告诉我。下期再见！\n","slug":"DM-数据旅程-01：第一次-start-task","published":1,"updated":"2024-06-16T07:12:29.395Z","_id":"clxh0ivhl0000rvdyen14f5dy","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h1><p>本文以 start task 为目的，带着读者从 0 到 1 启动一个数据迁移任务，旨在让读者了解到最基础的 DM 逻辑。本文将直接参照集成测试 <a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L27-L36\">start_task</a> 的过程，从以下几个方面展开：</p>\n<ol>\n<li>Start dm-master</li>\n<li>Start dm-worker</li>\n<li>绑定 source 和 dm-worker</li>\n<li>Start task</li>\n</ol>\n<blockquote>\n<p>注：为了专注于我们的目的（start task），本文不会对无关代码进行解读</p>\n</blockquote>\n<blockquote>\n<p>大家可使用 <a href=\"https://pingcap.feishu.cn/mindnotes/bmncnqlO5BCrkgxFqabTLaz6EQh#mindmap\">start/stop 流程</a> 辅助阅读</p>\n<p>由于写这篇的文章的时间是 2021 年 12 月份，所以所有的链接都是原 DM repo 的😂</p>\n</blockquote>\n<h1 id=\"二、start-dm-master\"><a href=\"#二、start-dm-master\" class=\"headerlink\" title=\"二、start dm-master\"></a>二、start dm-master</h1><ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L27\">./dm-master</a>（in <a href=\"https://github.com/pingcap/dm/blob/master/tests/_utils/run_dm_master\">run_dm_master</a>） 启动二进制文件，即调用 <a href=\"https://github.com/pingcap/dm/blob/master/cmd/dm-master/main.go#L35\">main 函数</a>，其中 <a href=\"https://github.com/pingcap/dm/blob/master/cmd/dm-master/main.go#L69\">master-server start</a></li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L232\">go electionNotify</a>：这个是为了<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L55\">等待 </a><code>etcd election</code><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L55\"> 成功</a>，并在其成功后做⬇️</li>\n</ol>\n<blockquote>\n<p>DM master 中内嵌了一个 <a href=\"https://etcd.io/\">etcd</a>，用于存储各种元数据，并且借此保证 DM master 的高可用。后面非常多的数据存储都会用到 etcd。</p>\n</blockquote>\n<ol start=\"3\">\n<li><p><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L71\">startLeaderComponent</a>，其中我们这次只需要关注 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L173\">s.scheduler.Start</a> 中的<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L243\">go observeWorkerEvent</a>，主要分为两部分</p>\n<ol>\n<li><p><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1617\">go WatchWorkerEvent</a>：该函数通过 etcd client 监听<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L198\">是否有 workerEvent 出现</a></p>\n</li>\n<li><p><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1619\">handleWorkerEv</a>：有 workerEvent 出现时，handle it</p>\n<ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1580\">handleWorkerOffline</a></li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1582\">handleWorkerOnline</a></li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>这个时候，dm-master 等待 workerEvent 到来</p>\n</li>\n</ol>\n<h1 id=\"三、start-dm-worker\"><a href=\"#三、start-dm-worker\" class=\"headerlink\" title=\"三、start dm-worker\"></a>三、start dm-worker</h1><ol>\n<li><p><a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L29\">./dm-worker</a>（in <a href=\"https://github.com/pingcap/dm/blob/master/tests/_utils/run_dm_worker\">run_dm_worker</a>）启动二进制文件，即调用 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go\">main 函数</a>，其中<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go#L89\"> worker-server start</a></p>\n</li>\n<li><p><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go#L78\">JoinMaster</a>：先告诉 master，我来了！</p>\n<ol>\n<li>worker 先在这 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/join.go#L72\">RegisterWorker</a>，然后会触发 master 调用 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L298\">RegisterWorker</a></li>\n<li>Master 会调用 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L308\">AddWorker</a>，然后 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L907\">PutWorkerInfo</a>，把相应的 key-value <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/worker.go#L69\">写到 etcd</a> 中</li>\n<li>可以看到写到 etcd 用的是 <code>clientv3.OpPut(key, value)</code>，也就是说 kv 要执行 put 操作</li>\n<li>之前的 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1617\">go WatchWorkerEvent</a> 中就监听到有事件来了，并且判断其为 <code>mvccpb.PUT</code><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L224\"> 类型</a>，event 处理之后会通过 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L242\">outCh</a> 传到 handleWorkerEv 中进行具体的<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1582\">上线处理</a></li>\n<li>刚上线的时候，就会去各种找 source 去 bound，但是现在我们还没有 create source，所以也找不到 source，暂时可以不关注这里</li>\n</ol>\n</li>\n<li><p>Start task 还需要 bound source，那 worker 首先要做的就是 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L169\">observeSourceBound</a>，这里同 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L243\">observeWorkerEvent</a> 是类似的：</p>\n<ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L404\">go WatchSourceBound</a>：通过 etcd client 监听<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/bound.go#L265\">是否有 sourceBound 出现</a></li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L406\">handleSourceBound</a>：上面监听到了之后，则 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L582\">operateSourceBound</a></li>\n</ol>\n</li>\n<li><p>接下来，dm-worker 等待 source bound</p>\n</li>\n</ol>\n<h1 id=\"四、operate-source-create\"><a href=\"#四、operate-source-create\" class=\"headerlink\" title=\"四、operate-source create\"></a>四、operate-source create</h1><blockquote>\n<p>DM 用的命令行工具是 <a href=\"https://github.com/spf13/cobra\">cobra</a>，有兴趣的读者可深入了解一下</p>\n</blockquote>\n<ol>\n<li><p>命令行执行 <a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L34\">operate-source create</a>（in <a href=\"https://github.com/pingcap/dm/blob/master/tests/_utils/test_prepare#L128-L136\">test_prepare</a>），<code>operate-source</code> 这个命令在 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/ctl.go#L68\">NewOperateSourceCmd</a> 注册，具体实现在 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L39\">operateSourceFunc</a></p>\n</li>\n<li><p>读取到该命令后，开始<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L89\">解析</a>第一个参数（即 <code>create</code>）并<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L47-L48\">转换</a>，最后被<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L143-L152\">打包送</a>到 master，开始执行 master 的 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1186\">OperateSource</a> 函数</p>\n</li>\n<li><p>该函数中，master 会从命令行中给出的配置文件路径</p>\n<ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1205\">解析并调整</a> source config</li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1227\">把 source cfg 也存到 etcd 里</a>，因为 worker 待会要用</li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L318-L319\">Try to bound it to a free worker</a>：因为我们是第一次 start task，并且也没有开启 relay 功能（<a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/conf/source1.yaml#L4\">test</a> 中是开启了，但本篇文章假设不开启），所以我们就只能 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1904-L1915\">bound a free worker</a> 了。</li>\n<li>最终，通过 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1936\">PutSourceBound</a>，把 SourceBound <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/bound.go#L100\">通过 etcd client 发送</a></li>\n</ol>\n</li>\n<li><p>发送之后，worker 就通过 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L404\">go WatchSourceBound</a> 监听到有 SourceBound 出现，然后进行 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L582\">operateSourceBound</a></p>\n<ol>\n<li>首先需要<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L649\">拿到 source cfg</a>，因为上面的操作都是在 master 执行的，worker 这里并没有 source cfg</li>\n<li>Source cfg 也是通过 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/source.go#L83\">etcd</a> 拿到的，正好上面存了</li>\n</ol>\n</li>\n<li><p>之后就可以<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L658\">开始 subtask 了吧</a>！</p>\n<ol>\n<li>但是并没有。。。我们还没开始 start task 呢！</li>\n<li>所以 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L396\">fetchSubTasksAndAdjust</a> 并不能拿到 subtask。拿到是空的</li>\n</ol>\n</li>\n<li><p>那没办法了，继续<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L422\">等</a>呗（又是同样的 watch/handle 机制）</p>\n<ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L638\">go WatchSubTaskStage</a></li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L640\">handleSubTaskStage</a></li>\n</ol>\n</li>\n</ol>\n<h1 id=\"五、start-task\"><a href=\"#五、start-task\" class=\"headerlink\" title=\"五、start-task\"></a>五、start-task</h1><ol>\n<li><p>命令行执行 <a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L36\">start-task</a>（in <a href=\"https://github.com/pingcap/dm/blob/master/tests/_utils/test_prepare#L53-L64\">test_prepare</a>），<code>start-task</code> 命令的注册和实现参考 <code>operate-source</code>，最后执行 master 的 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L404\">StartTask</a> 函数</p>\n</li>\n<li><p>直接开始就 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L426\">generateSubTask</a>（<code>req.Task</code> 直接传递的就是解析好的 <code>task.yaml</code> 字符串，原来在命令的实现中就帮我们解析好啦）。简单的说，就是经过一些 adjust 和 check， 帮助我们生成了 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/config/subtask.go#L184\">SubTask</a> struct</p>\n</li>\n<li><p>重点来了，<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L489\">AddSubTasks</a> -&gt; <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L727\">NewSubTaskStage</a>，subTask 终于创建好了，stage=running；再 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L739\">put</a> 进 etcd，完美。可以看到我们分别把 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/ops.go#L91\">SubTaskCfg</a> 和 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/ops.go#L95\">SubTaskStage</a> 都 put 进 etcd 了。</p>\n</li>\n<li><p>那上面就 watch 到 stage 来了，对 SubTaskCfg 进行<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L682\">处理</a>，如果我们是要进行 run 的操作，我们还得<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L735-L743\">先把 cfg 拿出来</a>，最后 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L716\">startSubTask</a></p>\n</li>\n<li><p>startSubTask 中，会 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L481\">NewSubTask</a>，再 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L504\">runSubTask</a>。subTask 内部具体的执行组建是由 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/unit/unit.go#L32-L67\">unit</a> 负责的，所以它会</p>\n<ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L200\">initUnits</a></li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L207\">st.run</a> 其实也是由 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L228\">currentUnit</a> 来 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L233\">Process</a></li>\n</ol>\n</li>\n</ol>\n<h1 id=\"六、结语\"><a href=\"#六、结语\" class=\"headerlink\" title=\"六、结语\"></a>六、结语</h1><p>在 unit Process 后，start-task 就结束啦！是不是还意犹未尽呢？到底有哪些 unit 呢？这些 unit 内部到底是怎么 Process 的呢？在后续的文章中会陆续和大家见面哦。</p>\n<p>其实再复读一下全文，我们发现本篇文章并没有太多很难的东西，大部分篇幅都在描述一些「准备活动」，全程用 etcd watch——master 等待 worker 到来、worker 等待 source 到来、source-worker 等待 subtask 到来。等就完事了。</p>\n<p>任何建议和反馈都欢迎告诉我。下期再见！</p>\n","site":{"data":{}},"cover_type":"img","length":2831,"excerpt":"","more":"<h1 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h1><p>本文以 start task 为目的，带着读者从 0 到 1 启动一个数据迁移任务，旨在让读者了解到最基础的 DM 逻辑。本文将直接参照集成测试 <a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L27-L36\">start_task</a> 的过程，从以下几个方面展开：</p>\n<ol>\n<li>Start dm-master</li>\n<li>Start dm-worker</li>\n<li>绑定 source 和 dm-worker</li>\n<li>Start task</li>\n</ol>\n<blockquote>\n<p>注：为了专注于我们的目的（start task），本文不会对无关代码进行解读</p>\n</blockquote>\n<blockquote>\n<p>大家可使用 <a href=\"https://pingcap.feishu.cn/mindnotes/bmncnqlO5BCrkgxFqabTLaz6EQh#mindmap\">start/stop 流程</a> 辅助阅读</p>\n<p>由于写这篇的文章的时间是 2021 年 12 月份，所以所有的链接都是原 DM repo 的😂</p>\n</blockquote>\n<h1 id=\"二、start-dm-master\"><a href=\"#二、start-dm-master\" class=\"headerlink\" title=\"二、start dm-master\"></a>二、start dm-master</h1><ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L27\">./dm-master</a>（in <a href=\"https://github.com/pingcap/dm/blob/master/tests/_utils/run_dm_master\">run_dm_master</a>） 启动二进制文件，即调用 <a href=\"https://github.com/pingcap/dm/blob/master/cmd/dm-master/main.go#L35\">main 函数</a>，其中 <a href=\"https://github.com/pingcap/dm/blob/master/cmd/dm-master/main.go#L69\">master-server start</a></li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L232\">go electionNotify</a>：这个是为了<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L55\">等待 </a><code>etcd election</code><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L55\"> 成功</a>，并在其成功后做⬇️</li>\n</ol>\n<blockquote>\n<p>DM master 中内嵌了一个 <a href=\"https://etcd.io/\">etcd</a>，用于存储各种元数据，并且借此保证 DM master 的高可用。后面非常多的数据存储都会用到 etcd。</p>\n</blockquote>\n<ol start=\"3\">\n<li><p><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L71\">startLeaderComponent</a>，其中我们这次只需要关注 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/election.go#L173\">s.scheduler.Start</a> 中的<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L243\">go observeWorkerEvent</a>，主要分为两部分</p>\n<ol>\n<li><p><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1617\">go WatchWorkerEvent</a>：该函数通过 etcd client 监听<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L198\">是否有 workerEvent 出现</a></p>\n</li>\n<li><p><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1619\">handleWorkerEv</a>：有 workerEvent 出现时，handle it</p>\n<ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1580\">handleWorkerOffline</a></li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1582\">handleWorkerOnline</a></li>\n</ol>\n</li>\n</ol>\n</li>\n<li><p>这个时候，dm-master 等待 workerEvent 到来</p>\n</li>\n</ol>\n<h1 id=\"三、start-dm-worker\"><a href=\"#三、start-dm-worker\" class=\"headerlink\" title=\"三、start dm-worker\"></a>三、start dm-worker</h1><ol>\n<li><p><a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L29\">./dm-worker</a>（in <a href=\"https://github.com/pingcap/dm/blob/master/tests/_utils/run_dm_worker\">run_dm_worker</a>）启动二进制文件，即调用 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go\">main 函数</a>，其中<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go#L89\"> worker-server start</a></p>\n</li>\n<li><p><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/cmd/dm-worker/main.go#L78\">JoinMaster</a>：先告诉 master，我来了！</p>\n<ol>\n<li>worker 先在这 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/join.go#L72\">RegisterWorker</a>，然后会触发 master 调用 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L298\">RegisterWorker</a></li>\n<li>Master 会调用 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L308\">AddWorker</a>，然后 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L907\">PutWorkerInfo</a>，把相应的 key-value <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/worker.go#L69\">写到 etcd</a> 中</li>\n<li>可以看到写到 etcd 用的是 <code>clientv3.OpPut(key, value)</code>，也就是说 kv 要执行 put 操作</li>\n<li>之前的 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1617\">go WatchWorkerEvent</a> 中就监听到有事件来了，并且判断其为 <code>mvccpb.PUT</code><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L224\"> 类型</a>，event 处理之后会通过 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/keepalive.go#L242\">outCh</a> 传到 handleWorkerEv 中进行具体的<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1582\">上线处理</a></li>\n<li>刚上线的时候，就会去各种找 source 去 bound，但是现在我们还没有 create source，所以也找不到 source，暂时可以不关注这里</li>\n</ol>\n</li>\n<li><p>Start task 还需要 bound source，那 worker 首先要做的就是 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L169\">observeSourceBound</a>，这里同 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L243\">observeWorkerEvent</a> 是类似的：</p>\n<ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L404\">go WatchSourceBound</a>：通过 etcd client 监听<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/bound.go#L265\">是否有 sourceBound 出现</a></li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L406\">handleSourceBound</a>：上面监听到了之后，则 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L582\">operateSourceBound</a></li>\n</ol>\n</li>\n<li><p>接下来，dm-worker 等待 source bound</p>\n</li>\n</ol>\n<h1 id=\"四、operate-source-create\"><a href=\"#四、operate-source-create\" class=\"headerlink\" title=\"四、operate-source create\"></a>四、operate-source create</h1><blockquote>\n<p>DM 用的命令行工具是 <a href=\"https://github.com/spf13/cobra\">cobra</a>，有兴趣的读者可深入了解一下</p>\n</blockquote>\n<ol>\n<li><p>命令行执行 <a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L34\">operate-source create</a>（in <a href=\"https://github.com/pingcap/dm/blob/master/tests/_utils/test_prepare#L128-L136\">test_prepare</a>），<code>operate-source</code> 这个命令在 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/ctl.go#L68\">NewOperateSourceCmd</a> 注册，具体实现在 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L39\">operateSourceFunc</a></p>\n</li>\n<li><p>读取到该命令后，开始<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L89\">解析</a>第一个参数（即 <code>create</code>）并<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L47-L48\">转换</a>，最后被<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/ctl/master/operate_source.go#L143-L152\">打包送</a>到 master，开始执行 master 的 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1186\">OperateSource</a> 函数</p>\n</li>\n<li><p>该函数中，master 会从命令行中给出的配置文件路径</p>\n<ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1205\">解析并调整</a> source config</li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L1227\">把 source cfg 也存到 etcd 里</a>，因为 worker 待会要用</li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L318-L319\">Try to bound it to a free worker</a>：因为我们是第一次 start task，并且也没有开启 relay 功能（<a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/conf/source1.yaml#L4\">test</a> 中是开启了，但本篇文章假设不开启），所以我们就只能 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1904-L1915\">bound a free worker</a> 了。</li>\n<li>最终，通过 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L1936\">PutSourceBound</a>，把 SourceBound <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/bound.go#L100\">通过 etcd client 发送</a></li>\n</ol>\n</li>\n<li><p>发送之后，worker 就通过 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L404\">go WatchSourceBound</a> 监听到有 SourceBound 出现，然后进行 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L582\">operateSourceBound</a></p>\n<ol>\n<li>首先需要<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L649\">拿到 source cfg</a>，因为上面的操作都是在 master 执行的，worker 这里并没有 source cfg</li>\n<li>Source cfg 也是通过 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/source.go#L83\">etcd</a> 拿到的，正好上面存了</li>\n</ol>\n</li>\n<li><p>之后就可以<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/server.go#L658\">开始 subtask 了吧</a>！</p>\n<ol>\n<li>但是并没有。。。我们还没开始 start task 呢！</li>\n<li>所以 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L396\">fetchSubTasksAndAdjust</a> 并不能拿到 subtask。拿到是空的</li>\n</ol>\n</li>\n<li><p>那没办法了，继续<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L422\">等</a>呗（又是同样的 watch/handle 机制）</p>\n<ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L638\">go WatchSubTaskStage</a></li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L640\">handleSubTaskStage</a></li>\n</ol>\n</li>\n</ol>\n<h1 id=\"五、start-task\"><a href=\"#五、start-task\" class=\"headerlink\" title=\"五、start-task\"></a>五、start-task</h1><ol>\n<li><p>命令行执行 <a href=\"https://github.com/pingcap/dm/blob/master/tests/start_task/run.sh#L36\">start-task</a>（in <a href=\"https://github.com/pingcap/dm/blob/master/tests/_utils/test_prepare#L53-L64\">test_prepare</a>），<code>start-task</code> 命令的注册和实现参考 <code>operate-source</code>，最后执行 master 的 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L404\">StartTask</a> 函数</p>\n</li>\n<li><p>直接开始就 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L426\">generateSubTask</a>（<code>req.Task</code> 直接传递的就是解析好的 <code>task.yaml</code> 字符串，原来在命令的实现中就帮我们解析好啦）。简单的说，就是经过一些 adjust 和 check， 帮助我们生成了 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/config/subtask.go#L184\">SubTask</a> struct</p>\n</li>\n<li><p>重点来了，<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/server.go#L489\">AddSubTasks</a> -&gt; <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L727\">NewSubTaskStage</a>，subTask 终于创建好了，stage=running；再 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/master/scheduler/scheduler.go#L739\">put</a> 进 etcd，完美。可以看到我们分别把 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/ops.go#L91\">SubTaskCfg</a> 和 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/pkg/ha/ops.go#L95\">SubTaskStage</a> 都 put 进 etcd 了。</p>\n</li>\n<li><p>那上面就 watch 到 stage 来了，对 SubTaskCfg 进行<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L682\">处理</a>，如果我们是要进行 run 的操作，我们还得<a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L735-L743\">先把 cfg 拿出来</a>，最后 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L716\">startSubTask</a></p>\n</li>\n<li><p>startSubTask 中，会 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L481\">NewSubTask</a>，再 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/source_worker.go#L504\">runSubTask</a>。subTask 内部具体的执行组建是由 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/unit/unit.go#L32-L67\">unit</a> 负责的，所以它会</p>\n<ol>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L200\">initUnits</a></li>\n<li><a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L207\">st.run</a> 其实也是由 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L228\">currentUnit</a> 来 <a href=\"https://github.com/pingcap/dm/blob/39b5e2098f21260c14373a23069f7e38395d8d7f/dm/worker/subtask.go#L233\">Process</a></li>\n</ol>\n</li>\n</ol>\n<h1 id=\"六、结语\"><a href=\"#六、结语\" class=\"headerlink\" title=\"六、结语\"></a>六、结语</h1><p>在 unit Process 后，start-task 就结束啦！是不是还意犹未尽呢？到底有哪些 unit 呢？这些 unit 内部到底是怎么 Process 的呢？在后续的文章中会陆续和大家见面哦。</p>\n<p>其实再复读一下全文，我们发现本篇文章并没有太多很难的东西，大部分篇幅都在描述一些「准备活动」，全程用 etcd watch——master 等待 worker 到来、worker 等待 source 到来、source-worker 等待 subtask 到来。等就完事了。</p>\n<p>任何建议和反馈都欢迎告诉我。下期再见！</p>\n"},{"title":"DM 数据旅程 02：分库分表悲观协调——02Lock -> Resolve Lock","date":"2023-01-02T19:58:33.000Z","top_img":"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283666.png","cover":"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283666.png","_content":"\n# 一、概述\n\n介绍了与悲观协调有关的各个数据结构之后，接下来将介绍一个 DM 系统从接受到第一条分表 DDL 开始，到所有该 DDL 对应的 Lock resolved 的全过程。\n\n> 本节内容皆参考 [DM v6.0](https://github.com/pingcap/tiflow/tree/release-6.0)，对现在而言，有可能已过时，欢迎大家提出意见～\n\n# 二、Overview\n\n假设现在起了 master 和两个 Worker，两个 Worker 分别绑定两个 Source（s1，s2），每个 Source 有两个分表（t1，t2），这四个表会 route 到一个 target table（tarTbl）中。在 DDL 到来之前，两个 worker 会创建好 ShardingGroupKeeper，里面只有一个 target table，两个 source table。\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283187.png)\n\n两个 Worker 先后收到两个 Source 四个分表的同一条 DDL，表示为：\n\n- DDL1：表示对 s1.t1 的 DDL。\n- DDL2：表示对 s2.t1 的 DDL。\n- DDL3：表示对 s1.t2 的 DDL。\n- DDL4：表示对 s2.t2 的 DDL。\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283666.png)\n\n# 三、具体过程\n\n> 本小节 worker 对 DDL 的处理从 [handleQueryEventPessimistic](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2853) 开始，如果不知道在此之前的 DDL 做过哪些处理，请期待后续文章😁\n\n接下来将对上图中的步骤一一介绍\n\n## Step 1\n\n1. worker1 收到来自 source1 的 DDL1，会直接 [TrySync](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883)，这里返回了一大堆的参数，其实有用的就只是 `synced`，简单来说，里面只做了一件事：[AddItem](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding_group.go#L215)。下面详细介绍一下 TrySync\n\n> 本节，假设该 DDL 不是 CreateTableStmt，如果是的话，也很简单，每次都是 remain <=0，synced = true，但是只有第一次发送该 create table 的 worker 会 syncDDL。\n\n### TrySync\n\n想要知道 worker 在悲观协调的时候做了什么，必须要搞懂 TrySync 是怎么运作的。在此之前，我们来重新理解一下 ShardingGroupKeeper：\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283187.png)\n\n单独拿出一个 ShardingGroup 举例（颜色代表 DDL 的种类）：\n\n#### Example\n\nworker 收到了以下 DDL\n\n- 依次收到了 table1 橙色、黄色、绿色三条 DDL\n- 收到了 table2 橙色\n- 这个时候 `activeIdx = 0`，`remain = 1`，因为只有 table3 没有收到 active DDL 了\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283679.png)\n\n- 如果在这个时候收到了 table3 橙色 DDL，`remain = 0`，处理了这条 DDL 之后，`active ++`\n\n![image.png](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/image-1672713793518.png)\n\n- 如果这个时候收到 table2 绿色 DDL，则会[报错](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L197-L199)，悲观协调要求同一个 source table 中 DDL 必须有序\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283186.png)\n\n- 如果 group 中所有的 DDL 都 resolved 了。则会[重置](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L243-L246)一下 meta\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283692.png)\n\n总结：[AddItem](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding_group.go#L215) 就是上面图中把 DDLItem 放进 ShardingSequence 的过程\n\n## Step 2 与 Step 1 相同\n\n## Step 3\n\n由于 tarTbl 只有两个 source table：s1.t1 和 s1.t2，这时 [TrySync](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883) 后，[synced = true](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2948)，说明该 worker ready\n\n## Step 4\n\n### worker1\n\n- [PutInfo](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2985)：发送 ready info 给 master（后面会详细介绍这个函数）\n- 之后会被阻塞，[等待 master 发送 operation](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2992)。\n\n### Master\n\n- [watchInfoPut](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L177)：成功监听到了\n- handleInfoPut：master 也开始 [TrySync](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L474)，master 的 TrySync 相比 worker 中的要简单很多，每一个 Info 直接相当于该 source/worker 已 ready，所以直接统计是否所有 ready 即可\n- 由于这里是第一个 worker 发 info 给 master，所以需要[新建 Lock](https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/keeper.go#L49)，新建 Lock 过程中会获取该 task 所有的 source，并存到 lock 中，这样就知道还有多少 source 没 ready。显然还有 source2 没 ready。\n- [继续等待](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L481-L485)\n\n## Step 5 与 Step 3 相同\n\n## Step 6\n\n- 前面与 Step 4 相同，但是这时所有 source 都 ready 了，[synced = true](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L486)\n\n## Step 7\n\n### master\n\n- [putOpForOwner](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L599)：发送 [exec](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L604) operation to owner(worker1)\n\n### Worker1\n\n- [得到 master 的 exec operation](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/shardddl/pessimist.go#L120-L124)\n\n- [NewDDLJob](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L3042-L3043) 并 handle\n\n- [addJob](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1057)：发送 job 给 DDLJobCh\n\n- syncDDL：之前 worker 起的协程接受到该 job\n\n  - [拿到刚刚得到的 operation](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1324)，并且不会被跳过，因为 ignore = false\n\n## Step 8\n\n- [同步到下游](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1344)\n\n## Step 9\n\n### Worker1\n\n- [DoneOperationDeleteInfo](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1384)：发送 done operation 给 master 并删除 info\n\n## Step 10\n\n### Master\n\n- [接受 done operation](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L509)\n- [markDone](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L529)\n- [putOpsForNonOwner](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L553)：给其他所有 non-owner 发送 skip info（skip done 是为了防止把 done 覆盖掉）\n\n### Worker2\n\n- 接受到了 no exec(skip) 的 operation，和 Step 7 类似，但是在 syncDDL 的时候会[被 skip](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1325-L1328)\n\n## Step 11 和 Step 9 相同\n\n# 四、总结\n\n本节介绍了在悲观协调过程中，遇到第一条 DDL 语句，生成 Lock，到收到所有 DDL 语句，Lock 解除的过程。\n\n经过本节的学习，我们已经完全学会了 DM 悲观协调的过程。是不是也没那么复杂😏，但是在这个过程中，我们只知道 DDL 的处理方式，这个过程中的 DML 会怎么办呢？下一章揭晓。\n\n# 五、疑似 bug\n\n1. [initShardingGroups](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L552-L559) 中对 ShardingGroup.sources 进行了初始化，这里包含了该 targetTable 对应的所有 sourceTables\n2. 在 [TrySync](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883) 的时候，却使用第一个 `sourceTable[0]`，来标记所有的 `DDL[]`，如果 `len(DDL[]) != 1`，则 remain 永远不可能为 0。因为 sourceTables 来源于 ddlInfo。而 DDLInfo 只存了[第一条 ddl 的 ddlInfo](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2738-L2743)，实际上对于每一个 Split 之后的 DDL，都会 [genDDLInfo](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2694)。\n3. 但是奇怪的是，代码中标注了[不支持 multi-table DDL](http://ErrSyncerUnitDDLOnMultipleTable)，这个 error 在 pessimist/optimist mode 中都用到了。但是在现在看 pessimist 代码中，又看到其为 multi-table DDL 实现了部分相关逻辑。。。**有毒**\n4. 比如：\n\n- https\\://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2957-L2960\n- https\\://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L35\n- 。。。\n\n","source":"_posts/DM-数据旅程-02：分库分表悲观协调——02Lock-Resolve-Lock.md","raw":"---\ntitle: DM 数据旅程 02：分库分表悲观协调——02Lock -> Resolve Lock\ndate: 2023-01-03 03:58:33\ntags:\n- DM\n- 源码阅读\ncategories:\n- DM 数据旅程\ntop_img: https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283666.png\ncover: https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283666.png\n---\n\n# 一、概述\n\n介绍了与悲观协调有关的各个数据结构之后，接下来将介绍一个 DM 系统从接受到第一条分表 DDL 开始，到所有该 DDL 对应的 Lock resolved 的全过程。\n\n> 本节内容皆参考 [DM v6.0](https://github.com/pingcap/tiflow/tree/release-6.0)，对现在而言，有可能已过时，欢迎大家提出意见～\n\n# 二、Overview\n\n假设现在起了 master 和两个 Worker，两个 Worker 分别绑定两个 Source（s1，s2），每个 Source 有两个分表（t1，t2），这四个表会 route 到一个 target table（tarTbl）中。在 DDL 到来之前，两个 worker 会创建好 ShardingGroupKeeper，里面只有一个 target table，两个 source table。\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283187.png)\n\n两个 Worker 先后收到两个 Source 四个分表的同一条 DDL，表示为：\n\n- DDL1：表示对 s1.t1 的 DDL。\n- DDL2：表示对 s2.t1 的 DDL。\n- DDL3：表示对 s1.t2 的 DDL。\n- DDL4：表示对 s2.t2 的 DDL。\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283666.png)\n\n# 三、具体过程\n\n> 本小节 worker 对 DDL 的处理从 [handleQueryEventPessimistic](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2853) 开始，如果不知道在此之前的 DDL 做过哪些处理，请期待后续文章😁\n\n接下来将对上图中的步骤一一介绍\n\n## Step 1\n\n1. worker1 收到来自 source1 的 DDL1，会直接 [TrySync](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883)，这里返回了一大堆的参数，其实有用的就只是 `synced`，简单来说，里面只做了一件事：[AddItem](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding_group.go#L215)。下面详细介绍一下 TrySync\n\n> 本节，假设该 DDL 不是 CreateTableStmt，如果是的话，也很简单，每次都是 remain <=0，synced = true，但是只有第一次发送该 create table 的 worker 会 syncDDL。\n\n### TrySync\n\n想要知道 worker 在悲观协调的时候做了什么，必须要搞懂 TrySync 是怎么运作的。在此之前，我们来重新理解一下 ShardingGroupKeeper：\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283187.png)\n\n单独拿出一个 ShardingGroup 举例（颜色代表 DDL 的种类）：\n\n#### Example\n\nworker 收到了以下 DDL\n\n- 依次收到了 table1 橙色、黄色、绿色三条 DDL\n- 收到了 table2 橙色\n- 这个时候 `activeIdx = 0`，`remain = 1`，因为只有 table3 没有收到 active DDL 了\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283679.png)\n\n- 如果在这个时候收到了 table3 橙色 DDL，`remain = 0`，处理了这条 DDL 之后，`active ++`\n\n![image.png](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/image-1672713793518.png)\n\n- 如果这个时候收到 table2 绿色 DDL，则会[报错](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L197-L199)，悲观协调要求同一个 source table 中 DDL 必须有序\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283186.png)\n\n- 如果 group 中所有的 DDL 都 resolved 了。则会[重置](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L243-L246)一下 meta\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283692.png)\n\n总结：[AddItem](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding_group.go#L215) 就是上面图中把 DDLItem 放进 ShardingSequence 的过程\n\n## Step 2 与 Step 1 相同\n\n## Step 3\n\n由于 tarTbl 只有两个 source table：s1.t1 和 s1.t2，这时 [TrySync](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883) 后，[synced = true](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2948)，说明该 worker ready\n\n## Step 4\n\n### worker1\n\n- [PutInfo](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2985)：发送 ready info 给 master（后面会详细介绍这个函数）\n- 之后会被阻塞，[等待 master 发送 operation](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2992)。\n\n### Master\n\n- [watchInfoPut](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L177)：成功监听到了\n- handleInfoPut：master 也开始 [TrySync](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L474)，master 的 TrySync 相比 worker 中的要简单很多，每一个 Info 直接相当于该 source/worker 已 ready，所以直接统计是否所有 ready 即可\n- 由于这里是第一个 worker 发 info 给 master，所以需要[新建 Lock](https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/keeper.go#L49)，新建 Lock 过程中会获取该 task 所有的 source，并存到 lock 中，这样就知道还有多少 source 没 ready。显然还有 source2 没 ready。\n- [继续等待](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L481-L485)\n\n## Step 5 与 Step 3 相同\n\n## Step 6\n\n- 前面与 Step 4 相同，但是这时所有 source 都 ready 了，[synced = true](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L486)\n\n## Step 7\n\n### master\n\n- [putOpForOwner](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L599)：发送 [exec](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L604) operation to owner(worker1)\n\n### Worker1\n\n- [得到 master 的 exec operation](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/shardddl/pessimist.go#L120-L124)\n\n- [NewDDLJob](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L3042-L3043) 并 handle\n\n- [addJob](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1057)：发送 job 给 DDLJobCh\n\n- syncDDL：之前 worker 起的协程接受到该 job\n\n  - [拿到刚刚得到的 operation](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1324)，并且不会被跳过，因为 ignore = false\n\n## Step 8\n\n- [同步到下游](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1344)\n\n## Step 9\n\n### Worker1\n\n- [DoneOperationDeleteInfo](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1384)：发送 done operation 给 master 并删除 info\n\n## Step 10\n\n### Master\n\n- [接受 done operation](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L509)\n- [markDone](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L529)\n- [putOpsForNonOwner](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L553)：给其他所有 non-owner 发送 skip info（skip done 是为了防止把 done 覆盖掉）\n\n### Worker2\n\n- 接受到了 no exec(skip) 的 operation，和 Step 7 类似，但是在 syncDDL 的时候会[被 skip](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1325-L1328)\n\n## Step 11 和 Step 9 相同\n\n# 四、总结\n\n本节介绍了在悲观协调过程中，遇到第一条 DDL 语句，生成 Lock，到收到所有 DDL 语句，Lock 解除的过程。\n\n经过本节的学习，我们已经完全学会了 DM 悲观协调的过程。是不是也没那么复杂😏，但是在这个过程中，我们只知道 DDL 的处理方式，这个过程中的 DML 会怎么办呢？下一章揭晓。\n\n# 五、疑似 bug\n\n1. [initShardingGroups](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L552-L559) 中对 ShardingGroup.sources 进行了初始化，这里包含了该 targetTable 对应的所有 sourceTables\n2. 在 [TrySync](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883) 的时候，却使用第一个 `sourceTable[0]`，来标记所有的 `DDL[]`，如果 `len(DDL[]) != 1`，则 remain 永远不可能为 0。因为 sourceTables 来源于 ddlInfo。而 DDLInfo 只存了[第一条 ddl 的 ddlInfo](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2738-L2743)，实际上对于每一个 Split 之后的 DDL，都会 [genDDLInfo](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2694)。\n3. 但是奇怪的是，代码中标注了[不支持 multi-table DDL](http://ErrSyncerUnitDDLOnMultipleTable)，这个 error 在 pessimist/optimist mode 中都用到了。但是在现在看 pessimist 代码中，又看到其为 multi-table DDL 实现了部分相关逻辑。。。**有毒**\n4. 比如：\n\n- https\\://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2957-L2960\n- https\\://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L35\n- 。。。\n\n","slug":"DM-数据旅程-02：分库分表悲观协调——02Lock-Resolve-Lock","published":1,"updated":"2024-06-16T06:59:24.542Z","_id":"clxh0mtjx0000avdy7tdtf3iz","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h1><p>介绍了与悲观协调有关的各个数据结构之后，接下来将介绍一个 DM 系统从接受到第一条分表 DDL 开始，到所有该 DDL 对应的 Lock resolved 的全过程。</p>\n<blockquote>\n<p>本节内容皆参考 <a href=\"https://github.com/pingcap/tiflow/tree/release-6.0\">DM v6.0</a>，对现在而言，有可能已过时，欢迎大家提出意见～</p>\n</blockquote>\n<h1 id=\"二、Overview\"><a href=\"#二、Overview\" class=\"headerlink\" title=\"二、Overview\"></a>二、Overview</h1><p>假设现在起了 master 和两个 Worker，两个 Worker 分别绑定两个 Source（s1，s2），每个 Source 有两个分表（t1，t2），这四个表会 route 到一个 target table（tarTbl）中。在 DDL 到来之前，两个 worker 会创建好 ShardingGroupKeeper，里面只有一个 target table，两个 source table。</p>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283187.png\"></p>\n<p>两个 Worker 先后收到两个 Source 四个分表的同一条 DDL，表示为：</p>\n<ul>\n<li>DDL1：表示对 s1.t1 的 DDL。</li>\n<li>DDL2：表示对 s2.t1 的 DDL。</li>\n<li>DDL3：表示对 s1.t2 的 DDL。</li>\n<li>DDL4：表示对 s2.t2 的 DDL。</li>\n</ul>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283666.png\"></p>\n<h1 id=\"三、具体过程\"><a href=\"#三、具体过程\" class=\"headerlink\" title=\"三、具体过程\"></a>三、具体过程</h1><blockquote>\n<p>本小节 worker 对 DDL 的处理从 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2853\">handleQueryEventPessimistic</a> 开始，如果不知道在此之前的 DDL 做过哪些处理，请期待后续文章😁</p>\n</blockquote>\n<p>接下来将对上图中的步骤一一介绍</p>\n<h2 id=\"Step-1\"><a href=\"#Step-1\" class=\"headerlink\" title=\"Step 1\"></a>Step 1</h2><ol>\n<li>worker1 收到来自 source1 的 DDL1，会直接 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883\">TrySync</a>，这里返回了一大堆的参数，其实有用的就只是 <code>synced</code>，简单来说，里面只做了一件事：<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding_group.go#L215\">AddItem</a>。下面详细介绍一下 TrySync</li>\n</ol>\n<blockquote>\n<p>本节，假设该 DDL 不是 CreateTableStmt，如果是的话，也很简单，每次都是 remain &lt;=0，synced = true，但是只有第一次发送该 create table 的 worker 会 syncDDL。</p>\n</blockquote>\n<h3 id=\"TrySync\"><a href=\"#TrySync\" class=\"headerlink\" title=\"TrySync\"></a>TrySync</h3><p>想要知道 worker 在悲观协调的时候做了什么，必须要搞懂 TrySync 是怎么运作的。在此之前，我们来重新理解一下 ShardingGroupKeeper：</p>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283187.png\"></p>\n<p>单独拿出一个 ShardingGroup 举例（颜色代表 DDL 的种类）：</p>\n<h4 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h4><p>worker 收到了以下 DDL</p>\n<ul>\n<li>依次收到了 table1 橙色、黄色、绿色三条 DDL</li>\n<li>收到了 table2 橙色</li>\n<li>这个时候 <code>activeIdx = 0</code>，<code>remain = 1</code>，因为只有 table3 没有收到 active DDL 了</li>\n</ul>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283679.png\"></p>\n<ul>\n<li>如果在这个时候收到了 table3 橙色 DDL，<code>remain = 0</code>，处理了这条 DDL 之后，<code>active ++</code></li>\n</ul>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/image-1672713793518.png\" alt=\"image.png\"></p>\n<ul>\n<li>如果这个时候收到 table2 绿色 DDL，则会<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L197-L199\">报错</a>，悲观协调要求同一个 source table 中 DDL 必须有序</li>\n</ul>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283186.png\"></p>\n<ul>\n<li>如果 group 中所有的 DDL 都 resolved 了。则会<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L243-L246\">重置</a>一下 meta</li>\n</ul>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283692.png\"></p>\n<p>总结：<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding_group.go#L215\">AddItem</a> 就是上面图中把 DDLItem 放进 ShardingSequence 的过程</p>\n<h2 id=\"Step-2-与-Step-1-相同\"><a href=\"#Step-2-与-Step-1-相同\" class=\"headerlink\" title=\"Step 2 与 Step 1 相同\"></a>Step 2 与 Step 1 相同</h2><h2 id=\"Step-3\"><a href=\"#Step-3\" class=\"headerlink\" title=\"Step 3\"></a>Step 3</h2><p>由于 tarTbl 只有两个 source table：s1.t1 和 s1.t2，这时 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883\">TrySync</a> 后，<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2948\">synced = true</a>，说明该 worker ready</p>\n<h2 id=\"Step-4\"><a href=\"#Step-4\" class=\"headerlink\" title=\"Step 4\"></a>Step 4</h2><h3 id=\"worker1\"><a href=\"#worker1\" class=\"headerlink\" title=\"worker1\"></a>worker1</h3><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2985\">PutInfo</a>：发送 ready info 给 master（后面会详细介绍这个函数）</li>\n<li>之后会被阻塞，<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2992\">等待 master 发送 operation</a>。</li>\n</ul>\n<h3 id=\"Master\"><a href=\"#Master\" class=\"headerlink\" title=\"Master\"></a>Master</h3><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L177\">watchInfoPut</a>：成功监听到了</li>\n<li>handleInfoPut：master 也开始 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L474\">TrySync</a>，master 的 TrySync 相比 worker 中的要简单很多，每一个 Info 直接相当于该 source/worker 已 ready，所以直接统计是否所有 ready 即可</li>\n<li>由于这里是第一个 worker 发 info 给 master，所以需要<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/keeper.go#L49\">新建 Lock</a>，新建 Lock 过程中会获取该 task 所有的 source，并存到 lock 中，这样就知道还有多少 source 没 ready。显然还有 source2 没 ready。</li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L481-L485\">继续等待</a></li>\n</ul>\n<h2 id=\"Step-5-与-Step-3-相同\"><a href=\"#Step-5-与-Step-3-相同\" class=\"headerlink\" title=\"Step 5 与 Step 3 相同\"></a>Step 5 与 Step 3 相同</h2><h2 id=\"Step-6\"><a href=\"#Step-6\" class=\"headerlink\" title=\"Step 6\"></a>Step 6</h2><ul>\n<li>前面与 Step 4 相同，但是这时所有 source 都 ready 了，<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L486\">synced = true</a></li>\n</ul>\n<h2 id=\"Step-7\"><a href=\"#Step-7\" class=\"headerlink\" title=\"Step 7\"></a>Step 7</h2><h3 id=\"master\"><a href=\"#master\" class=\"headerlink\" title=\"master\"></a>master</h3><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L599\">putOpForOwner</a>：发送 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L604\">exec</a> operation to owner(worker1)</li>\n</ul>\n<h3 id=\"Worker1\"><a href=\"#Worker1\" class=\"headerlink\" title=\"Worker1\"></a>Worker1</h3><ul>\n<li><p><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/shardddl/pessimist.go#L120-L124\">得到 master 的 exec operation</a></p>\n</li>\n<li><p><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L3042-L3043\">NewDDLJob</a> 并 handle</p>\n</li>\n<li><p><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1057\">addJob</a>：发送 job 给 DDLJobCh</p>\n</li>\n<li><p>syncDDL：之前 worker 起的协程接受到该 job</p>\n<ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1324\">拿到刚刚得到的 operation</a>，并且不会被跳过，因为 ignore = false</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Step-8\"><a href=\"#Step-8\" class=\"headerlink\" title=\"Step 8\"></a>Step 8</h2><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1344\">同步到下游</a></li>\n</ul>\n<h2 id=\"Step-9\"><a href=\"#Step-9\" class=\"headerlink\" title=\"Step 9\"></a>Step 9</h2><h3 id=\"Worker1-1\"><a href=\"#Worker1-1\" class=\"headerlink\" title=\"Worker1\"></a>Worker1</h3><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1384\">DoneOperationDeleteInfo</a>：发送 done operation 给 master 并删除 info</li>\n</ul>\n<h2 id=\"Step-10\"><a href=\"#Step-10\" class=\"headerlink\" title=\"Step 10\"></a>Step 10</h2><h3 id=\"Master-1\"><a href=\"#Master-1\" class=\"headerlink\" title=\"Master\"></a>Master</h3><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L509\">接受 done operation</a></li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L529\">markDone</a></li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L553\">putOpsForNonOwner</a>：给其他所有 non-owner 发送 skip info（skip done 是为了防止把 done 覆盖掉）</li>\n</ul>\n<h3 id=\"Worker2\"><a href=\"#Worker2\" class=\"headerlink\" title=\"Worker2\"></a>Worker2</h3><ul>\n<li>接受到了 no exec(skip) 的 operation，和 Step 7 类似，但是在 syncDDL 的时候会<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1325-L1328\">被 skip</a></li>\n</ul>\n<h2 id=\"Step-11-和-Step-9-相同\"><a href=\"#Step-11-和-Step-9-相同\" class=\"headerlink\" title=\"Step 11 和 Step 9 相同\"></a>Step 11 和 Step 9 相同</h2><h1 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h1><p>本节介绍了在悲观协调过程中，遇到第一条 DDL 语句，生成 Lock，到收到所有 DDL 语句，Lock 解除的过程。</p>\n<p>经过本节的学习，我们已经完全学会了 DM 悲观协调的过程。是不是也没那么复杂😏，但是在这个过程中，我们只知道 DDL 的处理方式，这个过程中的 DML 会怎么办呢？下一章揭晓。</p>\n<h1 id=\"五、疑似-bug\"><a href=\"#五、疑似-bug\" class=\"headerlink\" title=\"五、疑似 bug\"></a>五、疑似 bug</h1><ol>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L552-L559\">initShardingGroups</a> 中对 ShardingGroup.sources 进行了初始化，这里包含了该 targetTable 对应的所有 sourceTables</li>\n<li>在 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883\">TrySync</a> 的时候，却使用第一个 <code>sourceTable[0]</code>，来标记所有的 <code>DDL[]</code>，如果 <code>len(DDL[]) != 1</code>，则 remain 永远不可能为 0。因为 sourceTables 来源于 ddlInfo。而 DDLInfo 只存了<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2738-L2743\">第一条 ddl 的 ddlInfo</a>，实际上对于每一个 Split 之后的 DDL，都会 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2694\">genDDLInfo</a>。</li>\n<li>但是奇怪的是，代码中标注了<a href=\"http://errsyncerunitddlonmultipletable/\">不支持 multi-table DDL</a>，这个 error 在 pessimist/optimist mode 中都用到了。但是在现在看 pessimist 代码中，又看到其为 multi-table DDL 实现了部分相关逻辑。。。<strong>有毒</strong></li>\n<li>比如：</li>\n</ol>\n<ul>\n<li>https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2957-L2960</li>\n<li>https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L35</li>\n<li>。。。</li>\n</ul>\n","site":{"data":{}},"cover_type":"img","length":2729,"excerpt":"","more":"<h1 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h1><p>介绍了与悲观协调有关的各个数据结构之后，接下来将介绍一个 DM 系统从接受到第一条分表 DDL 开始，到所有该 DDL 对应的 Lock resolved 的全过程。</p>\n<blockquote>\n<p>本节内容皆参考 <a href=\"https://github.com/pingcap/tiflow/tree/release-6.0\">DM v6.0</a>，对现在而言，有可能已过时，欢迎大家提出意见～</p>\n</blockquote>\n<h1 id=\"二、Overview\"><a href=\"#二、Overview\" class=\"headerlink\" title=\"二、Overview\"></a>二、Overview</h1><p>假设现在起了 master 和两个 Worker，两个 Worker 分别绑定两个 Source（s1，s2），每个 Source 有两个分表（t1，t2），这四个表会 route 到一个 target table（tarTbl）中。在 DDL 到来之前，两个 worker 会创建好 ShardingGroupKeeper，里面只有一个 target table，两个 source table。</p>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283187.png\"></p>\n<p>两个 Worker 先后收到两个 Source 四个分表的同一条 DDL，表示为：</p>\n<ul>\n<li>DDL1：表示对 s1.t1 的 DDL。</li>\n<li>DDL2：表示对 s2.t1 的 DDL。</li>\n<li>DDL3：表示对 s1.t2 的 DDL。</li>\n<li>DDL4：表示对 s2.t2 的 DDL。</li>\n</ul>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283666.png\"></p>\n<h1 id=\"三、具体过程\"><a href=\"#三、具体过程\" class=\"headerlink\" title=\"三、具体过程\"></a>三、具体过程</h1><blockquote>\n<p>本小节 worker 对 DDL 的处理从 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2853\">handleQueryEventPessimistic</a> 开始，如果不知道在此之前的 DDL 做过哪些处理，请期待后续文章😁</p>\n</blockquote>\n<p>接下来将对上图中的步骤一一介绍</p>\n<h2 id=\"Step-1\"><a href=\"#Step-1\" class=\"headerlink\" title=\"Step 1\"></a>Step 1</h2><ol>\n<li>worker1 收到来自 source1 的 DDL1，会直接 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883\">TrySync</a>，这里返回了一大堆的参数，其实有用的就只是 <code>synced</code>，简单来说，里面只做了一件事：<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding_group.go#L215\">AddItem</a>。下面详细介绍一下 TrySync</li>\n</ol>\n<blockquote>\n<p>本节，假设该 DDL 不是 CreateTableStmt，如果是的话，也很简单，每次都是 remain &lt;=0，synced = true，但是只有第一次发送该 create table 的 worker 会 syncDDL。</p>\n</blockquote>\n<h3 id=\"TrySync\"><a href=\"#TrySync\" class=\"headerlink\" title=\"TrySync\"></a>TrySync</h3><p>想要知道 worker 在悲观协调的时候做了什么，必须要搞懂 TrySync 是怎么运作的。在此之前，我们来重新理解一下 ShardingGroupKeeper：</p>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283187.png\"></p>\n<p>单独拿出一个 ShardingGroup 举例（颜色代表 DDL 的种类）：</p>\n<h4 id=\"Example\"><a href=\"#Example\" class=\"headerlink\" title=\"Example\"></a>Example</h4><p>worker 收到了以下 DDL</p>\n<ul>\n<li>依次收到了 table1 橙色、黄色、绿色三条 DDL</li>\n<li>收到了 table2 橙色</li>\n<li>这个时候 <code>activeIdx = 0</code>，<code>remain = 1</code>，因为只有 table3 没有收到 active DDL 了</li>\n</ul>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283679.png\"></p>\n<ul>\n<li>如果在这个时候收到了 table3 橙色 DDL，<code>remain = 0</code>，处理了这条 DDL 之后，<code>active ++</code></li>\n</ul>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/image-1672713793518.png\" alt=\"image.png\"></p>\n<ul>\n<li>如果这个时候收到 table2 绿色 DDL，则会<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L197-L199\">报错</a>，悲观协调要求同一个 source table 中 DDL 必须有序</li>\n</ul>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283186.png\"></p>\n<ul>\n<li>如果 group 中所有的 DDL 都 resolved 了。则会<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L243-L246\">重置</a>一下 meta</li>\n</ul>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672403283692.png\"></p>\n<p>总结：<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding_group.go#L215\">AddItem</a> 就是上面图中把 DDLItem 放进 ShardingSequence 的过程</p>\n<h2 id=\"Step-2-与-Step-1-相同\"><a href=\"#Step-2-与-Step-1-相同\" class=\"headerlink\" title=\"Step 2 与 Step 1 相同\"></a>Step 2 与 Step 1 相同</h2><h2 id=\"Step-3\"><a href=\"#Step-3\" class=\"headerlink\" title=\"Step 3\"></a>Step 3</h2><p>由于 tarTbl 只有两个 source table：s1.t1 和 s1.t2，这时 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883\">TrySync</a> 后，<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2948\">synced = true</a>，说明该 worker ready</p>\n<h2 id=\"Step-4\"><a href=\"#Step-4\" class=\"headerlink\" title=\"Step 4\"></a>Step 4</h2><h3 id=\"worker1\"><a href=\"#worker1\" class=\"headerlink\" title=\"worker1\"></a>worker1</h3><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2985\">PutInfo</a>：发送 ready info 给 master（后面会详细介绍这个函数）</li>\n<li>之后会被阻塞，<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2992\">等待 master 发送 operation</a>。</li>\n</ul>\n<h3 id=\"Master\"><a href=\"#Master\" class=\"headerlink\" title=\"Master\"></a>Master</h3><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L177\">watchInfoPut</a>：成功监听到了</li>\n<li>handleInfoPut：master 也开始 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L474\">TrySync</a>，master 的 TrySync 相比 worker 中的要简单很多，每一个 Info 直接相当于该 source/worker 已 ready，所以直接统计是否所有 ready 即可</li>\n<li>由于这里是第一个 worker 发 info 给 master，所以需要<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/keeper.go#L49\">新建 Lock</a>，新建 Lock 过程中会获取该 task 所有的 source，并存到 lock 中，这样就知道还有多少 source 没 ready。显然还有 source2 没 ready。</li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L481-L485\">继续等待</a></li>\n</ul>\n<h2 id=\"Step-5-与-Step-3-相同\"><a href=\"#Step-5-与-Step-3-相同\" class=\"headerlink\" title=\"Step 5 与 Step 3 相同\"></a>Step 5 与 Step 3 相同</h2><h2 id=\"Step-6\"><a href=\"#Step-6\" class=\"headerlink\" title=\"Step 6\"></a>Step 6</h2><ul>\n<li>前面与 Step 4 相同，但是这时所有 source 都 ready 了，<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L486\">synced = true</a></li>\n</ul>\n<h2 id=\"Step-7\"><a href=\"#Step-7\" class=\"headerlink\" title=\"Step 7\"></a>Step 7</h2><h3 id=\"master\"><a href=\"#master\" class=\"headerlink\" title=\"master\"></a>master</h3><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L599\">putOpForOwner</a>：发送 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L604\">exec</a> operation to owner(worker1)</li>\n</ul>\n<h3 id=\"Worker1\"><a href=\"#Worker1\" class=\"headerlink\" title=\"Worker1\"></a>Worker1</h3><ul>\n<li><p><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/shardddl/pessimist.go#L120-L124\">得到 master 的 exec operation</a></p>\n</li>\n<li><p><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L3042-L3043\">NewDDLJob</a> 并 handle</p>\n</li>\n<li><p><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1057\">addJob</a>：发送 job 给 DDLJobCh</p>\n</li>\n<li><p>syncDDL：之前 worker 起的协程接受到该 job</p>\n<ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1324\">拿到刚刚得到的 operation</a>，并且不会被跳过，因为 ignore = false</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Step-8\"><a href=\"#Step-8\" class=\"headerlink\" title=\"Step 8\"></a>Step 8</h2><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1344\">同步到下游</a></li>\n</ul>\n<h2 id=\"Step-9\"><a href=\"#Step-9\" class=\"headerlink\" title=\"Step 9\"></a>Step 9</h2><h3 id=\"Worker1-1\"><a href=\"#Worker1-1\" class=\"headerlink\" title=\"Worker1\"></a>Worker1</h3><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1384\">DoneOperationDeleteInfo</a>：发送 done operation 给 master 并删除 info</li>\n</ul>\n<h2 id=\"Step-10\"><a href=\"#Step-10\" class=\"headerlink\" title=\"Step 10\"></a>Step 10</h2><h3 id=\"Master-1\"><a href=\"#Master-1\" class=\"headerlink\" title=\"Master\"></a>Master</h3><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L509\">接受 done operation</a></li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L529\">markDone</a></li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L553\">putOpsForNonOwner</a>：给其他所有 non-owner 发送 skip info（skip done 是为了防止把 done 覆盖掉）</li>\n</ul>\n<h3 id=\"Worker2\"><a href=\"#Worker2\" class=\"headerlink\" title=\"Worker2\"></a>Worker2</h3><ul>\n<li>接受到了 no exec(skip) 的 operation，和 Step 7 类似，但是在 syncDDL 的时候会<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1325-L1328\">被 skip</a></li>\n</ul>\n<h2 id=\"Step-11-和-Step-9-相同\"><a href=\"#Step-11-和-Step-9-相同\" class=\"headerlink\" title=\"Step 11 和 Step 9 相同\"></a>Step 11 和 Step 9 相同</h2><h1 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h1><p>本节介绍了在悲观协调过程中，遇到第一条 DDL 语句，生成 Lock，到收到所有 DDL 语句，Lock 解除的过程。</p>\n<p>经过本节的学习，我们已经完全学会了 DM 悲观协调的过程。是不是也没那么复杂😏，但是在这个过程中，我们只知道 DDL 的处理方式，这个过程中的 DML 会怎么办呢？下一章揭晓。</p>\n<h1 id=\"五、疑似-bug\"><a href=\"#五、疑似-bug\" class=\"headerlink\" title=\"五、疑似 bug\"></a>五、疑似 bug</h1><ol>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L552-L559\">initShardingGroups</a> 中对 ShardingGroup.sources 进行了初始化，这里包含了该 targetTable 对应的所有 sourceTables</li>\n<li>在 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2883\">TrySync</a> 的时候，却使用第一个 <code>sourceTable[0]</code>，来标记所有的 <code>DDL[]</code>，如果 <code>len(DDL[]) != 1</code>，则 remain 永远不可能为 0。因为 sourceTables 来源于 ddlInfo。而 DDLInfo 只存了<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2738-L2743\">第一条 ddl 的 ddlInfo</a>，实际上对于每一个 Split 之后的 DDL，都会 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2694\">genDDLInfo</a>。</li>\n<li>但是奇怪的是，代码中标注了<a href=\"http://errsyncerunitddlonmultipletable/\">不支持 multi-table DDL</a>，这个 error 在 pessimist/optimist mode 中都用到了。但是在现在看 pessimist 代码中，又看到其为 multi-table DDL 实现了部分相关逻辑。。。<strong>有毒</strong></li>\n<li>比如：</li>\n</ol>\n<ul>\n<li>https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2957-L2960</li>\n<li>https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/sharding-meta/shardmeta.go#L35</li>\n<li>。。。</li>\n</ul>\n"},{"title":"DM 数据旅程 02：分库分表悲观协调——03reSync","date":"2023-01-02T20:58:33.000Z","top_img":"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404522042.png","cover":"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404522042.png","_content":"\n# 一、概述\n\n在分库分表同步的过程中，不同的 DDL 之间，还会穿插着各种各样的 DML 语句，这些 DML 语句要如何处理呢？今天就来看看它们的处理过程——reSync。\n\n本节先介绍 reSync 的总流程，然后分为四个部分介绍 reSync：\n\n- 一阶段：reSync 之前\n- 开启 reSync\n- 二阶段：reSync 之后\n- 关闭 reSync\n\n> 本节内容皆参考 [DM v6.0](https://github.com/pingcap/tiflow/tree/release-6.0)，对现在而言，有可能已过时，欢迎大家提出意见～\n\n# 二、Overview\n\n1. 进入 lock 阶段后，在第一次 sync 的时候，会跳过被 active 影响到的 targetTable 对应的 DML\n2. 在 Lock resolved 之后，会回到第一次进入 lock 的 binlog Location 点，进行 reSync，把之前 skip 的 DML 重新 sync，这个阶段会跳过上次执行过的 DML。\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404522042.png)\n\n## 原理\n\n两种 DML 互相隔离，不会互相影响。\n\n# 三、过程\n\n## 1、一阶段\n\n### Skip\n\n在 handleRowsEvent 的时候，[判断该 event 是否需要 skip](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2368)：\n\n1. 通过 targetTable 得到对应的 group\n\n2. 通过 sourceTable 得到对应的 activeDDLItem，\n\n   1. 下图中 ID3 即不需要 skip\n\n   2. 如果已经收到 activeDDLItem\n\n      1. 如果该 DML 在 active 前面，不需要 skip\n      2. 如果该 DML 在 active 后面，则 skip\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404521513.png)\n\n## 2、开始 reSync\n\n[reSync 信号](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2970-L2975)：把 targetTable 和 binlog location 信息传递给主逻辑中，[重定向 streamer](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1843-L1864)。\n\n### ShardingReSync\n\n```go\n// ShardingReSync represents re-sync info for a sharding DDL group.\n\ntype ShardingReSync struct {\n\n    currLocation   binlog.Location // current DDL's binlog location, initialize to first DDL's location\n\n    latestLocation binlog.Location // latest DDL's binlog location\n\n    targetTable    *filter.Table\n\n    allResolved    bool\n\n}\n```\n\n用到的 `ShardingReSync` 结构体：\n\n- currLocation：用于重定向\n- latestLocation：用于判断 reSync 是否结束\n- targetTable：用于判断该 DML 是否需要 reSync\n- allResolved：与关闭 reSync 有关\n\n## 3、二阶段\n\n1. [判断是否 skip](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2333-L2337)\n2. 更新 `shardingReSync.currLocation` 并判断是否要结束 reSync\n\n- [XIDEvent](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2125-L2143)\n- [RotateEvent](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2285-L2300)\n- [RowsEvent](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2328-L2332)\n- [QueryEvent](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2629-L2645)\n\n## 4、关闭 reSync\n\n如果当前 binlog location 已经越过了 shardingReSync.lastestLocation，则重定向回去。根据是否 allResolved 有两种重定向方式，但貌似没有什么区别？\n\n# 四、总结\n\n经过 reSync 之后，悲观协调就结束了。reSync 的过程不是很复杂，主要包括两种操作：\n\n- 重定向\n- Skip\n\n接下来将会开始乐观协调的学习（希望😭\n","source":"_posts/DM-数据旅程-02：分库分表悲观协调——03reSync.md","raw":"---\ntitle: DM 数据旅程 02：分库分表悲观协调——03reSync\ndate: 2023-01-03 04:58:33\ntags:\n- DM\n- 源码阅读\ncategories:\n- DM 数据旅程\ntop_img: https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404522042.png\ncover: https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404522042.png\n---\n\n# 一、概述\n\n在分库分表同步的过程中，不同的 DDL 之间，还会穿插着各种各样的 DML 语句，这些 DML 语句要如何处理呢？今天就来看看它们的处理过程——reSync。\n\n本节先介绍 reSync 的总流程，然后分为四个部分介绍 reSync：\n\n- 一阶段：reSync 之前\n- 开启 reSync\n- 二阶段：reSync 之后\n- 关闭 reSync\n\n> 本节内容皆参考 [DM v6.0](https://github.com/pingcap/tiflow/tree/release-6.0)，对现在而言，有可能已过时，欢迎大家提出意见～\n\n# 二、Overview\n\n1. 进入 lock 阶段后，在第一次 sync 的时候，会跳过被 active 影响到的 targetTable 对应的 DML\n2. 在 Lock resolved 之后，会回到第一次进入 lock 的 binlog Location 点，进行 reSync，把之前 skip 的 DML 重新 sync，这个阶段会跳过上次执行过的 DML。\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404522042.png)\n\n## 原理\n\n两种 DML 互相隔离，不会互相影响。\n\n# 三、过程\n\n## 1、一阶段\n\n### Skip\n\n在 handleRowsEvent 的时候，[判断该 event 是否需要 skip](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2368)：\n\n1. 通过 targetTable 得到对应的 group\n\n2. 通过 sourceTable 得到对应的 activeDDLItem，\n\n   1. 下图中 ID3 即不需要 skip\n\n   2. 如果已经收到 activeDDLItem\n\n      1. 如果该 DML 在 active 前面，不需要 skip\n      2. 如果该 DML 在 active 后面，则 skip\n\n![](https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404521513.png)\n\n## 2、开始 reSync\n\n[reSync 信号](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2970-L2975)：把 targetTable 和 binlog location 信息传递给主逻辑中，[重定向 streamer](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1843-L1864)。\n\n### ShardingReSync\n\n```go\n// ShardingReSync represents re-sync info for a sharding DDL group.\n\ntype ShardingReSync struct {\n\n    currLocation   binlog.Location // current DDL's binlog location, initialize to first DDL's location\n\n    latestLocation binlog.Location // latest DDL's binlog location\n\n    targetTable    *filter.Table\n\n    allResolved    bool\n\n}\n```\n\n用到的 `ShardingReSync` 结构体：\n\n- currLocation：用于重定向\n- latestLocation：用于判断 reSync 是否结束\n- targetTable：用于判断该 DML 是否需要 reSync\n- allResolved：与关闭 reSync 有关\n\n## 3、二阶段\n\n1. [判断是否 skip](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2333-L2337)\n2. 更新 `shardingReSync.currLocation` 并判断是否要结束 reSync\n\n- [XIDEvent](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2125-L2143)\n- [RotateEvent](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2285-L2300)\n- [RowsEvent](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2328-L2332)\n- [QueryEvent](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2629-L2645)\n\n## 4、关闭 reSync\n\n如果当前 binlog location 已经越过了 shardingReSync.lastestLocation，则重定向回去。根据是否 allResolved 有两种重定向方式，但貌似没有什么区别？\n\n# 四、总结\n\n经过 reSync 之后，悲观协调就结束了。reSync 的过程不是很复杂，主要包括两种操作：\n\n- 重定向\n- Skip\n\n接下来将会开始乐观协调的学习（希望😭\n","slug":"DM-数据旅程-02：分库分表悲观协调——03reSync","published":1,"updated":"2024-06-16T07:00:14.111Z","_id":"clxh0oeka0000kbdy6mt69rq6","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h1><p>在分库分表同步的过程中，不同的 DDL 之间，还会穿插着各种各样的 DML 语句，这些 DML 语句要如何处理呢？今天就来看看它们的处理过程——reSync。</p>\n<p>本节先介绍 reSync 的总流程，然后分为四个部分介绍 reSync：</p>\n<ul>\n<li>一阶段：reSync 之前</li>\n<li>开启 reSync</li>\n<li>二阶段：reSync 之后</li>\n<li>关闭 reSync</li>\n</ul>\n<blockquote>\n<p>本节内容皆参考 <a href=\"https://github.com/pingcap/tiflow/tree/release-6.0\">DM v6.0</a>，对现在而言，有可能已过时，欢迎大家提出意见～</p>\n</blockquote>\n<h1 id=\"二、Overview\"><a href=\"#二、Overview\" class=\"headerlink\" title=\"二、Overview\"></a>二、Overview</h1><ol>\n<li>进入 lock 阶段后，在第一次 sync 的时候，会跳过被 active 影响到的 targetTable 对应的 DML</li>\n<li>在 Lock resolved 之后，会回到第一次进入 lock 的 binlog Location 点，进行 reSync，把之前 skip 的 DML 重新 sync，这个阶段会跳过上次执行过的 DML。</li>\n</ol>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404522042.png\"></p>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>两种 DML 互相隔离，不会互相影响。</p>\n<h1 id=\"三、过程\"><a href=\"#三、过程\" class=\"headerlink\" title=\"三、过程\"></a>三、过程</h1><h2 id=\"1、一阶段\"><a href=\"#1、一阶段\" class=\"headerlink\" title=\"1、一阶段\"></a>1、一阶段</h2><h3 id=\"Skip\"><a href=\"#Skip\" class=\"headerlink\" title=\"Skip\"></a>Skip</h3><p>在 handleRowsEvent 的时候，<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2368\">判断该 event 是否需要 skip</a>：</p>\n<ol>\n<li><p>通过 targetTable 得到对应的 group</p>\n</li>\n<li><p>通过 sourceTable 得到对应的 activeDDLItem，</p>\n<ol>\n<li><p>下图中 ID3 即不需要 skip</p>\n</li>\n<li><p>如果已经收到 activeDDLItem</p>\n<ol>\n<li>如果该 DML 在 active 前面，不需要 skip</li>\n<li>如果该 DML 在 active 后面，则 skip</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404521513.png\"></p>\n<h2 id=\"2、开始-reSync\"><a href=\"#2、开始-reSync\" class=\"headerlink\" title=\"2、开始 reSync\"></a>2、开始 reSync</h2><p><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2970-L2975\">reSync 信号</a>：把 targetTable 和 binlog location 信息传递给主逻辑中，<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1843-L1864\">重定向 streamer</a>。</p>\n<h3 id=\"ShardingReSync\"><a href=\"#ShardingReSync\" class=\"headerlink\" title=\"ShardingReSync\"></a>ShardingReSync</h3><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ShardingReSync represents re-sync info for a sharding DDL group.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> ShardingReSync <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    currLocation   binlog.Location <span class=\"comment\">// current DDL&#x27;s binlog location, initialize to first DDL&#x27;s location</span></span><br><span class=\"line\"></span><br><span class=\"line\">    latestLocation binlog.Location <span class=\"comment\">// latest DDL&#x27;s binlog location</span></span><br><span class=\"line\"></span><br><span class=\"line\">    targetTable    *filter.Table</span><br><span class=\"line\"></span><br><span class=\"line\">    allResolved    <span class=\"type\">bool</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>用到的 <code>ShardingReSync</code> 结构体：</p>\n<ul>\n<li>currLocation：用于重定向</li>\n<li>latestLocation：用于判断 reSync 是否结束</li>\n<li>targetTable：用于判断该 DML 是否需要 reSync</li>\n<li>allResolved：与关闭 reSync 有关</li>\n</ul>\n<h2 id=\"3、二阶段\"><a href=\"#3、二阶段\" class=\"headerlink\" title=\"3、二阶段\"></a>3、二阶段</h2><ol>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2333-L2337\">判断是否 skip</a></li>\n<li>更新 <code>shardingReSync.currLocation</code> 并判断是否要结束 reSync</li>\n</ol>\n<ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2125-L2143\">XIDEvent</a></li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2285-L2300\">RotateEvent</a></li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2328-L2332\">RowsEvent</a></li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2629-L2645\">QueryEvent</a></li>\n</ul>\n<h2 id=\"4、关闭-reSync\"><a href=\"#4、关闭-reSync\" class=\"headerlink\" title=\"4、关闭 reSync\"></a>4、关闭 reSync</h2><p>如果当前 binlog location 已经越过了 shardingReSync.lastestLocation，则重定向回去。根据是否 allResolved 有两种重定向方式，但貌似没有什么区别？</p>\n<h1 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h1><p>经过 reSync 之后，悲观协调就结束了。reSync 的过程不是很复杂，主要包括两种操作：</p>\n<ul>\n<li>重定向</li>\n<li>Skip</li>\n</ul>\n<p>接下来将会开始乐观协调的学习（希望😭</p>\n","site":{"data":{}},"cover_type":"img","length":1322,"excerpt":"","more":"<h1 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h1><p>在分库分表同步的过程中，不同的 DDL 之间，还会穿插着各种各样的 DML 语句，这些 DML 语句要如何处理呢？今天就来看看它们的处理过程——reSync。</p>\n<p>本节先介绍 reSync 的总流程，然后分为四个部分介绍 reSync：</p>\n<ul>\n<li>一阶段：reSync 之前</li>\n<li>开启 reSync</li>\n<li>二阶段：reSync 之后</li>\n<li>关闭 reSync</li>\n</ul>\n<blockquote>\n<p>本节内容皆参考 <a href=\"https://github.com/pingcap/tiflow/tree/release-6.0\">DM v6.0</a>，对现在而言，有可能已过时，欢迎大家提出意见～</p>\n</blockquote>\n<h1 id=\"二、Overview\"><a href=\"#二、Overview\" class=\"headerlink\" title=\"二、Overview\"></a>二、Overview</h1><ol>\n<li>进入 lock 阶段后，在第一次 sync 的时候，会跳过被 active 影响到的 targetTable 对应的 DML</li>\n<li>在 Lock resolved 之后，会回到第一次进入 lock 的 binlog Location 点，进行 reSync，把之前 skip 的 DML 重新 sync，这个阶段会跳过上次执行过的 DML。</li>\n</ol>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404522042.png\"></p>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>两种 DML 互相隔离，不会互相影响。</p>\n<h1 id=\"三、过程\"><a href=\"#三、过程\" class=\"headerlink\" title=\"三、过程\"></a>三、过程</h1><h2 id=\"1、一阶段\"><a href=\"#1、一阶段\" class=\"headerlink\" title=\"1、一阶段\"></a>1、一阶段</h2><h3 id=\"Skip\"><a href=\"#Skip\" class=\"headerlink\" title=\"Skip\"></a>Skip</h3><p>在 handleRowsEvent 的时候，<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2368\">判断该 event 是否需要 skip</a>：</p>\n<ol>\n<li><p>通过 targetTable 得到对应的 group</p>\n</li>\n<li><p>通过 sourceTable 得到对应的 activeDDLItem，</p>\n<ol>\n<li><p>下图中 ID3 即不需要 skip</p>\n</li>\n<li><p>如果已经收到 activeDDLItem</p>\n<ol>\n<li>如果该 DML 在 active 前面，不需要 skip</li>\n<li>如果该 DML 在 active 后面，则 skip</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<p><img src=\"https://tidb-blog.oss-cn-beijing.aliyuncs.com/media/unnamed-1672404521513.png\"></p>\n<h2 id=\"2、开始-reSync\"><a href=\"#2、开始-reSync\" class=\"headerlink\" title=\"2、开始 reSync\"></a>2、开始 reSync</h2><p><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2970-L2975\">reSync 信号</a>：把 targetTable 和 binlog location 信息传递给主逻辑中，<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L1843-L1864\">重定向 streamer</a>。</p>\n<h3 id=\"ShardingReSync\"><a href=\"#ShardingReSync\" class=\"headerlink\" title=\"ShardingReSync\"></a>ShardingReSync</h3><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ShardingReSync represents re-sync info for a sharding DDL group.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> ShardingReSync <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    currLocation   binlog.Location <span class=\"comment\">// current DDL&#x27;s binlog location, initialize to first DDL&#x27;s location</span></span><br><span class=\"line\"></span><br><span class=\"line\">    latestLocation binlog.Location <span class=\"comment\">// latest DDL&#x27;s binlog location</span></span><br><span class=\"line\"></span><br><span class=\"line\">    targetTable    *filter.Table</span><br><span class=\"line\"></span><br><span class=\"line\">    allResolved    <span class=\"type\">bool</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>用到的 <code>ShardingReSync</code> 结构体：</p>\n<ul>\n<li>currLocation：用于重定向</li>\n<li>latestLocation：用于判断 reSync 是否结束</li>\n<li>targetTable：用于判断该 DML 是否需要 reSync</li>\n<li>allResolved：与关闭 reSync 有关</li>\n</ul>\n<h2 id=\"3、二阶段\"><a href=\"#3、二阶段\" class=\"headerlink\" title=\"3、二阶段\"></a>3、二阶段</h2><ol>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2333-L2337\">判断是否 skip</a></li>\n<li>更新 <code>shardingReSync.currLocation</code> 并判断是否要结束 reSync</li>\n</ol>\n<ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2125-L2143\">XIDEvent</a></li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2285-L2300\">RotateEvent</a></li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2328-L2332\">RowsEvent</a></li>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L2629-L2645\">QueryEvent</a></li>\n</ul>\n<h2 id=\"4、关闭-reSync\"><a href=\"#4、关闭-reSync\" class=\"headerlink\" title=\"4、关闭 reSync\"></a>4、关闭 reSync</h2><p>如果当前 binlog location 已经越过了 shardingReSync.lastestLocation，则重定向回去。根据是否 allResolved 有两种重定向方式，但貌似没有什么区别？</p>\n<h1 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h1><p>经过 reSync 之后，悲观协调就结束了。reSync 的过程不是很复杂，主要包括两种操作：</p>\n<ul>\n<li>重定向</li>\n<li>Skip</li>\n</ul>\n<p>接下来将会开始乐观协调的学习（希望😭</p>\n"},{"title":"DM 数据旅程 02：分库分表悲观协调——01准备过程","date":"2023-01-02T19:50:33.000Z","cover":"/img/category/dm_shard.png","_content":"\n# 一、概述\n\n分库分表的悲观协调方法是 2018 年开发的特性，是 DM 首次支持 MySQL 分库分表的迁移。由于分库分表在各个公司中的应用实在太过广泛，所以只有在支持分库分表迁移后，DM 才有了工程实践的意义，否则只能算作一个玩具。这对 DM 来说意义重大。\n\n由于悲观协调的内容庞大，本节只讲述悲观协调的准备过程：\n\n- Master 的准备过程\n- Worker 的准备过程\n\n以及在悲观协调过程中至关重要的结构体：\n\n- Lock\n- Info\n- Operation\n- ShardingMeta\n- ShardingGroup\n- ...\n\n> 注：为了专注于我们的目的（悲观协调），本文不会对无关代码进行解读\n\n> 这一节外链中的代码，读者可能会产生这个逻辑为什么是这里的疑问。这是因为本节并没有完全按照顺序读代码。所以读者可以仅带着学习的心态阅读本节，暂时不需要知道它为什么在代码的这个地方。在下一节中会顺序阅读代码\n\n> 本节基于 [DM release-6.0.0](https://github.com/pingcap/tiflow/tree/release-6.0)\n\n# 二、Master\n\n## 1、Pessimist 和 LockKeeper\n\n- [NewPessimist](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/server.go#L140)：Pessimist 是 Master 处理悲观协调的结构体，其中最重要的成员是 `LockKeeper`。\n- `LockKeeper` 的作用是管理各种各样的 lock。\n\n```go\n// LockKeeper used to keep and handle DDL lock conveniently.\n\n// The lock information do not need to be persistent, and can be re-constructed from the shard DDL info.\n\ntype LockKeeper struct {\n\n    mu    sync.RWMutex\n\n    locks map[string]*Lock // lockID -> Lock\n\n}\n```\n\n- Lock 可以看作是每一个 ddl 影响的库表，这些库表分布在不同的 MySQL/source 中。由于在悲观协调过程中，数据流（binlog 流）不是停滞的，所以在数据流中，会源源不断地出现新 DDL，即新 lock。\n- 故 `LockKeeper` 就是管理这些 lock。\n\n```go\n// Lock represents the shard DDL lock in memory.\n\n// This information does not need to be persistent, and can be re-constructed from the shard DDL info.\n\ntype Lock struct {\n\n    mu sync.RWMutex\n\n\n\n    ID     string   // lock's ID\n\n    Task   string   // lock's corresponding task name\n\n    Owner  string   // Owner's source ID (not DM-worker's name)\n\n    DDLs   []string // DDL statements\n\n    remain int      // remain count of sources needed to receive DDL info\n\n\n\n    // whether the DDL info received from the source.\n\n    // if all of them have been ready, then we call the lock `synced`.\n\n    ready map[string]bool\n\n\n\n    // whether the operations have done (exec/skip the shard DDL).\n\n    // if all of them have done, then we call the lock `resolved`.\n\n    done map[string]bool\n\n}\n```\n\n## 2、Lock\n\n- ID 表现形式为 [${task}-${schema}.${table}](https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/utils/common.go#L223)，从 LockKeeper 的结构可以看到同一任务同一表下只能有一个 lock，如果遇到了不同的 DDL，影响的又是同任务同表，则[报错](https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/lock.go#L72-L74)。\n- DDLs 为什么是 `[]string`？因为这里是经过 `Split` 的 DDLs，单条 DDL 可能会被 Split 成多条 DDL。\n- Remain 表示剩余的还未收到 DDL 的 source/worker（以下 worker 都表示 source/worker 对）数量。即如果 worker 把这个 Lock 相关的 DDLs（实际上是 info 的形式）发给 master，master 则把 `remain --`。\n- Ready 和 remain 表达相同的意思，remain 即表示 ready 中为 `true` 的个数\n- Done 表示 operation 结束的 worker 的状态\n\n> 注意：下面说的所有 worker 都 ready 即是 **remain <= 0**，代码中即是 **synced** = true。这里创造的概念过多，应该收束一下，减少代码的理解难度。\n\n> TODO：可以把代码中的 remain 改成 noReadies；synced 改成 allReady\n\n## 3、Info\n\n```go\n// Info represents the shard DDL information.\n\n// This information should be persistent in etcd so can be retrieved after the DM-master leader restarted or changed.\n\n// NOTE: `Task` and `Source` are redundant in the etcd key path for convenient.\n\ntype Info struct {\n\n    Task   string   `json:\"task\"`   // data migration task name\n\n    Source string   `json:\"source\"` // upstream source ID\n\n    Schema string   `json:\"schema\"` // schema name of the DDL\n\n    Table  string   `json:\"table\"`  // table name of the DDL\n\n    DDLs   []string `json:\"ddls\"`   // DDL statements\n\n}\n```\n\nInfo 并没有什么特别的地方，只是用作 worker 通知 master，某 lock ready 的消息。\n\n## 4、Operation\n\n```go\n// Operation represents a shard DDL coordinate operation.\n\n// This information should be persistent in etcd so can be retrieved after the DM-master leader restarted or changed.\n\n// NOTE: `Task` and `Source` are redundant in the etcd key path for convenient.\n\ntype Operation struct {\n\n    ID     string   `json:\"id\"`     // the corresponding DDL lock ID\n\n    Task   string   `json:\"task\"`   // data migration task name\n\n    Source string   `json:\"source\"` // upstream source ID\n\n    DDLs   []string `json:\"ddls\"`   // DDL statements\n\n    Exec   bool     `json:\"exec\"`   // execute or skip the DDL statements\n\n    Done   bool     `json:\"done\"`   // whether the `Exec` operation has done\n\n\n\n    // only used to report to the caller of the watcher, do not marsh it.\n\n    // if it's true, it means the Operation has been deleted in etcd.\n\n    IsDeleted bool `json:\"-\"`\n\n}\n```\n\n- Exec：是 master 向 worker 发送消息时所用到的字段。它告知该 worker 是否需要执行 DDL，只需要 owner 执行 DDL\n- Done：是 worker 向 master 发送消息时所用到的字段。它告知 master 该 worker done 了。done 并不代表该 worker 执行了 DDL，而是表示一种状态，因为只有 owner 可以执行 DDL，non-owner done 可以当作 non-worker 接受到了 DDL 已执行的信息的确认。\n\n## 3、Start\n\n> 以下可以直接在代码中搜索对应的名字，请务必与对应代码一起阅读！\n\n- s.pessimist.Start\n\n- p.run\n\n  - watchInfoOperation\n\n    - pessimism.WatchInfoPut：等待 worker 发送 info\n\n    - p.handleInfoPut：\n\n      - 收到 Worker 发送的 info 之后，意味着该 worker [已 ready](https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/lock.go#L87-L88)\n      - 如果这个时候所有的 source/worker 都 [ready（synced）](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L486) 了，则可以[发送一个 exec operation 给该 lock 的 owner](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L602-L611)（第一个[创建 lock](https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/keeper.go#L49) 的 worker）\n\n    - pessimism.WatchOperationPut：\n\n      - 等待 worker 发送 operation done。\n      - 这里的 operation 和 上面发送的 operation 其实是一样的，这里监听的没有指定 [task 和 source](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L192)，上面发送的 operation 是[指定 task 和 source](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L604) 的。所以上面发送的 operation 这里也会监听到，\n\n    - p.handleOperationPut：\n\n      - 收到 [not done ](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L509-L512)operation 这里并不进行操作。即上面发送 exec operation 的时候没有 done。\n\n      - 当收到 operation is done 时，才进行一系列操作。即从 worker 发送过来的 done operation。\n\n        - 首先 markDone\n        - 如果是 owner done 了，还会对 non-owner 发送 [exec operation](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L553)，督促 non-owner done\n        - 如果所有的 worker 都 done 了（即 resolved），则[把 lock 释放](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L533)\n\n  - 错误处理\n\n# 三、Worker\n\n## 1、Pessimist\n\n```go\n// Pessimist used to coordinate the shard DDL migration in pessimism mode.\n\ntype Pessimist struct {\n\n    mu sync.RWMutex\n\n\n\n    logger log.Logger\n\n    cli    *clientv3.Client\n\n    task   string\n\n    source string\n\n\n\n    // the shard DDL info which is pending to handle.\n\n    pendingInfo *pessimism.Info\n\n    // the shard DDL lock operation which is pending to handle.\n\n    pendingOp *pessimism.Operation\n\n}\n```\n\n- [NewPessimist](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L252)：worker 中的 pessimist 不同于 master 中的 pessimist。它只保存了 `pendingInfo` 和 `pendingOp`，用于保存当前的 Info 和 Operation\n\n## 2、ShardingGroupKeeper\n\n- [NewShardingGroupKeeper](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L277)：其中最重要的结构体就是 `shardingGroup`。`shardingGroup` 和 master 中的 `Lock` 类似，也是用于管理 DDL 影响到的 table（在 Lock 中是 source/worker）。\n\n```go\n// ShardingGroupKeeper used to keep ShardingGroup.\n\ntype ShardingGroupKeeper struct {\n\n    sync.RWMutex\n\n    groups map[string]*ShardingGroup // target table ID -> ShardingGroup\n\n    cfg    *config.SubTaskConfig\n\n\n\n    shardMetaSchema    string\n\n    shardMetaTable     string\n\n    shardMetaTableName string\n\n\n\n    db     *conn.BaseDB\n\n    dbConn *dbconn.DBConn\n\n\n\n    tctx *tcontext.Context\n\n}\n```\n\n## 3、ShardingGroup\n\n```go\n// ShardingGroup represents a sharding DDL sync group.\n\ntype ShardingGroup struct {\n\n    sync.RWMutex\n\n    // remain count waiting for syncing\n\n    // == len(sources):  DDL syncing not started or resolved\n\n    // == 0: all DDLs synced, will be reset to len(sources) after resolved combining with other dm-workers\n\n    // (0, len(sources)): waiting for syncing\n\n    // NOTE: we can make remain to be configurable if needed\n\n    remain       int\n\n    sources      map[string]bool // source table ID -> whether source table's DDL synced\n\n    IsSchemaOnly bool            // whether is a schema (database) only DDL TODO: zxc add schema-level syncing support later\n\n\n\n    sourceID string                  // associate dm-worker source ID\n\n    meta     *shardmeta.ShardingMeta // sharding sequence meta storage\n\n\n\n    firstLocation    *binlog.Location // first DDL's binlog pos and gtid, used to restrain the global checkpoint when un-resolved\n\n    firstEndLocation *binlog.Location // first DDL's binlog End_log_pos and gtid, used to re-direct binlog streamer after synced\n\n    ddls             []string         // DDL which current in syncing\n\n\n\n    flavor     string\n\n    enableGTID bool\n\n}\n```\n\n- Remain 和 Lock 中的 remain 意义完全一样，但是这里指 table 是否 ready（现代码中用的 synced）\n\n> whether source table's DDL synced\n\n> TODO：应该统一概念，这里也用 ready 表示\n\n- sources：和 Lock 中的 ready 类似\n- firstLocation/firstEndLocation/ddls：这三个其实在 meta 中都有保存，所以感觉其实没啥用\n- meta：里面保存着所有的有用的信息，下面详细说\n\n## 4、ShardingMeta\n\n这些信息会被持久化到磁盘中\n\n```go\n// ShardingMeta stores sharding ddl sequence\n\n// including global sequence and each source's own sequence\n\n// NOTE: sharding meta is not thread safe, it must be used in thread safe context.\n\ntype ShardingMeta struct {\n\n    activeIdx int                          // the first unsynced DDL index\n\n    global    *ShardingSequence            // merged sharding sequence of all source tables\n\n    sources   map[string]*ShardingSequence // source table ID -> its sharding sequence\n\n    tableName string                       // table name (with schema) used in downstream meta db\n\n\n\n    enableGTID bool // whether enableGTID, used to compare location\n\n}\n```\n\n- activeIdx：表示当前活跃的 DDL 下标，即现在被哪个 DDL 卡住了\n- global：表示全局的 DDL 序列，即所有 table 中最长的\n- sources：表示各个 table 的 DDL 序列\n\n## 5、ShardingSequence 和 DDLItem\n\n```go\n// ShardingSequence records a list of DDLItem.\n\ntype ShardingSequence struct {\n\n    Items []*DDLItem `json:\"items\"`\n\n}\n```\n\n```go\n// DDLItem records ddl information used in sharding sequence organization.\n\ntype DDLItem struct {\n\n    FirstLocation binlog.Location `json:\"-\"`      // first DDL's binlog Pos, not the End_log_pos of the event\n\n    DDLs          []string        `json:\"ddls\"`   // DDLs, these ddls are in the same QueryEvent\n\n    Source        string          `json:\"source\"` // source table ID\n\n\n\n    // just used for json's marshal and unmarshal, because gtid.Set in FirstLocation is interface,\n\n    // can't be marshal and unmarshal\n\n    FirstPosition mysql.Position `json:\"first-position\"`\n\n    FirstGTIDSet  string         `json:\"first-gtid-set\"`\n\n}\n```\n\n这里的 DDLItem 和 Lock 中的 \\[]DDL 其实是一样的，可以看到一个 DDLItem 中也包含多个 DDL。但是这里的 DDLItem 中封装了更多的信息：\n\n> DDLs \\[]string \\`json:\"ddls\"\\` // DDLs, these ddls are in the same QueryEvent\n\n- FirstLocation：DDL 开始的位点，主要用于识别该 DDL 之前是否来过了。\n\n## 6、Init\n\n- s.sgk.Init()：在下游创建库表 `dm_meta.($task)_syncer_sharding_meta`\n- s.initShardingGroups\n\n> TODO：可用 `utils.FetchTargetDoTables()` 替换 `fromDB.FetchAllDoTables`\n\n1. s.sgk.LoadShardMeta：把数据读出来，存到内存里\n2. s.sgk.AddGroup：把 ShardingGroup 恢复\n\n- Reset\n\n## 7、Start\n\n- 启动 syncDDL 线程，等待 DDL job\n\n# 四、总结\n\n本小节主要介绍了在悲观协调中：\n\n- 会用到的各种数据结构\n- Master 运行了几个线程，等待 worker 中信息的来临\n- Worker 运行了 syncDDL 线程，等待着 DDL 到来\n\n这一节中，罗列了特别多的概念，看不懂是正常的！在下一节，将从 worker 接受到一条 DDL 开始，直到这条 DDL 的 lock 解除的过程。在这个过程中，我们来学习这些结构体到底是怎么用的。\n\n> 抱歉第二章就是悲观协调这个功能😂，本来想让系列文章的难度更加平滑一点的，但是人太懒了一拖再拖😂。为了避免再拖下去，先把写了的存活发出来吧！\n","source":"_posts/DM-数据旅程-02：分库分表悲观协调——01准备过程.md","raw":"---\ntitle: DM 数据旅程 02：分库分表悲观协调——01准备过程\ndate: 2023-01-03 03:50:33\ntags:\n- DM\n- 源码阅读\ncategories:\n- DM 数据旅程\ncover: /img/category/dm_shard.png\n---\n\n# 一、概述\n\n分库分表的悲观协调方法是 2018 年开发的特性，是 DM 首次支持 MySQL 分库分表的迁移。由于分库分表在各个公司中的应用实在太过广泛，所以只有在支持分库分表迁移后，DM 才有了工程实践的意义，否则只能算作一个玩具。这对 DM 来说意义重大。\n\n由于悲观协调的内容庞大，本节只讲述悲观协调的准备过程：\n\n- Master 的准备过程\n- Worker 的准备过程\n\n以及在悲观协调过程中至关重要的结构体：\n\n- Lock\n- Info\n- Operation\n- ShardingMeta\n- ShardingGroup\n- ...\n\n> 注：为了专注于我们的目的（悲观协调），本文不会对无关代码进行解读\n\n> 这一节外链中的代码，读者可能会产生这个逻辑为什么是这里的疑问。这是因为本节并没有完全按照顺序读代码。所以读者可以仅带着学习的心态阅读本节，暂时不需要知道它为什么在代码的这个地方。在下一节中会顺序阅读代码\n\n> 本节基于 [DM release-6.0.0](https://github.com/pingcap/tiflow/tree/release-6.0)\n\n# 二、Master\n\n## 1、Pessimist 和 LockKeeper\n\n- [NewPessimist](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/server.go#L140)：Pessimist 是 Master 处理悲观协调的结构体，其中最重要的成员是 `LockKeeper`。\n- `LockKeeper` 的作用是管理各种各样的 lock。\n\n```go\n// LockKeeper used to keep and handle DDL lock conveniently.\n\n// The lock information do not need to be persistent, and can be re-constructed from the shard DDL info.\n\ntype LockKeeper struct {\n\n    mu    sync.RWMutex\n\n    locks map[string]*Lock // lockID -> Lock\n\n}\n```\n\n- Lock 可以看作是每一个 ddl 影响的库表，这些库表分布在不同的 MySQL/source 中。由于在悲观协调过程中，数据流（binlog 流）不是停滞的，所以在数据流中，会源源不断地出现新 DDL，即新 lock。\n- 故 `LockKeeper` 就是管理这些 lock。\n\n```go\n// Lock represents the shard DDL lock in memory.\n\n// This information does not need to be persistent, and can be re-constructed from the shard DDL info.\n\ntype Lock struct {\n\n    mu sync.RWMutex\n\n\n\n    ID     string   // lock's ID\n\n    Task   string   // lock's corresponding task name\n\n    Owner  string   // Owner's source ID (not DM-worker's name)\n\n    DDLs   []string // DDL statements\n\n    remain int      // remain count of sources needed to receive DDL info\n\n\n\n    // whether the DDL info received from the source.\n\n    // if all of them have been ready, then we call the lock `synced`.\n\n    ready map[string]bool\n\n\n\n    // whether the operations have done (exec/skip the shard DDL).\n\n    // if all of them have done, then we call the lock `resolved`.\n\n    done map[string]bool\n\n}\n```\n\n## 2、Lock\n\n- ID 表现形式为 [${task}-${schema}.${table}](https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/utils/common.go#L223)，从 LockKeeper 的结构可以看到同一任务同一表下只能有一个 lock，如果遇到了不同的 DDL，影响的又是同任务同表，则[报错](https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/lock.go#L72-L74)。\n- DDLs 为什么是 `[]string`？因为这里是经过 `Split` 的 DDLs，单条 DDL 可能会被 Split 成多条 DDL。\n- Remain 表示剩余的还未收到 DDL 的 source/worker（以下 worker 都表示 source/worker 对）数量。即如果 worker 把这个 Lock 相关的 DDLs（实际上是 info 的形式）发给 master，master 则把 `remain --`。\n- Ready 和 remain 表达相同的意思，remain 即表示 ready 中为 `true` 的个数\n- Done 表示 operation 结束的 worker 的状态\n\n> 注意：下面说的所有 worker 都 ready 即是 **remain <= 0**，代码中即是 **synced** = true。这里创造的概念过多，应该收束一下，减少代码的理解难度。\n\n> TODO：可以把代码中的 remain 改成 noReadies；synced 改成 allReady\n\n## 3、Info\n\n```go\n// Info represents the shard DDL information.\n\n// This information should be persistent in etcd so can be retrieved after the DM-master leader restarted or changed.\n\n// NOTE: `Task` and `Source` are redundant in the etcd key path for convenient.\n\ntype Info struct {\n\n    Task   string   `json:\"task\"`   // data migration task name\n\n    Source string   `json:\"source\"` // upstream source ID\n\n    Schema string   `json:\"schema\"` // schema name of the DDL\n\n    Table  string   `json:\"table\"`  // table name of the DDL\n\n    DDLs   []string `json:\"ddls\"`   // DDL statements\n\n}\n```\n\nInfo 并没有什么特别的地方，只是用作 worker 通知 master，某 lock ready 的消息。\n\n## 4、Operation\n\n```go\n// Operation represents a shard DDL coordinate operation.\n\n// This information should be persistent in etcd so can be retrieved after the DM-master leader restarted or changed.\n\n// NOTE: `Task` and `Source` are redundant in the etcd key path for convenient.\n\ntype Operation struct {\n\n    ID     string   `json:\"id\"`     // the corresponding DDL lock ID\n\n    Task   string   `json:\"task\"`   // data migration task name\n\n    Source string   `json:\"source\"` // upstream source ID\n\n    DDLs   []string `json:\"ddls\"`   // DDL statements\n\n    Exec   bool     `json:\"exec\"`   // execute or skip the DDL statements\n\n    Done   bool     `json:\"done\"`   // whether the `Exec` operation has done\n\n\n\n    // only used to report to the caller of the watcher, do not marsh it.\n\n    // if it's true, it means the Operation has been deleted in etcd.\n\n    IsDeleted bool `json:\"-\"`\n\n}\n```\n\n- Exec：是 master 向 worker 发送消息时所用到的字段。它告知该 worker 是否需要执行 DDL，只需要 owner 执行 DDL\n- Done：是 worker 向 master 发送消息时所用到的字段。它告知 master 该 worker done 了。done 并不代表该 worker 执行了 DDL，而是表示一种状态，因为只有 owner 可以执行 DDL，non-owner done 可以当作 non-worker 接受到了 DDL 已执行的信息的确认。\n\n## 3、Start\n\n> 以下可以直接在代码中搜索对应的名字，请务必与对应代码一起阅读！\n\n- s.pessimist.Start\n\n- p.run\n\n  - watchInfoOperation\n\n    - pessimism.WatchInfoPut：等待 worker 发送 info\n\n    - p.handleInfoPut：\n\n      - 收到 Worker 发送的 info 之后，意味着该 worker [已 ready](https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/lock.go#L87-L88)\n      - 如果这个时候所有的 source/worker 都 [ready（synced）](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L486) 了，则可以[发送一个 exec operation 给该 lock 的 owner](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L602-L611)（第一个[创建 lock](https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/keeper.go#L49) 的 worker）\n\n    - pessimism.WatchOperationPut：\n\n      - 等待 worker 发送 operation done。\n      - 这里的 operation 和 上面发送的 operation 其实是一样的，这里监听的没有指定 [task 和 source](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L192)，上面发送的 operation 是[指定 task 和 source](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L604) 的。所以上面发送的 operation 这里也会监听到，\n\n    - p.handleOperationPut：\n\n      - 收到 [not done ](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L509-L512)operation 这里并不进行操作。即上面发送 exec operation 的时候没有 done。\n\n      - 当收到 operation is done 时，才进行一系列操作。即从 worker 发送过来的 done operation。\n\n        - 首先 markDone\n        - 如果是 owner done 了，还会对 non-owner 发送 [exec operation](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L553)，督促 non-owner done\n        - 如果所有的 worker 都 done 了（即 resolved），则[把 lock 释放](https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L533)\n\n  - 错误处理\n\n# 三、Worker\n\n## 1、Pessimist\n\n```go\n// Pessimist used to coordinate the shard DDL migration in pessimism mode.\n\ntype Pessimist struct {\n\n    mu sync.RWMutex\n\n\n\n    logger log.Logger\n\n    cli    *clientv3.Client\n\n    task   string\n\n    source string\n\n\n\n    // the shard DDL info which is pending to handle.\n\n    pendingInfo *pessimism.Info\n\n    // the shard DDL lock operation which is pending to handle.\n\n    pendingOp *pessimism.Operation\n\n}\n```\n\n- [NewPessimist](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L252)：worker 中的 pessimist 不同于 master 中的 pessimist。它只保存了 `pendingInfo` 和 `pendingOp`，用于保存当前的 Info 和 Operation\n\n## 2、ShardingGroupKeeper\n\n- [NewShardingGroupKeeper](https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L277)：其中最重要的结构体就是 `shardingGroup`。`shardingGroup` 和 master 中的 `Lock` 类似，也是用于管理 DDL 影响到的 table（在 Lock 中是 source/worker）。\n\n```go\n// ShardingGroupKeeper used to keep ShardingGroup.\n\ntype ShardingGroupKeeper struct {\n\n    sync.RWMutex\n\n    groups map[string]*ShardingGroup // target table ID -> ShardingGroup\n\n    cfg    *config.SubTaskConfig\n\n\n\n    shardMetaSchema    string\n\n    shardMetaTable     string\n\n    shardMetaTableName string\n\n\n\n    db     *conn.BaseDB\n\n    dbConn *dbconn.DBConn\n\n\n\n    tctx *tcontext.Context\n\n}\n```\n\n## 3、ShardingGroup\n\n```go\n// ShardingGroup represents a sharding DDL sync group.\n\ntype ShardingGroup struct {\n\n    sync.RWMutex\n\n    // remain count waiting for syncing\n\n    // == len(sources):  DDL syncing not started or resolved\n\n    // == 0: all DDLs synced, will be reset to len(sources) after resolved combining with other dm-workers\n\n    // (0, len(sources)): waiting for syncing\n\n    // NOTE: we can make remain to be configurable if needed\n\n    remain       int\n\n    sources      map[string]bool // source table ID -> whether source table's DDL synced\n\n    IsSchemaOnly bool            // whether is a schema (database) only DDL TODO: zxc add schema-level syncing support later\n\n\n\n    sourceID string                  // associate dm-worker source ID\n\n    meta     *shardmeta.ShardingMeta // sharding sequence meta storage\n\n\n\n    firstLocation    *binlog.Location // first DDL's binlog pos and gtid, used to restrain the global checkpoint when un-resolved\n\n    firstEndLocation *binlog.Location // first DDL's binlog End_log_pos and gtid, used to re-direct binlog streamer after synced\n\n    ddls             []string         // DDL which current in syncing\n\n\n\n    flavor     string\n\n    enableGTID bool\n\n}\n```\n\n- Remain 和 Lock 中的 remain 意义完全一样，但是这里指 table 是否 ready（现代码中用的 synced）\n\n> whether source table's DDL synced\n\n> TODO：应该统一概念，这里也用 ready 表示\n\n- sources：和 Lock 中的 ready 类似\n- firstLocation/firstEndLocation/ddls：这三个其实在 meta 中都有保存，所以感觉其实没啥用\n- meta：里面保存着所有的有用的信息，下面详细说\n\n## 4、ShardingMeta\n\n这些信息会被持久化到磁盘中\n\n```go\n// ShardingMeta stores sharding ddl sequence\n\n// including global sequence and each source's own sequence\n\n// NOTE: sharding meta is not thread safe, it must be used in thread safe context.\n\ntype ShardingMeta struct {\n\n    activeIdx int                          // the first unsynced DDL index\n\n    global    *ShardingSequence            // merged sharding sequence of all source tables\n\n    sources   map[string]*ShardingSequence // source table ID -> its sharding sequence\n\n    tableName string                       // table name (with schema) used in downstream meta db\n\n\n\n    enableGTID bool // whether enableGTID, used to compare location\n\n}\n```\n\n- activeIdx：表示当前活跃的 DDL 下标，即现在被哪个 DDL 卡住了\n- global：表示全局的 DDL 序列，即所有 table 中最长的\n- sources：表示各个 table 的 DDL 序列\n\n## 5、ShardingSequence 和 DDLItem\n\n```go\n// ShardingSequence records a list of DDLItem.\n\ntype ShardingSequence struct {\n\n    Items []*DDLItem `json:\"items\"`\n\n}\n```\n\n```go\n// DDLItem records ddl information used in sharding sequence organization.\n\ntype DDLItem struct {\n\n    FirstLocation binlog.Location `json:\"-\"`      // first DDL's binlog Pos, not the End_log_pos of the event\n\n    DDLs          []string        `json:\"ddls\"`   // DDLs, these ddls are in the same QueryEvent\n\n    Source        string          `json:\"source\"` // source table ID\n\n\n\n    // just used for json's marshal and unmarshal, because gtid.Set in FirstLocation is interface,\n\n    // can't be marshal and unmarshal\n\n    FirstPosition mysql.Position `json:\"first-position\"`\n\n    FirstGTIDSet  string         `json:\"first-gtid-set\"`\n\n}\n```\n\n这里的 DDLItem 和 Lock 中的 \\[]DDL 其实是一样的，可以看到一个 DDLItem 中也包含多个 DDL。但是这里的 DDLItem 中封装了更多的信息：\n\n> DDLs \\[]string \\`json:\"ddls\"\\` // DDLs, these ddls are in the same QueryEvent\n\n- FirstLocation：DDL 开始的位点，主要用于识别该 DDL 之前是否来过了。\n\n## 6、Init\n\n- s.sgk.Init()：在下游创建库表 `dm_meta.($task)_syncer_sharding_meta`\n- s.initShardingGroups\n\n> TODO：可用 `utils.FetchTargetDoTables()` 替换 `fromDB.FetchAllDoTables`\n\n1. s.sgk.LoadShardMeta：把数据读出来，存到内存里\n2. s.sgk.AddGroup：把 ShardingGroup 恢复\n\n- Reset\n\n## 7、Start\n\n- 启动 syncDDL 线程，等待 DDL job\n\n# 四、总结\n\n本小节主要介绍了在悲观协调中：\n\n- 会用到的各种数据结构\n- Master 运行了几个线程，等待 worker 中信息的来临\n- Worker 运行了 syncDDL 线程，等待着 DDL 到来\n\n这一节中，罗列了特别多的概念，看不懂是正常的！在下一节，将从 worker 接受到一条 DDL 开始，直到这条 DDL 的 lock 解除的过程。在这个过程中，我们来学习这些结构体到底是怎么用的。\n\n> 抱歉第二章就是悲观协调这个功能😂，本来想让系列文章的难度更加平滑一点的，但是人太懒了一拖再拖😂。为了避免再拖下去，先把写了的存活发出来吧！\n","slug":"DM-数据旅程-02：分库分表悲观协调——01准备过程","published":1,"updated":"2024-06-16T07:10:04.519Z","_id":"clxh0zy370000hfdy585eg5ei","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h1><p>分库分表的悲观协调方法是 2018 年开发的特性，是 DM 首次支持 MySQL 分库分表的迁移。由于分库分表在各个公司中的应用实在太过广泛，所以只有在支持分库分表迁移后，DM 才有了工程实践的意义，否则只能算作一个玩具。这对 DM 来说意义重大。</p>\n<p>由于悲观协调的内容庞大，本节只讲述悲观协调的准备过程：</p>\n<ul>\n<li>Master 的准备过程</li>\n<li>Worker 的准备过程</li>\n</ul>\n<p>以及在悲观协调过程中至关重要的结构体：</p>\n<ul>\n<li>Lock</li>\n<li>Info</li>\n<li>Operation</li>\n<li>ShardingMeta</li>\n<li>ShardingGroup</li>\n<li>…</li>\n</ul>\n<blockquote>\n<p>注：为了专注于我们的目的（悲观协调），本文不会对无关代码进行解读</p>\n</blockquote>\n<blockquote>\n<p>这一节外链中的代码，读者可能会产生这个逻辑为什么是这里的疑问。这是因为本节并没有完全按照顺序读代码。所以读者可以仅带着学习的心态阅读本节，暂时不需要知道它为什么在代码的这个地方。在下一节中会顺序阅读代码</p>\n</blockquote>\n<blockquote>\n<p>本节基于 <a href=\"https://github.com/pingcap/tiflow/tree/release-6.0\">DM release-6.0.0</a></p>\n</blockquote>\n<h1 id=\"二、Master\"><a href=\"#二、Master\" class=\"headerlink\" title=\"二、Master\"></a>二、Master</h1><h2 id=\"1、Pessimist-和-LockKeeper\"><a href=\"#1、Pessimist-和-LockKeeper\" class=\"headerlink\" title=\"1、Pessimist 和 LockKeeper\"></a>1、Pessimist 和 LockKeeper</h2><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/server.go#L140\">NewPessimist</a>：Pessimist 是 Master 处理悲观协调的结构体，其中最重要的成员是 <code>LockKeeper</code>。</li>\n<li><code>LockKeeper</code> 的作用是管理各种各样的 lock。</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// LockKeeper used to keep and handle DDL lock conveniently.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// The lock information do not need to be persistent, and can be re-constructed from the shard DDL info.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> LockKeeper <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    mu    sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">    locks <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]*Lock <span class=\"comment\">// lockID -&gt; Lock</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Lock 可以看作是每一个 ddl 影响的库表，这些库表分布在不同的 MySQL/source 中。由于在悲观协调过程中，数据流（binlog 流）不是停滞的，所以在数据流中，会源源不断地出现新 DDL，即新 lock。</li>\n<li>故 <code>LockKeeper</code> 就是管理这些 lock。</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Lock represents the shard DDL lock in memory.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// This information does not need to be persistent, and can be re-constructed from the shard DDL info.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Lock <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    mu sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    ID     <span class=\"type\">string</span>   <span class=\"comment\">// lock&#x27;s ID</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Task   <span class=\"type\">string</span>   <span class=\"comment\">// lock&#x27;s corresponding task name</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Owner  <span class=\"type\">string</span>   <span class=\"comment\">// Owner&#x27;s source ID (not DM-worker&#x27;s name)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    DDLs   []<span class=\"type\">string</span> <span class=\"comment\">// DDL statements</span></span><br><span class=\"line\"></span><br><span class=\"line\">    remain <span class=\"type\">int</span>      <span class=\"comment\">// remain count of sources needed to receive DDL info</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// whether the DDL info received from the source.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// if all of them have been ready, then we call the lock `synced`.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ready <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]<span class=\"type\">bool</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// whether the operations have done (exec/skip the shard DDL).</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// if all of them have done, then we call the lock `resolved`.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    done <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]<span class=\"type\">bool</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2、Lock\"><a href=\"#2、Lock\" class=\"headerlink\" title=\"2、Lock\"></a>2、Lock</h2><ul>\n<li>ID 表现形式为 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/utils/common.go#L223\">${task}-${schema}.${table}</a>，从 LockKeeper 的结构可以看到同一任务同一表下只能有一个 lock，如果遇到了不同的 DDL，影响的又是同任务同表，则<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/lock.go#L72-L74\">报错</a>。</li>\n<li>DDLs 为什么是 <code>[]string</code>？因为这里是经过 <code>Split</code> 的 DDLs，单条 DDL 可能会被 Split 成多条 DDL。</li>\n<li>Remain 表示剩余的还未收到 DDL 的 source/worker（以下 worker 都表示 source/worker 对）数量。即如果 worker 把这个 Lock 相关的 DDLs（实际上是 info 的形式）发给 master，master 则把 <code>remain --</code>。</li>\n<li>Ready 和 remain 表达相同的意思，remain 即表示 ready 中为 <code>true</code> 的个数</li>\n<li>Done 表示 operation 结束的 worker 的状态</li>\n</ul>\n<blockquote>\n<p>注意：下面说的所有 worker 都 ready 即是 <strong>remain &lt;= 0</strong>，代码中即是 <strong>synced</strong> = true。这里创造的概念过多，应该收束一下，减少代码的理解难度。</p>\n</blockquote>\n<blockquote>\n<p>TODO：可以把代码中的 remain 改成 noReadies；synced 改成 allReady</p>\n</blockquote>\n<h2 id=\"3、Info\"><a href=\"#3、Info\" class=\"headerlink\" title=\"3、Info\"></a>3、Info</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Info represents the shard DDL information.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// This information should be persistent in etcd so can be retrieved after the DM-master leader restarted or changed.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// <span class=\"doctag\">NOTE:</span> `Task` and `Source` are redundant in the etcd key path for convenient.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Info <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    Task   <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;task&quot;`</span>   <span class=\"comment\">// data migration task name</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Source <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;source&quot;`</span> <span class=\"comment\">// upstream source ID</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Schema <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;schema&quot;`</span> <span class=\"comment\">// schema name of the DDL</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Table  <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;table&quot;`</span>  <span class=\"comment\">// table name of the DDL</span></span><br><span class=\"line\"></span><br><span class=\"line\">    DDLs   []<span class=\"type\">string</span> <span class=\"string\">`json:&quot;ddls&quot;`</span>   <span class=\"comment\">// DDL statements</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Info 并没有什么特别的地方，只是用作 worker 通知 master，某 lock ready 的消息。</p>\n<h2 id=\"4、Operation\"><a href=\"#4、Operation\" class=\"headerlink\" title=\"4、Operation\"></a>4、Operation</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Operation represents a shard DDL coordinate operation.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// This information should be persistent in etcd so can be retrieved after the DM-master leader restarted or changed.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// <span class=\"doctag\">NOTE:</span> `Task` and `Source` are redundant in the etcd key path for convenient.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Operation <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    ID     <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;id&quot;`</span>     <span class=\"comment\">// the corresponding DDL lock ID</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Task   <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;task&quot;`</span>   <span class=\"comment\">// data migration task name</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Source <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;source&quot;`</span> <span class=\"comment\">// upstream source ID</span></span><br><span class=\"line\"></span><br><span class=\"line\">    DDLs   []<span class=\"type\">string</span> <span class=\"string\">`json:&quot;ddls&quot;`</span>   <span class=\"comment\">// DDL statements</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Exec   <span class=\"type\">bool</span>     <span class=\"string\">`json:&quot;exec&quot;`</span>   <span class=\"comment\">// execute or skip the DDL statements</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Done   <span class=\"type\">bool</span>     <span class=\"string\">`json:&quot;done&quot;`</span>   <span class=\"comment\">// whether the `Exec` operation has done</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// only used to report to the caller of the watcher, do not marsh it.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// if it&#x27;s true, it means the Operation has been deleted in etcd.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    IsDeleted <span class=\"type\">bool</span> <span class=\"string\">`json:&quot;-&quot;`</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Exec：是 master 向 worker 发送消息时所用到的字段。它告知该 worker 是否需要执行 DDL，只需要 owner 执行 DDL</li>\n<li>Done：是 worker 向 master 发送消息时所用到的字段。它告知 master 该 worker done 了。done 并不代表该 worker 执行了 DDL，而是表示一种状态，因为只有 owner 可以执行 DDL，non-owner done 可以当作 non-worker 接受到了 DDL 已执行的信息的确认。</li>\n</ul>\n<h2 id=\"3、Start\"><a href=\"#3、Start\" class=\"headerlink\" title=\"3、Start\"></a>3、Start</h2><blockquote>\n<p>以下可以直接在代码中搜索对应的名字，请务必与对应代码一起阅读！</p>\n</blockquote>\n<ul>\n<li><p>s.pessimist.Start</p>\n</li>\n<li><p>p.run</p>\n<ul>\n<li><p>watchInfoOperation</p>\n<ul>\n<li><p>pessimism.WatchInfoPut：等待 worker 发送 info</p>\n</li>\n<li><p>p.handleInfoPut：</p>\n<ul>\n<li>收到 Worker 发送的 info 之后，意味着该 worker <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/lock.go#L87-L88\">已 ready</a></li>\n<li>如果这个时候所有的 source/worker 都 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L486\">ready（synced）</a> 了，则可以<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L602-L611\">发送一个 exec operation 给该 lock 的 owner</a>（第一个<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/keeper.go#L49\">创建 lock</a> 的 worker）</li>\n</ul>\n</li>\n<li><p>pessimism.WatchOperationPut：</p>\n<ul>\n<li>等待 worker 发送 operation done。</li>\n<li>这里的 operation 和 上面发送的 operation 其实是一样的，这里监听的没有指定 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L192\">task 和 source</a>，上面发送的 operation 是<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L604\">指定 task 和 source</a> 的。所以上面发送的 operation 这里也会监听到，</li>\n</ul>\n</li>\n<li><p>p.handleOperationPut：</p>\n<ul>\n<li><p>收到 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L509-L512\">not done </a>operation 这里并不进行操作。即上面发送 exec operation 的时候没有 done。</p>\n</li>\n<li><p>当收到 operation is done 时，才进行一系列操作。即从 worker 发送过来的 done operation。</p>\n<ul>\n<li>首先 markDone</li>\n<li>如果是 owner done 了，还会对 non-owner 发送 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L553\">exec operation</a>，督促 non-owner done</li>\n<li>如果所有的 worker 都 done 了（即 resolved），则<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L533\">把 lock 释放</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>错误处理</p>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"三、Worker\"><a href=\"#三、Worker\" class=\"headerlink\" title=\"三、Worker\"></a>三、Worker</h1><h2 id=\"1、Pessimist\"><a href=\"#1、Pessimist\" class=\"headerlink\" title=\"1、Pessimist\"></a>1、Pessimist</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Pessimist used to coordinate the shard DDL migration in pessimism mode.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Pessimist <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    mu sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    logger log.Logger</span><br><span class=\"line\"></span><br><span class=\"line\">    cli    *clientv3.Client</span><br><span class=\"line\"></span><br><span class=\"line\">    task   <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\">    source <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// the shard DDL info which is pending to handle.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    pendingInfo *pessimism.Info</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// the shard DDL lock operation which is pending to handle.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    pendingOp *pessimism.Operation</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L252\">NewPessimist</a>：worker 中的 pessimist 不同于 master 中的 pessimist。它只保存了 <code>pendingInfo</code> 和 <code>pendingOp</code>，用于保存当前的 Info 和 Operation</li>\n</ul>\n<h2 id=\"2、ShardingGroupKeeper\"><a href=\"#2、ShardingGroupKeeper\" class=\"headerlink\" title=\"2、ShardingGroupKeeper\"></a>2、ShardingGroupKeeper</h2><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L277\">NewShardingGroupKeeper</a>：其中最重要的结构体就是 <code>shardingGroup</code>。<code>shardingGroup</code> 和 master 中的 <code>Lock</code> 类似，也是用于管理 DDL 影响到的 table（在 Lock 中是 source/worker）。</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ShardingGroupKeeper used to keep ShardingGroup.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> ShardingGroupKeeper <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">    groups <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]*ShardingGroup <span class=\"comment\">// target table ID -&gt; ShardingGroup</span></span><br><span class=\"line\"></span><br><span class=\"line\">    cfg    *config.SubTaskConfig</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    shardMetaSchema    <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\">    shardMetaTable     <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\">    shardMetaTableName <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    db     *conn.BaseDB</span><br><span class=\"line\"></span><br><span class=\"line\">    dbConn *dbconn.DBConn</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    tctx *tcontext.Context</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、ShardingGroup\"><a href=\"#3、ShardingGroup\" class=\"headerlink\" title=\"3、ShardingGroup\"></a>3、ShardingGroup</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ShardingGroup represents a sharding DDL sync group.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> ShardingGroup <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// remain count waiting for syncing</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// == len(sources):  DDL syncing not started or resolved</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// == 0: all DDLs synced, will be reset to len(sources) after resolved combining with other dm-workers</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// (0, len(sources)): waiting for syncing</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// <span class=\"doctag\">NOTE:</span> we can make remain to be configurable if needed</span></span><br><span class=\"line\"></span><br><span class=\"line\">    remain       <span class=\"type\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\">    sources      <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]<span class=\"type\">bool</span> <span class=\"comment\">// source table ID -&gt; whether source table&#x27;s DDL synced</span></span><br><span class=\"line\"></span><br><span class=\"line\">    IsSchemaOnly <span class=\"type\">bool</span>            <span class=\"comment\">// whether is a schema (database) only DDL <span class=\"doctag\">TODO:</span> zxc add schema-level syncing support later</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    sourceID <span class=\"type\">string</span>                  <span class=\"comment\">// associate dm-worker source ID</span></span><br><span class=\"line\"></span><br><span class=\"line\">    meta     *shardmeta.ShardingMeta <span class=\"comment\">// sharding sequence meta storage</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    firstLocation    *binlog.Location <span class=\"comment\">// first DDL&#x27;s binlog pos and gtid, used to restrain the global checkpoint when un-resolved</span></span><br><span class=\"line\"></span><br><span class=\"line\">    firstEndLocation *binlog.Location <span class=\"comment\">// first DDL&#x27;s binlog End_log_pos and gtid, used to re-direct binlog streamer after synced</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ddls             []<span class=\"type\">string</span>         <span class=\"comment\">// DDL which current in syncing</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    flavor     <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\">    enableGTID <span class=\"type\">bool</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Remain 和 Lock 中的 remain 意义完全一样，但是这里指 table 是否 ready（现代码中用的 synced）</li>\n</ul>\n<blockquote>\n<p>whether source table’s DDL synced</p>\n</blockquote>\n<blockquote>\n<p>TODO：应该统一概念，这里也用 ready 表示</p>\n</blockquote>\n<ul>\n<li>sources：和 Lock 中的 ready 类似</li>\n<li>firstLocation/firstEndLocation/ddls：这三个其实在 meta 中都有保存，所以感觉其实没啥用</li>\n<li>meta：里面保存着所有的有用的信息，下面详细说</li>\n</ul>\n<h2 id=\"4、ShardingMeta\"><a href=\"#4、ShardingMeta\" class=\"headerlink\" title=\"4、ShardingMeta\"></a>4、ShardingMeta</h2><p>这些信息会被持久化到磁盘中</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ShardingMeta stores sharding ddl sequence</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// including global sequence and each source&#x27;s own sequence</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// <span class=\"doctag\">NOTE:</span> sharding meta is not thread safe, it must be used in thread safe context.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> ShardingMeta <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    activeIdx <span class=\"type\">int</span>                          <span class=\"comment\">// the first unsynced DDL index</span></span><br><span class=\"line\"></span><br><span class=\"line\">    global    *ShardingSequence            <span class=\"comment\">// merged sharding sequence of all source tables</span></span><br><span class=\"line\"></span><br><span class=\"line\">    sources   <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]*ShardingSequence <span class=\"comment\">// source table ID -&gt; its sharding sequence</span></span><br><span class=\"line\"></span><br><span class=\"line\">    tableName <span class=\"type\">string</span>                       <span class=\"comment\">// table name (with schema) used in downstream meta db</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    enableGTID <span class=\"type\">bool</span> <span class=\"comment\">// whether enableGTID, used to compare location</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>activeIdx：表示当前活跃的 DDL 下标，即现在被哪个 DDL 卡住了</li>\n<li>global：表示全局的 DDL 序列，即所有 table 中最长的</li>\n<li>sources：表示各个 table 的 DDL 序列</li>\n</ul>\n<h2 id=\"5、ShardingSequence-和-DDLItem\"><a href=\"#5、ShardingSequence-和-DDLItem\" class=\"headerlink\" title=\"5、ShardingSequence 和 DDLItem\"></a>5、ShardingSequence 和 DDLItem</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ShardingSequence records a list of DDLItem.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> ShardingSequence <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    Items []*DDLItem <span class=\"string\">`json:&quot;items&quot;`</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// DDLItem records ddl information used in sharding sequence organization.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> DDLItem <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    FirstLocation binlog.Location <span class=\"string\">`json:&quot;-&quot;`</span>      <span class=\"comment\">// first DDL&#x27;s binlog Pos, not the End_log_pos of the event</span></span><br><span class=\"line\"></span><br><span class=\"line\">    DDLs          []<span class=\"type\">string</span>        <span class=\"string\">`json:&quot;ddls&quot;`</span>   <span class=\"comment\">// DDLs, these ddls are in the same QueryEvent</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Source        <span class=\"type\">string</span>          <span class=\"string\">`json:&quot;source&quot;`</span> <span class=\"comment\">// source table ID</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// just used for json&#x27;s marshal and unmarshal, because gtid.Set in FirstLocation is interface,</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// can&#x27;t be marshal and unmarshal</span></span><br><span class=\"line\"></span><br><span class=\"line\">    FirstPosition mysql.Position <span class=\"string\">`json:&quot;first-position&quot;`</span></span><br><span class=\"line\"></span><br><span class=\"line\">    FirstGTIDSet  <span class=\"type\">string</span>         <span class=\"string\">`json:&quot;first-gtid-set&quot;`</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这里的 DDLItem 和 Lock 中的 []DDL 其实是一样的，可以看到一个 DDLItem 中也包含多个 DDL。但是这里的 DDLItem 中封装了更多的信息：</p>\n<blockquote>\n<p>DDLs []string `json:”ddls”` // DDLs, these ddls are in the same QueryEvent</p>\n</blockquote>\n<ul>\n<li>FirstLocation：DDL 开始的位点，主要用于识别该 DDL 之前是否来过了。</li>\n</ul>\n<h2 id=\"6、Init\"><a href=\"#6、Init\" class=\"headerlink\" title=\"6、Init\"></a>6、Init</h2><ul>\n<li>s.sgk.Init()：在下游创建库表 <code>dm_meta.($task)_syncer_sharding_meta</code></li>\n<li>s.initShardingGroups</li>\n</ul>\n<blockquote>\n<p>TODO：可用 <code>utils.FetchTargetDoTables()</code> 替换 <code>fromDB.FetchAllDoTables</code></p>\n</blockquote>\n<ol>\n<li>s.sgk.LoadShardMeta：把数据读出来，存到内存里</li>\n<li>s.sgk.AddGroup：把 ShardingGroup 恢复</li>\n</ol>\n<ul>\n<li>Reset</li>\n</ul>\n<h2 id=\"7、Start\"><a href=\"#7、Start\" class=\"headerlink\" title=\"7、Start\"></a>7、Start</h2><ul>\n<li>启动 syncDDL 线程，等待 DDL job</li>\n</ul>\n<h1 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h1><p>本小节主要介绍了在悲观协调中：</p>\n<ul>\n<li>会用到的各种数据结构</li>\n<li>Master 运行了几个线程，等待 worker 中信息的来临</li>\n<li>Worker 运行了 syncDDL 线程，等待着 DDL 到来</li>\n</ul>\n<p>这一节中，罗列了特别多的概念，看不懂是正常的！在下一节，将从 worker 接受到一条 DDL 开始，直到这条 DDL 的 lock 解除的过程。在这个过程中，我们来学习这些结构体到底是怎么用的。</p>\n<blockquote>\n<p>抱歉第二章就是悲观协调这个功能😂，本来想让系列文章的难度更加平滑一点的，但是人太懒了一拖再拖😂。为了避免再拖下去，先把写了的存活发出来吧！</p>\n</blockquote>\n","site":{"data":{}},"cover_type":"img","length":8456,"excerpt":"","more":"<h1 id=\"一、概述\"><a href=\"#一、概述\" class=\"headerlink\" title=\"一、概述\"></a>一、概述</h1><p>分库分表的悲观协调方法是 2018 年开发的特性，是 DM 首次支持 MySQL 分库分表的迁移。由于分库分表在各个公司中的应用实在太过广泛，所以只有在支持分库分表迁移后，DM 才有了工程实践的意义，否则只能算作一个玩具。这对 DM 来说意义重大。</p>\n<p>由于悲观协调的内容庞大，本节只讲述悲观协调的准备过程：</p>\n<ul>\n<li>Master 的准备过程</li>\n<li>Worker 的准备过程</li>\n</ul>\n<p>以及在悲观协调过程中至关重要的结构体：</p>\n<ul>\n<li>Lock</li>\n<li>Info</li>\n<li>Operation</li>\n<li>ShardingMeta</li>\n<li>ShardingGroup</li>\n<li>…</li>\n</ul>\n<blockquote>\n<p>注：为了专注于我们的目的（悲观协调），本文不会对无关代码进行解读</p>\n</blockquote>\n<blockquote>\n<p>这一节外链中的代码，读者可能会产生这个逻辑为什么是这里的疑问。这是因为本节并没有完全按照顺序读代码。所以读者可以仅带着学习的心态阅读本节，暂时不需要知道它为什么在代码的这个地方。在下一节中会顺序阅读代码</p>\n</blockquote>\n<blockquote>\n<p>本节基于 <a href=\"https://github.com/pingcap/tiflow/tree/release-6.0\">DM release-6.0.0</a></p>\n</blockquote>\n<h1 id=\"二、Master\"><a href=\"#二、Master\" class=\"headerlink\" title=\"二、Master\"></a>二、Master</h1><h2 id=\"1、Pessimist-和-LockKeeper\"><a href=\"#1、Pessimist-和-LockKeeper\" class=\"headerlink\" title=\"1、Pessimist 和 LockKeeper\"></a>1、Pessimist 和 LockKeeper</h2><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/server.go#L140\">NewPessimist</a>：Pessimist 是 Master 处理悲观协调的结构体，其中最重要的成员是 <code>LockKeeper</code>。</li>\n<li><code>LockKeeper</code> 的作用是管理各种各样的 lock。</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// LockKeeper used to keep and handle DDL lock conveniently.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// The lock information do not need to be persistent, and can be re-constructed from the shard DDL info.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> LockKeeper <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    mu    sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">    locks <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]*Lock <span class=\"comment\">// lockID -&gt; Lock</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Lock 可以看作是每一个 ddl 影响的库表，这些库表分布在不同的 MySQL/source 中。由于在悲观协调过程中，数据流（binlog 流）不是停滞的，所以在数据流中，会源源不断地出现新 DDL，即新 lock。</li>\n<li>故 <code>LockKeeper</code> 就是管理这些 lock。</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Lock represents the shard DDL lock in memory.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// This information does not need to be persistent, and can be re-constructed from the shard DDL info.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Lock <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    mu sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    ID     <span class=\"type\">string</span>   <span class=\"comment\">// lock&#x27;s ID</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Task   <span class=\"type\">string</span>   <span class=\"comment\">// lock&#x27;s corresponding task name</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Owner  <span class=\"type\">string</span>   <span class=\"comment\">// Owner&#x27;s source ID (not DM-worker&#x27;s name)</span></span><br><span class=\"line\"></span><br><span class=\"line\">    DDLs   []<span class=\"type\">string</span> <span class=\"comment\">// DDL statements</span></span><br><span class=\"line\"></span><br><span class=\"line\">    remain <span class=\"type\">int</span>      <span class=\"comment\">// remain count of sources needed to receive DDL info</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// whether the DDL info received from the source.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// if all of them have been ready, then we call the lock `synced`.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ready <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]<span class=\"type\">bool</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// whether the operations have done (exec/skip the shard DDL).</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// if all of them have done, then we call the lock `resolved`.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    done <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]<span class=\"type\">bool</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2、Lock\"><a href=\"#2、Lock\" class=\"headerlink\" title=\"2、Lock\"></a>2、Lock</h2><ul>\n<li>ID 表现形式为 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/utils/common.go#L223\">${task}-${schema}.${table}</a>，从 LockKeeper 的结构可以看到同一任务同一表下只能有一个 lock，如果遇到了不同的 DDL，影响的又是同任务同表，则<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/lock.go#L72-L74\">报错</a>。</li>\n<li>DDLs 为什么是 <code>[]string</code>？因为这里是经过 <code>Split</code> 的 DDLs，单条 DDL 可能会被 Split 成多条 DDL。</li>\n<li>Remain 表示剩余的还未收到 DDL 的 source/worker（以下 worker 都表示 source/worker 对）数量。即如果 worker 把这个 Lock 相关的 DDLs（实际上是 info 的形式）发给 master，master 则把 <code>remain --</code>。</li>\n<li>Ready 和 remain 表达相同的意思，remain 即表示 ready 中为 <code>true</code> 的个数</li>\n<li>Done 表示 operation 结束的 worker 的状态</li>\n</ul>\n<blockquote>\n<p>注意：下面说的所有 worker 都 ready 即是 <strong>remain &lt;= 0</strong>，代码中即是 <strong>synced</strong> = true。这里创造的概念过多，应该收束一下，减少代码的理解难度。</p>\n</blockquote>\n<blockquote>\n<p>TODO：可以把代码中的 remain 改成 noReadies；synced 改成 allReady</p>\n</blockquote>\n<h2 id=\"3、Info\"><a href=\"#3、Info\" class=\"headerlink\" title=\"3、Info\"></a>3、Info</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Info represents the shard DDL information.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// This information should be persistent in etcd so can be retrieved after the DM-master leader restarted or changed.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// <span class=\"doctag\">NOTE:</span> `Task` and `Source` are redundant in the etcd key path for convenient.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Info <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    Task   <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;task&quot;`</span>   <span class=\"comment\">// data migration task name</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Source <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;source&quot;`</span> <span class=\"comment\">// upstream source ID</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Schema <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;schema&quot;`</span> <span class=\"comment\">// schema name of the DDL</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Table  <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;table&quot;`</span>  <span class=\"comment\">// table name of the DDL</span></span><br><span class=\"line\"></span><br><span class=\"line\">    DDLs   []<span class=\"type\">string</span> <span class=\"string\">`json:&quot;ddls&quot;`</span>   <span class=\"comment\">// DDL statements</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>Info 并没有什么特别的地方，只是用作 worker 通知 master，某 lock ready 的消息。</p>\n<h2 id=\"4、Operation\"><a href=\"#4、Operation\" class=\"headerlink\" title=\"4、Operation\"></a>4、Operation</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Operation represents a shard DDL coordinate operation.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// This information should be persistent in etcd so can be retrieved after the DM-master leader restarted or changed.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// <span class=\"doctag\">NOTE:</span> `Task` and `Source` are redundant in the etcd key path for convenient.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Operation <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    ID     <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;id&quot;`</span>     <span class=\"comment\">// the corresponding DDL lock ID</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Task   <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;task&quot;`</span>   <span class=\"comment\">// data migration task name</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Source <span class=\"type\">string</span>   <span class=\"string\">`json:&quot;source&quot;`</span> <span class=\"comment\">// upstream source ID</span></span><br><span class=\"line\"></span><br><span class=\"line\">    DDLs   []<span class=\"type\">string</span> <span class=\"string\">`json:&quot;ddls&quot;`</span>   <span class=\"comment\">// DDL statements</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Exec   <span class=\"type\">bool</span>     <span class=\"string\">`json:&quot;exec&quot;`</span>   <span class=\"comment\">// execute or skip the DDL statements</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Done   <span class=\"type\">bool</span>     <span class=\"string\">`json:&quot;done&quot;`</span>   <span class=\"comment\">// whether the `Exec` operation has done</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// only used to report to the caller of the watcher, do not marsh it.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// if it&#x27;s true, it means the Operation has been deleted in etcd.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    IsDeleted <span class=\"type\">bool</span> <span class=\"string\">`json:&quot;-&quot;`</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Exec：是 master 向 worker 发送消息时所用到的字段。它告知该 worker 是否需要执行 DDL，只需要 owner 执行 DDL</li>\n<li>Done：是 worker 向 master 发送消息时所用到的字段。它告知 master 该 worker done 了。done 并不代表该 worker 执行了 DDL，而是表示一种状态，因为只有 owner 可以执行 DDL，non-owner done 可以当作 non-worker 接受到了 DDL 已执行的信息的确认。</li>\n</ul>\n<h2 id=\"3、Start\"><a href=\"#3、Start\" class=\"headerlink\" title=\"3、Start\"></a>3、Start</h2><blockquote>\n<p>以下可以直接在代码中搜索对应的名字，请务必与对应代码一起阅读！</p>\n</blockquote>\n<ul>\n<li><p>s.pessimist.Start</p>\n</li>\n<li><p>p.run</p>\n<ul>\n<li><p>watchInfoOperation</p>\n<ul>\n<li><p>pessimism.WatchInfoPut：等待 worker 发送 info</p>\n</li>\n<li><p>p.handleInfoPut：</p>\n<ul>\n<li>收到 Worker 发送的 info 之后，意味着该 worker <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/lock.go#L87-L88\">已 ready</a></li>\n<li>如果这个时候所有的 source/worker 都 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L486\">ready（synced）</a> 了，则可以<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L602-L611\">发送一个 exec operation 给该 lock 的 owner</a>（第一个<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/pkg/shardddl/pessimism/keeper.go#L49\">创建 lock</a> 的 worker）</li>\n</ul>\n</li>\n<li><p>pessimism.WatchOperationPut：</p>\n<ul>\n<li>等待 worker 发送 operation done。</li>\n<li>这里的 operation 和 上面发送的 operation 其实是一样的，这里监听的没有指定 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L192\">task 和 source</a>，上面发送的 operation 是<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L604\">指定 task 和 source</a> 的。所以上面发送的 operation 这里也会监听到，</li>\n</ul>\n</li>\n<li><p>p.handleOperationPut：</p>\n<ul>\n<li><p>收到 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L509-L512\">not done </a>operation 这里并不进行操作。即上面发送 exec operation 的时候没有 done。</p>\n</li>\n<li><p>当收到 operation is done 时，才进行一系列操作。即从 worker 发送过来的 done operation。</p>\n<ul>\n<li>首先 markDone</li>\n<li>如果是 owner done 了，还会对 non-owner 发送 <a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L553\">exec operation</a>，督促 non-owner done</li>\n<li>如果所有的 worker 都 done 了（即 resolved），则<a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/dm/master/shardddl/pessimist.go#L533\">把 lock 释放</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>错误处理</p>\n</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"三、Worker\"><a href=\"#三、Worker\" class=\"headerlink\" title=\"三、Worker\"></a>三、Worker</h1><h2 id=\"1、Pessimist\"><a href=\"#1、Pessimist\" class=\"headerlink\" title=\"1、Pessimist\"></a>1、Pessimist</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Pessimist used to coordinate the shard DDL migration in pessimism mode.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Pessimist <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    mu sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    logger log.Logger</span><br><span class=\"line\"></span><br><span class=\"line\">    cli    *clientv3.Client</span><br><span class=\"line\"></span><br><span class=\"line\">    task   <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\">    source <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// the shard DDL info which is pending to handle.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    pendingInfo *pessimism.Info</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// the shard DDL lock operation which is pending to handle.</span></span><br><span class=\"line\"></span><br><span class=\"line\">    pendingOp *pessimism.Operation</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L252\">NewPessimist</a>：worker 中的 pessimist 不同于 master 中的 pessimist。它只保存了 <code>pendingInfo</code> 和 <code>pendingOp</code>，用于保存当前的 Info 和 Operation</li>\n</ul>\n<h2 id=\"2、ShardingGroupKeeper\"><a href=\"#2、ShardingGroupKeeper\" class=\"headerlink\" title=\"2、ShardingGroupKeeper\"></a>2、ShardingGroupKeeper</h2><ul>\n<li><a href=\"https://github.com/pingcap/tiflow/blob/release-6.0/dm/syncer/syncer.go#L277\">NewShardingGroupKeeper</a>：其中最重要的结构体就是 <code>shardingGroup</code>。<code>shardingGroup</code> 和 master 中的 <code>Lock</code> 类似，也是用于管理 DDL 影响到的 table（在 Lock 中是 source/worker）。</li>\n</ul>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ShardingGroupKeeper used to keep ShardingGroup.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> ShardingGroupKeeper <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">    groups <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]*ShardingGroup <span class=\"comment\">// target table ID -&gt; ShardingGroup</span></span><br><span class=\"line\"></span><br><span class=\"line\">    cfg    *config.SubTaskConfig</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    shardMetaSchema    <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\">    shardMetaTable     <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\">    shardMetaTableName <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    db     *conn.BaseDB</span><br><span class=\"line\"></span><br><span class=\"line\">    dbConn *dbconn.DBConn</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    tctx *tcontext.Context</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、ShardingGroup\"><a href=\"#3、ShardingGroup\" class=\"headerlink\" title=\"3、ShardingGroup\"></a>3、ShardingGroup</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ShardingGroup represents a sharding DDL sync group.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> ShardingGroup <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    sync.RWMutex</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// remain count waiting for syncing</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// == len(sources):  DDL syncing not started or resolved</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// == 0: all DDLs synced, will be reset to len(sources) after resolved combining with other dm-workers</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// (0, len(sources)): waiting for syncing</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// <span class=\"doctag\">NOTE:</span> we can make remain to be configurable if needed</span></span><br><span class=\"line\"></span><br><span class=\"line\">    remain       <span class=\"type\">int</span></span><br><span class=\"line\"></span><br><span class=\"line\">    sources      <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]<span class=\"type\">bool</span> <span class=\"comment\">// source table ID -&gt; whether source table&#x27;s DDL synced</span></span><br><span class=\"line\"></span><br><span class=\"line\">    IsSchemaOnly <span class=\"type\">bool</span>            <span class=\"comment\">// whether is a schema (database) only DDL <span class=\"doctag\">TODO:</span> zxc add schema-level syncing support later</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    sourceID <span class=\"type\">string</span>                  <span class=\"comment\">// associate dm-worker source ID</span></span><br><span class=\"line\"></span><br><span class=\"line\">    meta     *shardmeta.ShardingMeta <span class=\"comment\">// sharding sequence meta storage</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    firstLocation    *binlog.Location <span class=\"comment\">// first DDL&#x27;s binlog pos and gtid, used to restrain the global checkpoint when un-resolved</span></span><br><span class=\"line\"></span><br><span class=\"line\">    firstEndLocation *binlog.Location <span class=\"comment\">// first DDL&#x27;s binlog End_log_pos and gtid, used to re-direct binlog streamer after synced</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ddls             []<span class=\"type\">string</span>         <span class=\"comment\">// DDL which current in syncing</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    flavor     <span class=\"type\">string</span></span><br><span class=\"line\"></span><br><span class=\"line\">    enableGTID <span class=\"type\">bool</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Remain 和 Lock 中的 remain 意义完全一样，但是这里指 table 是否 ready（现代码中用的 synced）</li>\n</ul>\n<blockquote>\n<p>whether source table’s DDL synced</p>\n</blockquote>\n<blockquote>\n<p>TODO：应该统一概念，这里也用 ready 表示</p>\n</blockquote>\n<ul>\n<li>sources：和 Lock 中的 ready 类似</li>\n<li>firstLocation/firstEndLocation/ddls：这三个其实在 meta 中都有保存，所以感觉其实没啥用</li>\n<li>meta：里面保存着所有的有用的信息，下面详细说</li>\n</ul>\n<h2 id=\"4、ShardingMeta\"><a href=\"#4、ShardingMeta\" class=\"headerlink\" title=\"4、ShardingMeta\"></a>4、ShardingMeta</h2><p>这些信息会被持久化到磁盘中</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ShardingMeta stores sharding ddl sequence</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// including global sequence and each source&#x27;s own sequence</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// <span class=\"doctag\">NOTE:</span> sharding meta is not thread safe, it must be used in thread safe context.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> ShardingMeta <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    activeIdx <span class=\"type\">int</span>                          <span class=\"comment\">// the first unsynced DDL index</span></span><br><span class=\"line\"></span><br><span class=\"line\">    global    *ShardingSequence            <span class=\"comment\">// merged sharding sequence of all source tables</span></span><br><span class=\"line\"></span><br><span class=\"line\">    sources   <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]*ShardingSequence <span class=\"comment\">// source table ID -&gt; its sharding sequence</span></span><br><span class=\"line\"></span><br><span class=\"line\">    tableName <span class=\"type\">string</span>                       <span class=\"comment\">// table name (with schema) used in downstream meta db</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    enableGTID <span class=\"type\">bool</span> <span class=\"comment\">// whether enableGTID, used to compare location</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>activeIdx：表示当前活跃的 DDL 下标，即现在被哪个 DDL 卡住了</li>\n<li>global：表示全局的 DDL 序列，即所有 table 中最长的</li>\n<li>sources：表示各个 table 的 DDL 序列</li>\n</ul>\n<h2 id=\"5、ShardingSequence-和-DDLItem\"><a href=\"#5、ShardingSequence-和-DDLItem\" class=\"headerlink\" title=\"5、ShardingSequence 和 DDLItem\"></a>5、ShardingSequence 和 DDLItem</h2><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// ShardingSequence records a list of DDLItem.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> ShardingSequence <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    Items []*DDLItem <span class=\"string\">`json:&quot;items&quot;`</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// DDLItem records ddl information used in sharding sequence organization.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> DDLItem <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    FirstLocation binlog.Location <span class=\"string\">`json:&quot;-&quot;`</span>      <span class=\"comment\">// first DDL&#x27;s binlog Pos, not the End_log_pos of the event</span></span><br><span class=\"line\"></span><br><span class=\"line\">    DDLs          []<span class=\"type\">string</span>        <span class=\"string\">`json:&quot;ddls&quot;`</span>   <span class=\"comment\">// DDLs, these ddls are in the same QueryEvent</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Source        <span class=\"type\">string</span>          <span class=\"string\">`json:&quot;source&quot;`</span> <span class=\"comment\">// source table ID</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// just used for json&#x27;s marshal and unmarshal, because gtid.Set in FirstLocation is interface,</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// can&#x27;t be marshal and unmarshal</span></span><br><span class=\"line\"></span><br><span class=\"line\">    FirstPosition mysql.Position <span class=\"string\">`json:&quot;first-position&quot;`</span></span><br><span class=\"line\"></span><br><span class=\"line\">    FirstGTIDSet  <span class=\"type\">string</span>         <span class=\"string\">`json:&quot;first-gtid-set&quot;`</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这里的 DDLItem 和 Lock 中的 []DDL 其实是一样的，可以看到一个 DDLItem 中也包含多个 DDL。但是这里的 DDLItem 中封装了更多的信息：</p>\n<blockquote>\n<p>DDLs []string `json:”ddls”` // DDLs, these ddls are in the same QueryEvent</p>\n</blockquote>\n<ul>\n<li>FirstLocation：DDL 开始的位点，主要用于识别该 DDL 之前是否来过了。</li>\n</ul>\n<h2 id=\"6、Init\"><a href=\"#6、Init\" class=\"headerlink\" title=\"6、Init\"></a>6、Init</h2><ul>\n<li>s.sgk.Init()：在下游创建库表 <code>dm_meta.($task)_syncer_sharding_meta</code></li>\n<li>s.initShardingGroups</li>\n</ul>\n<blockquote>\n<p>TODO：可用 <code>utils.FetchTargetDoTables()</code> 替换 <code>fromDB.FetchAllDoTables</code></p>\n</blockquote>\n<ol>\n<li>s.sgk.LoadShardMeta：把数据读出来，存到内存里</li>\n<li>s.sgk.AddGroup：把 ShardingGroup 恢复</li>\n</ol>\n<ul>\n<li>Reset</li>\n</ul>\n<h2 id=\"7、Start\"><a href=\"#7、Start\" class=\"headerlink\" title=\"7、Start\"></a>7、Start</h2><ul>\n<li>启动 syncDDL 线程，等待 DDL job</li>\n</ul>\n<h1 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h1><p>本小节主要介绍了在悲观协调中：</p>\n<ul>\n<li>会用到的各种数据结构</li>\n<li>Master 运行了几个线程，等待 worker 中信息的来临</li>\n<li>Worker 运行了 syncDDL 线程，等待着 DDL 到来</li>\n</ul>\n<p>这一节中，罗列了特别多的概念，看不懂是正常的！在下一节，将从 worker 接受到一条 DDL 开始，直到这条 DDL 的 lock 解除的过程。在这个过程中，我们来学习这些结构体到底是怎么用的。</p>\n<blockquote>\n<p>抱歉第二章就是悲观协调这个功能😂，本来想让系列文章的难度更加平滑一点的，但是人太懒了一拖再拖😂。为了避免再拖下去，先把写了的存活发出来吧！</p>\n</blockquote>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"clxgdbzoh0001xbdygyu7c36p","category_id":"clxgdbzom0003xbdyhftahxry","_id":"clxgdbzop0007xbdyf7yqdkr6"},{"post_id":"clxgfc6d300007odyg8gg1y4w","category_id":"clxgfdvel0004fhdyg0rb7wuq","_id":"clxgfdvem0005fhdyhyobb52i"},{"post_id":"clxh0ivhl0000rvdyen14f5dy","category_id":"clxgfdvel0004fhdyg0rb7wuq","_id":"clxh0ivhs0003rvdyd98kdl7m"},{"post_id":"clxh0mtjx0000avdy7tdtf3iz","category_id":"clxgfdvel0004fhdyg0rb7wuq","_id":"clxh0mtk30003avdyf5s92d7p"},{"post_id":"clxh0oeka0000kbdy6mt69rq6","category_id":"clxgfdvel0004fhdyg0rb7wuq","_id":"clxh0pgxf0002m3dyaq5f17qw"},{"post_id":"clxh0zy370000hfdy585eg5ei","category_id":"clxgfdvel0004fhdyg0rb7wuq","_id":"clxh0zy3c0003hfdy9ugh1n33"}],"PostTag":[{"post_id":"clxgdbzoh0001xbdygyu7c36p","tag_id":"clxgdbzon0004xbdy9jlx483v","_id":"clxgdbzop0008xbdy5dgvgrxz"},{"post_id":"clxgdbzoh0001xbdygyu7c36p","tag_id":"clxgdbzoo0006xbdy6c4m53ue","_id":"clxgdbzoq0009xbdy4kytajym"},{"post_id":"clxgfc6d300007odyg8gg1y4w","tag_id":"clxgfdcs90000fhdy0ht83py9","_id":"clxgfdcsb0002fhdy9p6p0b0u"},{"post_id":"clxgfc6d300007odyg8gg1y4w","tag_id":"clxgfdcsa0001fhdy0f8j8s40","_id":"clxgfdcsb0003fhdy5x1u8pf3"},{"post_id":"clxh0ivhl0000rvdyen14f5dy","tag_id":"clxgfdcs90000fhdy0ht83py9","_id":"clxh0ivhr0001rvdybk4u1mnh"},{"post_id":"clxh0ivhl0000rvdyen14f5dy","tag_id":"clxgfdcsa0001fhdy0f8j8s40","_id":"clxh0ivhs0002rvdyby8665aw"},{"post_id":"clxh0mtjx0000avdy7tdtf3iz","tag_id":"clxgfdcs90000fhdy0ht83py9","_id":"clxh0mtk20001avdye9hj8gk5"},{"post_id":"clxh0mtjx0000avdy7tdtf3iz","tag_id":"clxgfdcsa0001fhdy0f8j8s40","_id":"clxh0mtk30002avdygayi74rl"},{"post_id":"clxh0oeka0000kbdy6mt69rq6","tag_id":"clxgfdcs90000fhdy0ht83py9","_id":"clxh0pgxe0000m3dycs4obulf"},{"post_id":"clxh0oeka0000kbdy6mt69rq6","tag_id":"clxgfdcsa0001fhdy0f8j8s40","_id":"clxh0pgxf0001m3dyeolf9bw4"},{"post_id":"clxh0zy370000hfdy585eg5ei","tag_id":"clxgfdcs90000fhdy0ht83py9","_id":"clxh0zy3c0001hfdy956y21be"},{"post_id":"clxh0zy370000hfdy585eg5ei","tag_id":"clxgfdcsa0001fhdy0f8j8s40","_id":"clxh0zy3c0002hfdy8tc2gbku"}],"Tag":[{"name":"生活","_id":"clxgdbzon0004xbdy9jlx483v"},{"name":"工作","_id":"clxgdbzoo0006xbdy6c4m53ue"},{"name":"DM, 源码阅读","_id":"clxgfc6d800017ody912ifvxa"},{"name":"DM","_id":"clxgfdcs90000fhdy0ht83py9"},{"name":"源码阅读","_id":"clxgfdcsa0001fhdy0f8j8s40"}]}}